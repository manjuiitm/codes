{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3601c67a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:38.116340Z",
     "iopub.status.busy": "2025-07-22T09:29:38.116126Z",
     "iopub.status.idle": "2025-07-22T09:29:38.119854Z",
     "shell.execute_reply": "2025-07-22T09:29:38.119265Z"
    },
    "papermill": {
     "duration": 0.035531,
     "end_time": "2025-07-22T09:29:38.120859",
     "exception": false,
     "start_time": "2025-07-22T09:29:38.085328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7da5a0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:38.174206Z",
     "iopub.status.busy": "2025-07-22T09:29:38.173992Z",
     "iopub.status.idle": "2025-07-22T09:29:38.176933Z",
     "shell.execute_reply": "2025-07-22T09:29:38.176340Z"
    },
    "papermill": {
     "duration": 0.030735,
     "end_time": "2025-07-22T09:29:38.178023",
     "exception": false,
     "start_time": "2025-07-22T09:29:38.147288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"/kaggle/input/engage-2-value-from-clicks-to-conversions/train_data.csv\") \n",
    "# X = df.drop(\"purchaseValue\", axis=1) \n",
    "# y = df['purchaseValue'] \n",
    "# from sklearn.dummy import DummyRegressor \n",
    "# model = DummyRegressor().fit(X,y) \n",
    "# X_test = pd.read_csv(\"/kaggle/input/engage-2-value-from-clicks-to-conversions/test_data.csv\") \n",
    "# y_pred=model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00f29a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:38.273098Z",
     "iopub.status.busy": "2025-07-22T09:29:38.272599Z",
     "iopub.status.idle": "2025-07-22T09:29:38.275781Z",
     "shell.execute_reply": "2025-07-22T09:29:38.275104Z"
    },
    "papermill": {
     "duration": 0.072536,
     "end_time": "2025-07-22T09:29:38.276887",
     "exception": false,
     "start_time": "2025-07-22T09:29:38.204351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({\"id\": range(0,X_test.shape[0]), \"purchaseValue\": y_pred}) \n",
    "# submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b14de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:38.330546Z",
     "iopub.status.busy": "2025-07-22T09:29:38.329921Z",
     "iopub.status.idle": "2025-07-22T09:29:43.513203Z",
     "shell.execute_reply": "2025-07-22T09:29:43.512376Z"
    },
    "papermill": {
     "duration": 5.211627,
     "end_time": "2025-07-22T09:29:43.514669",
     "exception": false,
     "start_time": "2025-07-22T09:29:38.303042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_df = pd.read_csv('/kaggle/input/engage-2-value-from-clicks-to-conversions/train_data.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/engage-2-value-from-clicks-to-conversions/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436e3f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:43.569230Z",
     "iopub.status.busy": "2025-07-22T09:29:43.568586Z",
     "iopub.status.idle": "2025-07-22T09:29:43.571911Z",
     "shell.execute_reply": "2025-07-22T09:29:43.571242Z"
    },
    "papermill": {
     "duration": 0.031469,
     "end_time": "2025-07-22T09:29:43.573154",
     "exception": false,
     "start_time": "2025-07-22T09:29:43.541685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea89f247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:43.627475Z",
     "iopub.status.busy": "2025-07-22T09:29:43.627293Z",
     "iopub.status.idle": "2025-07-22T09:29:43.630293Z",
     "shell.execute_reply": "2025-07-22T09:29:43.629687Z"
    },
    "papermill": {
     "duration": 0.030631,
     "end_time": "2025-07-22T09:29:43.631437",
     "exception": false,
     "start_time": "2025-07-22T09:29:43.600806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9430871a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:43.684435Z",
     "iopub.status.busy": "2025-07-22T09:29:43.684227Z",
     "iopub.status.idle": "2025-07-22T09:29:43.687269Z",
     "shell.execute_reply": "2025-07-22T09:29:43.686586Z"
    },
    "papermill": {
     "duration": 0.030588,
     "end_time": "2025-07-22T09:29:43.688380",
     "exception": false,
     "start_time": "2025-07-22T09:29:43.657792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d453f14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:43.741522Z",
     "iopub.status.busy": "2025-07-22T09:29:43.741326Z",
     "iopub.status.idle": "2025-07-22T09:29:43.744335Z",
     "shell.execute_reply": "2025-07-22T09:29:43.743646Z"
    },
    "papermill": {
     "duration": 0.030461,
     "end_time": "2025-07-22T09:29:43.745452",
     "exception": false,
     "start_time": "2025-07-22T09:29:43.714991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5cb54a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:43.797992Z",
     "iopub.status.busy": "2025-07-22T09:29:43.797795Z",
     "iopub.status.idle": "2025-07-22T09:29:43.800743Z",
     "shell.execute_reply": "2025-07-22T09:29:43.800115Z"
    },
    "papermill": {
     "duration": 0.030446,
     "end_time": "2025-07-22T09:29:43.801775",
     "exception": false,
     "start_time": "2025-07-22T09:29:43.771329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce54e0b",
   "metadata": {
    "papermill": {
     "duration": 0.026054,
     "end_time": "2025-07-22T09:29:43.853724",
     "exception": false,
     "start_time": "2025-07-22T09:29:43.827670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "User & Session Metadata \n",
    "| Column          | Description                                          |\n",
    "| --------------- | ---------------------------------------------------- |\n",
    "| `userId`        | Unique ID for the user                               |\n",
    "| `sessionId`     | Unique ID for a session (group of user interactions) |\n",
    "| `sessionNumber` | The nth session for the user                         |\n",
    "| `sessionStart`  | Timestamp (or similar) marking session start         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9bb89",
   "metadata": {
    "papermill": {
     "duration": 0.025839,
     "end_time": "2025-07-22T09:29:43.905326",
     "exception": false,
     "start_time": "2025-07-22T09:29:43.879487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Missing Values\n",
    "* Explore Numerical data\n",
    "* Explore Categorical data\n",
    "* Find the relationship between variables\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08b6299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:43.957811Z",
     "iopub.status.busy": "2025-07-22T09:29:43.957614Z",
     "iopub.status.idle": "2025-07-22T09:29:43.989835Z",
     "shell.execute_reply": "2025-07-22T09:29:43.989103Z"
    },
    "papermill": {
     "duration": 0.059731,
     "end_time": "2025-07-22T09:29:43.990961",
     "exception": false,
     "start_time": "2025-07-22T09:29:43.931230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trafficSource.isTrueDirect</th>\n",
       "      <th>purchaseValue</th>\n",
       "      <th>browser</th>\n",
       "      <th>device.screenResolution</th>\n",
       "      <th>trafficSource.adContent</th>\n",
       "      <th>trafficSource.keyword</th>\n",
       "      <th>screenSize</th>\n",
       "      <th>geoCluster</th>\n",
       "      <th>trafficSource.adwordsClickInfo.slot</th>\n",
       "      <th>device.mobileDeviceBranding</th>\n",
       "      <th>...</th>\n",
       "      <th>device.language</th>\n",
       "      <th>deviceType</th>\n",
       "      <th>userChannel</th>\n",
       "      <th>device.browserVersion</th>\n",
       "      <th>totalHits</th>\n",
       "      <th>device.screenColors</th>\n",
       "      <th>sessionStart</th>\n",
       "      <th>geoNetwork.continent</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>new_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "      <td>Region_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>...</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Social</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>1</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>1500100799</td>\n",
       "      <td>Americas</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "      <td>Region_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>...</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Direct</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>1</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>1495262065</td>\n",
       "      <td>Americas</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>medium</td>\n",
       "      <td>Region_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>...</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>6</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>1508510328</td>\n",
       "      <td>Europe</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "      <td>Region_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>...</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Social</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>1</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>1483431838</td>\n",
       "      <td>Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>88950000.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "      <td>Region_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>...</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Direct</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>66</td>\n",
       "      <td>not available in demo dataset</td>\n",
       "      <td>1475804633</td>\n",
       "      <td>Americas</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trafficSource.isTrueDirect  purchaseValue            browser  \\\n",
       "0                        NaN            0.0               Edge   \n",
       "1                       True            0.0             Chrome   \n",
       "2                       True            0.0             Chrome   \n",
       "3                        NaN            0.0  Internet Explorer   \n",
       "4                       True     88950000.0             Chrome   \n",
       "\n",
       "         device.screenResolution trafficSource.adContent  \\\n",
       "0  not available in demo dataset                     NaN   \n",
       "1  not available in demo dataset                     NaN   \n",
       "2  not available in demo dataset                     NaN   \n",
       "3  not available in demo dataset                     NaN   \n",
       "4  not available in demo dataset                     NaN   \n",
       "\n",
       "  trafficSource.keyword screenSize geoCluster  \\\n",
       "0                   NaN     medium   Region_2   \n",
       "1                   NaN     medium   Region_3   \n",
       "2        (not provided)     medium   Region_2   \n",
       "3                   NaN     medium   Region_4   \n",
       "4                   NaN     medium   Region_3   \n",
       "\n",
       "  trafficSource.adwordsClickInfo.slot    device.mobileDeviceBranding  ...  \\\n",
       "0                                 NaN  not available in demo dataset  ...   \n",
       "1                                 NaN  not available in demo dataset  ...   \n",
       "2                                 NaN  not available in demo dataset  ...   \n",
       "3                                 NaN  not available in demo dataset  ...   \n",
       "4                                 NaN  not available in demo dataset  ...   \n",
       "\n",
       "                 device.language  deviceType     userChannel  \\\n",
       "0  not available in demo dataset     desktop          Social   \n",
       "1  not available in demo dataset     desktop          Direct   \n",
       "2  not available in demo dataset     desktop  Organic Search   \n",
       "3  not available in demo dataset     desktop          Social   \n",
       "4  not available in demo dataset     desktop          Direct   \n",
       "\n",
       "           device.browserVersion totalHits            device.screenColors  \\\n",
       "0  not available in demo dataset         1  not available in demo dataset   \n",
       "1  not available in demo dataset         1  not available in demo dataset   \n",
       "2  not available in demo dataset         6  not available in demo dataset   \n",
       "3  not available in demo dataset         1  not available in demo dataset   \n",
       "4  not available in demo dataset        66  not available in demo dataset   \n",
       "\n",
       "  sessionStart  geoNetwork.continent device.isMobile new_visits  \n",
       "0   1500100799              Americas           False        1.0  \n",
       "1   1495262065              Americas           False        1.0  \n",
       "2   1508510328                Europe           False        NaN  \n",
       "3   1483431838                  Asia           False        1.0  \n",
       "4   1475804633              Americas           False        1.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7821a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.045413Z",
     "iopub.status.busy": "2025-07-22T09:29:44.045200Z",
     "iopub.status.idle": "2025-07-22T09:29:44.048160Z",
     "shell.execute_reply": "2025-07-22T09:29:44.047500Z"
    },
    "papermill": {
     "duration": 0.030692,
     "end_time": "2025-07-22T09:29:44.049163",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.018471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[['trafficSource.keyword','trafficSource.isTrueDirect','trafficSource.referralPath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df382b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.102407Z",
     "iopub.status.busy": "2025-07-22T09:29:44.102211Z",
     "iopub.status.idle": "2025-07-22T09:29:44.104966Z",
     "shell.execute_reply": "2025-07-22T09:29:44.104481Z"
    },
    "papermill": {
     "duration": 0.030449,
     "end_time": "2025-07-22T09:29:44.105901",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.075452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "566b4142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.159356Z",
     "iopub.status.busy": "2025-07-22T09:29:44.159182Z",
     "iopub.status.idle": "2025-07-22T09:29:44.161976Z",
     "shell.execute_reply": "2025-07-22T09:29:44.161361Z"
    },
    "papermill": {
     "duration": 0.030628,
     "end_time": "2025-07-22T09:29:44.163125",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.132497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf77915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.223510Z",
     "iopub.status.busy": "2025-07-22T09:29:44.223218Z",
     "iopub.status.idle": "2025-07-22T09:29:44.227185Z",
     "shell.execute_reply": "2025-07-22T09:29:44.226532Z"
    },
    "papermill": {
     "duration": 0.038632,
     "end_time": "2025-07-22T09:29:44.228125",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.189493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5439cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.301497Z",
     "iopub.status.busy": "2025-07-22T09:29:44.301282Z",
     "iopub.status.idle": "2025-07-22T09:29:44.304713Z",
     "shell.execute_reply": "2025-07-22T09:29:44.304115Z"
    },
    "papermill": {
     "duration": 0.038815,
     "end_time": "2025-07-22T09:29:44.305730",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.266915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[features for features in train_df.columns if train_df[features].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f7538a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.361980Z",
     "iopub.status.busy": "2025-07-22T09:29:44.361784Z",
     "iopub.status.idle": "2025-07-22T09:29:44.364831Z",
     "shell.execute_reply": "2025-07-22T09:29:44.364242Z"
    },
    "papermill": {
     "duration": 0.031121,
     "end_time": "2025-07-22T09:29:44.365931",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.334810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[features for features in test_df.columns if test_df[features].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb000cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.429152Z",
     "iopub.status.busy": "2025-07-22T09:29:44.428616Z",
     "iopub.status.idle": "2025-07-22T09:29:44.432087Z",
     "shell.execute_reply": "2025-07-22T09:29:44.431470Z"
    },
    "papermill": {
     "duration": 0.034806,
     "end_time": "2025-07-22T09:29:44.433396",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.398590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# missing_counts = test_df.isnull().sum()\n",
    "# missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
    "# print(missing_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e618935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.494510Z",
     "iopub.status.busy": "2025-07-22T09:29:44.494312Z",
     "iopub.status.idle": "2025-07-22T09:29:44.692141Z",
     "shell.execute_reply": "2025-07-22T09:29:44.691380Z"
    },
    "papermill": {
     "duration": 0.226637,
     "end_time": "2025-07-22T09:29:44.693679",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.467042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trafficSource.adContent                         0.974462\n",
       "trafficSource.adwordsClickInfo.slot             0.963102\n",
       "trafficSource.adwordsClickInfo.adNetworkType    0.963102\n",
       "trafficSource.adwordsClickInfo.isVideoAd        0.963102\n",
       "trafficSource.adwordsClickInfo.page             0.963102\n",
       "trafficSource.referralPath                      0.631849\n",
       "trafficSource.isTrueDirect                      0.630332\n",
       "trafficSource.keyword                           0.619369\n",
       "totals.bounces                                  0.593632\n",
       "new_visits                                      0.306017\n",
       "pageViews                                       0.000069\n",
       "device.screenResolution                         0.000000\n",
       "trafficSource.campaign                          0.000000\n",
       "browser                                         0.000000\n",
       "purchaseValue                                   0.000000\n",
       "screenSize                                      0.000000\n",
       "geoCluster                                      0.000000\n",
       "device.mobileDeviceBranding                     0.000000\n",
       "device.mobileInputSelector                      0.000000\n",
       "userId                                          0.000000\n",
       "geoNetwork.region                               0.000000\n",
       "device.flashVersion                             0.000000\n",
       "sessionNumber                                   0.000000\n",
       "device.operatingSystemVersion                   0.000000\n",
       "gclIdPresent                                    0.000000\n",
       "geoNetwork.networkDomain                        0.000000\n",
       "device.mobileDeviceMarketingName                0.000000\n",
       "trafficSource                                   0.000000\n",
       "trafficSource.medium                            0.000000\n",
       "geoNetwork.subContinent                         0.000000\n",
       "locationCountry                                 0.000000\n",
       "browserMajor                                    0.000000\n",
       "sessionId                                       0.000000\n",
       "os                                              0.000000\n",
       "geoNetwork.networkLocation                      0.000000\n",
       "totals.visits                                   0.000000\n",
       "geoNetwork.metro                                0.000000\n",
       "geoNetwork.city                                 0.000000\n",
       "socialEngagementType                            0.000000\n",
       "device.browserSize                              0.000000\n",
       "device.mobileDeviceModel                        0.000000\n",
       "date                                            0.000000\n",
       "device.language                                 0.000000\n",
       "locationZone                                    0.000000\n",
       "deviceType                                      0.000000\n",
       "userChannel                                     0.000000\n",
       "totalHits                                       0.000000\n",
       "device.browserVersion                           0.000000\n",
       "device.screenColors                             0.000000\n",
       "sessionStart                                    0.000000\n",
       "geoNetwork.continent                            0.000000\n",
       "device.isMobile                                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_df.isna().mean().sort_values(ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36fb7958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.754313Z",
     "iopub.status.busy": "2025-07-22T09:29:44.754053Z",
     "iopub.status.idle": "2025-07-22T09:29:44.757163Z",
     "shell.execute_reply": "2025-07-22T09:29:44.756504Z"
    },
    "papermill": {
     "duration": 0.03194,
     "end_time": "2025-07-22T09:29:44.758579",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.726639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# missing_counts = train_df.isnull().sum()\n",
    "# missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
    "# print(missing_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b9fe78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.818339Z",
     "iopub.status.busy": "2025-07-22T09:29:44.818131Z",
     "iopub.status.idle": "2025-07-22T09:29:44.867825Z",
     "shell.execute_reply": "2025-07-22T09:29:44.867112Z"
    },
    "papermill": {
     "duration": 0.07801,
     "end_time": "2025-07-22T09:29:44.868942",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.790932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of sparse columns to drop\n",
    "sparse_cols_to_drop = [\n",
    "    'trafficSource.adContent',\n",
    "    'trafficSource.adwordsClickInfo.slot',\n",
    "    'trafficSource.adwordsClickInfo.isVideoAd',\n",
    "    'trafficSource.adwordsClickInfo.adNetworkType',\n",
    "    'trafficSource.adwordsClickInfo.page'\n",
    "       \n",
    "]\n",
    "\n",
    "# Drop from train set\n",
    "train_df.drop(columns=sparse_cols_to_drop, inplace=True)\n",
    "\n",
    "# If you have test_df as well, drop from it too\n",
    "test_df.drop(columns=sparse_cols_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f06bdba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:44.924651Z",
     "iopub.status.busy": "2025-07-22T09:29:44.924436Z",
     "iopub.status.idle": "2025-07-22T09:29:45.141824Z",
     "shell.execute_reply": "2025-07-22T09:29:45.141025Z"
    },
    "papermill": {
     "duration": 0.246031,
     "end_time": "2025-07-22T09:29:45.143224",
     "exception": false,
     "start_time": "2025-07-22T09:29:44.897193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with only 1 unique value:\n",
      "['device.screenResolution', 'screenSize', 'device.mobileDeviceBranding', 'device.mobileInputSelector', 'device.mobileDeviceMarketingName', 'device.operatingSystemVersion', 'device.flashVersion', 'totals.visits', 'geoNetwork.networkLocation', 'browserMajor', 'device.browserSize', 'socialEngagementType', 'locationZone', 'device.mobileDeviceModel', 'device.language', 'device.browserVersion', 'device.screenColors']\n"
     ]
    }
   ],
   "source": [
    "# Show columns with only 1 unique value\n",
    "single_value_cols = [col for col in train_df.columns if train_df[col].nunique(dropna=False) == 1]\n",
    "\n",
    "# Display result\n",
    "print(\"Columns with only 1 unique value:\")\n",
    "print(single_value_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fb1d25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:45.203960Z",
     "iopub.status.busy": "2025-07-22T09:29:45.203749Z",
     "iopub.status.idle": "2025-07-22T09:29:45.242102Z",
     "shell.execute_reply": "2025-07-22T09:29:45.241340Z"
    },
    "papermill": {
     "duration": 0.06707,
     "end_time": "2025-07-22T09:29:45.243509",
     "exception": false,
     "start_time": "2025-07-22T09:29:45.176439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.drop(columns=single_value_cols, inplace=True)\n",
    "test_df.drop(columns=single_value_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e194d75f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:45.304986Z",
     "iopub.status.busy": "2025-07-22T09:29:45.304772Z",
     "iopub.status.idle": "2025-07-22T09:29:45.322967Z",
     "shell.execute_reply": "2025-07-22T09:29:45.322335Z"
    },
    "papermill": {
     "duration": 0.047066,
     "end_time": "2025-07-22T09:29:45.323991",
     "exception": false,
     "start_time": "2025-07-22T09:29:45.276925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['trafficSource.isTrueDirect'] = (\n",
    "    train_df['trafficSource.isTrueDirect']\n",
    "    .astype('boolean')  # nullable boolean type\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    "    .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c8d41fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:45.378154Z",
     "iopub.status.busy": "2025-07-22T09:29:45.377887Z",
     "iopub.status.idle": "2025-07-22T09:29:45.387170Z",
     "shell.execute_reply": "2025-07-22T09:29:45.386530Z"
    },
    "papermill": {
     "duration": 0.037201,
     "end_time": "2025-07-22T09:29:45.388153",
     "exception": false,
     "start_time": "2025-07-22T09:29:45.350952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['trafficSource.isTrueDirect'] = (\n",
    "    test_df['trafficSource.isTrueDirect']\n",
    "    .astype('boolean')  # nullable boolean type\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    "    .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fafd3edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:45.442634Z",
     "iopub.status.busy": "2025-07-22T09:29:45.442391Z",
     "iopub.status.idle": "2025-07-22T09:29:45.455604Z",
     "shell.execute_reply": "2025-07-22T09:29:45.455030Z"
    },
    "papermill": {
     "duration": 0.042094,
     "end_time": "2025-07-22T09:29:45.456650",
     "exception": false,
     "start_time": "2025-07-22T09:29:45.414556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['totals.bounces']=train_df['totals.bounces'].fillna(0).astype(int)\n",
    "train_df['new_visits']=train_df['new_visits'].fillna(0).astype(int)\n",
    "test_df['totals.bounces']=test_df['totals.bounces'].fillna(0).astype(int)\n",
    "test_df['new_visits']=test_df['new_visits'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52265a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:45.512135Z",
     "iopub.status.busy": "2025-07-22T09:29:45.511905Z",
     "iopub.status.idle": "2025-07-22T09:29:45.518102Z",
     "shell.execute_reply": "2025-07-22T09:29:45.517446Z"
    },
    "papermill": {
     "duration": 0.0363,
     "end_time": "2025-07-22T09:29:45.519331",
     "exception": false,
     "start_time": "2025-07-22T09:29:45.483031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['pageViews']=train_df['pageViews'].fillna(train_df['pageViews'].median())\n",
    "test_df['pageViews']=test_df['pageViews'].fillna(test_df['pageViews'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b246e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:45.573297Z",
     "iopub.status.busy": "2025-07-22T09:29:45.573040Z",
     "iopub.status.idle": "2025-07-22T09:29:45.577303Z",
     "shell.execute_reply": "2025-07-22T09:29:45.576819Z"
    },
    "papermill": {
     "duration": 0.032276,
     "end_time": "2025-07-22T09:29:45.578330",
     "exception": false,
     "start_time": "2025-07-22T09:29:45.546054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_and_group_categories(df, column, top_n, missing_values=None, replacement='Other'):\n",
    "    \"\"\"\n",
    "    Cleans a categorical column by:\n",
    "    - Replacing placeholder values\n",
    "    - Handling NaNs\n",
    "    - Keeping only top N frequent categories\n",
    "    - Replacing all others with a replacement value\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame.\n",
    "        column (str): Column to clean.\n",
    "        top_n (int): Number of top categories to keep.\n",
    "        missing_values (list or None): List of placeholder values to replace.\n",
    "        replacement (str): Value to replace rare or missing entries.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame.\n",
    "    \"\"\"\n",
    "    if missing_values:\n",
    "        df[column] = df[column].replace(missing_values, replacement)\n",
    "    df[column] = df[column].fillna(replacement)\n",
    "\n",
    "    top_categories = df[column].value_counts().nlargest(top_n).index\n",
    "    df[column] = df[column].apply(lambda x: x if x in top_categories else replacement)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63cde879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:45.633876Z",
     "iopub.status.busy": "2025-07-22T09:29:45.633710Z",
     "iopub.status.idle": "2025-07-22T09:29:46.617756Z",
     "shell.execute_reply": "2025-07-22T09:29:46.617198Z"
    },
    "papermill": {
     "duration": 1.013214,
     "end_time": "2025-07-22T09:29:46.619022",
     "exception": false,
     "start_time": "2025-07-22T09:29:45.605808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_clean = [\n",
    "    # Format: (column_name, top_n, missing_values, replacement)\n",
    "    ('browser', 15, ['(not set)', 'not available in demo dataset'], 'Other'),\n",
    "    ('os', 6, ['(not set)', 'not available in demo dataset'], 'Other'),\n",
    "    ('locationCountry', 10, ['(not set)', 'not available in demo dataset'], 'Unknown'),\n",
    "    ('geoNetwork.city', 10, ['(not set)', 'not available in demo dataset'], 'Unknown'),\n",
    "    ('geoNetwork.continent', 10, ['(not set)', 'not available in demo dataset'], 'Unknown'),\n",
    "    ('geoNetwork.region', 10, ['(not set)', 'not available in demo dataset'], 'Unknown'),\n",
    "    ('trafficSource.campaign', 10, None, 'Unknown'),\n",
    "    ('trafficSource.referralPath', 15, ['(not provided)'], 'Others'),\n",
    "    ('trafficSource.keyword', 20, ['(not provided)'], 'Others')  # approximation of top categories\n",
    "]\n",
    "\n",
    "for col, top_n, missing_vals, replacement in columns_to_clean:\n",
    "    train_df = clean_and_group_categories(train_df, col, top_n, missing_vals, replacement)\n",
    "    test_df = clean_and_group_categories(test_df, col, top_n, missing_vals, replacement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef91b729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:46.674936Z",
     "iopub.status.busy": "2025-07-22T09:29:46.674361Z",
     "iopub.status.idle": "2025-07-22T09:29:46.695645Z",
     "shell.execute_reply": "2025-07-22T09:29:46.695078Z"
    },
    "papermill": {
     "duration": 0.050363,
     "end_time": "2025-07-22T09:29:46.696923",
     "exception": false,
     "start_time": "2025-07-22T09:29:46.646560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_to_transform = [ 'sessionNumber', 'pageViews', 'totalHits','avg_interaction']\n",
    "\n",
    "for feature in features_to_transform:\n",
    "  # Apply log transformation (add 1 to handle zero values)\n",
    "  if feature in train_df.columns:\n",
    "    train_df[f'{feature}_log'] = np.log1p(train_df[feature])\n",
    "  if feature in test_df.columns:\n",
    "    test_df[f'{feature}_log'] = np.log1p(test_df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c662c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:46.751444Z",
     "iopub.status.busy": "2025-07-22T09:29:46.750768Z",
     "iopub.status.idle": "2025-07-22T09:29:46.754051Z",
     "shell.execute_reply": "2025-07-22T09:29:46.753562Z"
    },
    "papermill": {
     "duration": 0.03121,
     "end_time": "2025-07-22T09:29:46.755158",
     "exception": false,
     "start_time": "2025-07-22T09:29:46.723948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8831fc4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:46.808551Z",
     "iopub.status.busy": "2025-07-22T09:29:46.808383Z",
     "iopub.status.idle": "2025-07-22T09:29:46.811337Z",
     "shell.execute_reply": "2025-07-22T09:29:46.810666Z"
    },
    "papermill": {
     "duration": 0.030904,
     "end_time": "2025-07-22T09:29:46.812452",
     "exception": false,
     "start_time": "2025-07-22T09:29:46.781548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[['trafficSource.keyword','trafficSource.isTrueDirect','trafficSource.referralPath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e921eb41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:46.866562Z",
     "iopub.status.busy": "2025-07-22T09:29:46.866376Z",
     "iopub.status.idle": "2025-07-22T09:29:46.869206Z",
     "shell.execute_reply": "2025-07-22T09:29:46.868684Z"
    },
    "papermill": {
     "duration": 0.030787,
     "end_time": "2025-07-22T09:29:46.870142",
     "exception": false,
     "start_time": "2025-07-22T09:29:46.839355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a762c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:46.924159Z",
     "iopub.status.busy": "2025-07-22T09:29:46.923943Z",
     "iopub.status.idle": "2025-07-22T09:29:46.926996Z",
     "shell.execute_reply": "2025-07-22T09:29:46.926328Z"
    },
    "papermill": {
     "duration": 0.030825,
     "end_time": "2025-07-22T09:29:46.928054",
     "exception": false,
     "start_time": "2025-07-22T09:29:46.897229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Get top 10 keywords\n",
    "# top_keywords = train_df['trafficSource.keyword'].value_counts().head(10).reset_index()\n",
    "# top_keywords.columns = ['keyword', 'count']\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(data=top_keywords, x='keyword', y='count', palette='viridis')\n",
    "\n",
    "# plt.title('Top 10 Keywords in trafficSource.keyword')\n",
    "# plt.xlabel('Keyword')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65ed140a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:46.981856Z",
     "iopub.status.busy": "2025-07-22T09:29:46.981652Z",
     "iopub.status.idle": "2025-07-22T09:29:46.984530Z",
     "shell.execute_reply": "2025-07-22T09:29:46.983872Z"
    },
    "papermill": {
     "duration": 0.030836,
     "end_time": "2025-07-22T09:29:46.985522",
     "exception": false,
     "start_time": "2025-07-22T09:29:46.954686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.keyword'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8334bc52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.039524Z",
     "iopub.status.busy": "2025-07-22T09:29:47.039056Z",
     "iopub.status.idle": "2025-07-22T09:29:47.042254Z",
     "shell.execute_reply": "2025-07-22T09:29:47.041597Z"
    },
    "papermill": {
     "duration": 0.030876,
     "end_time": "2025-07-22T09:29:47.043324",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.012448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Step 1: Replace '(not provided)' and NaN with 'Others'\n",
    "# train_df['trafficSource.keyword'] = train_df['trafficSource.keyword'].replace('(not provided)', 'Others')\n",
    "# train_df['trafficSource.keyword'] = train_df['trafficSource.keyword'].fillna('Others')\n",
    "\n",
    "# # Step 2: Count keyword frequencies after above replacement\n",
    "# keyword_counts = train_df['trafficSource.keyword'].value_counts()\n",
    "\n",
    "# # Step 3: Replace low-frequency keywords (<50) with 'Others'\n",
    "# train_df['trafficSource.keyword'] = train_df['trafficSource.keyword'].apply(\n",
    "#     lambda x: x if keyword_counts.get(x, 0) >= 50 else 'Others'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82e4876c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.096541Z",
     "iopub.status.busy": "2025-07-22T09:29:47.096358Z",
     "iopub.status.idle": "2025-07-22T09:29:47.099045Z",
     "shell.execute_reply": "2025-07-22T09:29:47.098591Z"
    },
    "papermill": {
     "duration": 0.030332,
     "end_time": "2025-07-22T09:29:47.100013",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.069681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Step 1: Replace '(not provided)' and NaN with 'Others' in test_df\n",
    "# test_df['trafficSource.keyword'] = test_df['trafficSource.keyword'].replace('(not provided)', 'Others')\n",
    "# test_df['trafficSource.keyword'] = test_df['trafficSource.keyword'].fillna('Others')\n",
    "\n",
    "# # Step 2: Use the keyword_counts from train_df to replace low-frequency keywords with 'Others' in test_df\n",
    "# test_df['trafficSource.keyword'] = test_df['trafficSource.keyword'].apply(\n",
    "#     lambda x: x if keyword_counts.get(x, 0) >= 50 else 'Others'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6180124a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.153459Z",
     "iopub.status.busy": "2025-07-22T09:29:47.153293Z",
     "iopub.status.idle": "2025-07-22T09:29:47.156422Z",
     "shell.execute_reply": "2025-07-22T09:29:47.155761Z"
    },
    "papermill": {
     "duration": 0.030981,
     "end_time": "2025-07-22T09:29:47.157535",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.126554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_counts = train_df['trafficSource.keyword'].value_counts().reset_index()\n",
    "# final_counts.columns = ['keyword', 'count']\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(data=final_counts, x='keyword', y='count', palette='Set2')\n",
    "\n",
    "# plt.title('trafficSource.keyword (Grouped with Others)')\n",
    "# plt.xlabel('Keyword')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "befc52fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.210891Z",
     "iopub.status.busy": "2025-07-22T09:29:47.210697Z",
     "iopub.status.idle": "2025-07-22T09:29:47.213464Z",
     "shell.execute_reply": "2025-07-22T09:29:47.212964Z"
    },
    "papermill": {
     "duration": 0.03059,
     "end_time": "2025-07-22T09:29:47.214512",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.183922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_counts = test_df['trafficSource.keyword'].value_counts().reset_index()\n",
    "# final_counts.columns = ['keyword', 'count']\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(data=final_counts, x='keyword', y='count', palette='Set2')\n",
    "\n",
    "# plt.title('trafficSource.keyword (Grouped with Others)')\n",
    "# plt.xlabel('Keyword')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "526503c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.268524Z",
     "iopub.status.busy": "2025-07-22T09:29:47.268363Z",
     "iopub.status.idle": "2025-07-22T09:29:47.271227Z",
     "shell.execute_reply": "2025-07-22T09:29:47.270575Z"
    },
    "papermill": {
     "duration": 0.030736,
     "end_time": "2025-07-22T09:29:47.272230",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.241494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc3554c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.326405Z",
     "iopub.status.busy": "2025-07-22T09:29:47.326211Z",
     "iopub.status.idle": "2025-07-22T09:29:47.328714Z",
     "shell.execute_reply": "2025-07-22T09:29:47.328277Z"
    },
    "papermill": {
     "duration": 0.031014,
     "end_time": "2025-07-22T09:29:47.329671",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.298657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02170949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.383338Z",
     "iopub.status.busy": "2025-07-22T09:29:47.382774Z",
     "iopub.status.idle": "2025-07-22T09:29:47.385595Z",
     "shell.execute_reply": "2025-07-22T09:29:47.385128Z"
    },
    "papermill": {
     "duration": 0.030429,
     "end_time": "2025-07-22T09:29:47.386571",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.356142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['trafficSource.keyword'] = train_df['trafficSource.keyword'].fillna('unknown')\n",
    "# train_df['trafficSource.isTrueDirect'] = train_df['trafficSource.isTrueDirect'].fillna('unknown')\n",
    "# train_df['trafficSource.referralPath'] = train_df['trafficSource.referralPath'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d3dfa43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.440170Z",
     "iopub.status.busy": "2025-07-22T09:29:47.439953Z",
     "iopub.status.idle": "2025-07-22T09:29:47.442549Z",
     "shell.execute_reply": "2025-07-22T09:29:47.442058Z"
    },
    "papermill": {
     "duration": 0.030647,
     "end_time": "2025-07-22T09:29:47.443541",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.412894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.isTrueDirect'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e0a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:54:19.345450Z",
     "iopub.status.busy": "2025-07-22T07:54:19.344862Z",
     "iopub.status.idle": "2025-07-22T07:54:19.362241Z",
     "shell.execute_reply": "2025-07-22T07:54:19.361532Z",
     "shell.execute_reply.started": "2025-07-22T07:54:19.345425Z"
    },
    "papermill": {
     "duration": 0.026308,
     "end_time": "2025-07-22T09:29:47.496374",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.470066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a76fec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:05:43.464157Z",
     "iopub.status.busy": "2025-07-22T09:05:43.463647Z",
     "iopub.status.idle": "2025-07-22T09:05:43.474180Z",
     "shell.execute_reply": "2025-07-22T09:05:43.473339Z",
     "shell.execute_reply.started": "2025-07-22T09:05:43.464131Z"
    },
    "papermill": {
     "duration": 0.026064,
     "end_time": "2025-07-22T09:29:47.548552",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.522488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6f1826b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.602714Z",
     "iopub.status.busy": "2025-07-22T09:29:47.602522Z",
     "iopub.status.idle": "2025-07-22T09:29:47.605422Z",
     "shell.execute_reply": "2025-07-22T09:29:47.604771Z"
    },
    "papermill": {
     "duration": 0.031792,
     "end_time": "2025-07-22T09:29:47.606412",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.574620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.isTrueDirect'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edafccbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.660164Z",
     "iopub.status.busy": "2025-07-22T09:29:47.659652Z",
     "iopub.status.idle": "2025-07-22T09:29:47.662626Z",
     "shell.execute_reply": "2025-07-22T09:29:47.661956Z"
    },
    "papermill": {
     "duration": 0.030962,
     "end_time": "2025-07-22T09:29:47.663829",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.632867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df['trafficSource.isTrueDirect'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f884150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.718165Z",
     "iopub.status.busy": "2025-07-22T09:29:47.717954Z",
     "iopub.status.idle": "2025-07-22T09:29:47.720544Z",
     "shell.execute_reply": "2025-07-22T09:29:47.720059Z"
    },
    "papermill": {
     "duration": 0.030819,
     "end_time": "2025-07-22T09:29:47.721548",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.690729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df['trafficSource.isTrueDirect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8b7b1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.776522Z",
     "iopub.status.busy": "2025-07-22T09:29:47.776357Z",
     "iopub.status.idle": "2025-07-22T09:29:47.779007Z",
     "shell.execute_reply": "2025-07-22T09:29:47.778542Z"
    },
    "papermill": {
     "duration": 0.031135,
     "end_time": "2025-07-22T09:29:47.780005",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.748870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.referralPath'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d533c239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.833568Z",
     "iopub.status.busy": "2025-07-22T09:29:47.833405Z",
     "iopub.status.idle": "2025-07-22T09:29:47.836021Z",
     "shell.execute_reply": "2025-07-22T09:29:47.835548Z"
    },
    "papermill": {
     "duration": 0.030598,
     "end_time": "2025-07-22T09:29:47.837052",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.806454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.referralPath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ff48e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.890440Z",
     "iopub.status.busy": "2025-07-22T09:29:47.890249Z",
     "iopub.status.idle": "2025-07-22T09:29:47.893333Z",
     "shell.execute_reply": "2025-07-22T09:29:47.892700Z"
    },
    "papermill": {
     "duration": 0.031136,
     "end_time": "2025-07-22T09:29:47.894413",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.863277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Set threshold\n",
    "# min_count = 50\n",
    "# train_df['trafficSource.referralPath'] = train_df['trafficSource.referralPath'].replace('(not provided)', 'Others')\n",
    "# train_df['trafficSource.referralPath'] = train_df['trafficSource.referralPath'].fillna('Others')\n",
    "# # Get counts\n",
    "# referral_counts = train_df['trafficSource.referralPath'].value_counts()\n",
    "\n",
    "# # Referral paths with counts >= min_count\n",
    "# valid_referrals = referral_counts[referral_counts >= min_count].index\n",
    "\n",
    "# # Replace low-frequency referral paths with 'Others'\n",
    "# train_df['trafficSource.referralPath'] = train_df['trafficSource.referralPath'].apply(\n",
    "#     lambda x: x if x in valid_referrals else 'Others'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "705260c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:47.948321Z",
     "iopub.status.busy": "2025-07-22T09:29:47.948151Z",
     "iopub.status.idle": "2025-07-22T09:29:47.950732Z",
     "shell.execute_reply": "2025-07-22T09:29:47.950265Z"
    },
    "papermill": {
     "duration": 0.030917,
     "end_time": "2025-07-22T09:29:47.951823",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.920906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Fill NaNs in test_df\n",
    "# test_df['trafficSource.referralPath'] = test_df['trafficSource.referralPath'].fillna('Others')\n",
    "\n",
    "# # Replace low-frequency referral paths in test_df using valid_referrals from train_df\n",
    "# test_df['trafficSource.referralPath'] = test_df['trafficSource.referralPath'].apply(\n",
    "#     lambda x: x if x in valid_referrals else 'Others'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc79a031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.005506Z",
     "iopub.status.busy": "2025-07-22T09:29:48.005331Z",
     "iopub.status.idle": "2025-07-22T09:29:48.008063Z",
     "shell.execute_reply": "2025-07-22T09:29:48.007566Z"
    },
    "papermill": {
     "duration": 0.030836,
     "end_time": "2025-07-22T09:29:48.009017",
     "exception": false,
     "start_time": "2025-07-22T09:29:47.978181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.referralPath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7888f688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.062232Z",
     "iopub.status.busy": "2025-07-22T09:29:48.062021Z",
     "iopub.status.idle": "2025-07-22T09:29:48.064736Z",
     "shell.execute_reply": "2025-07-22T09:29:48.064252Z"
    },
    "papermill": {
     "duration": 0.030315,
     "end_time": "2025-07-22T09:29:48.065668",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.035353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df['trafficSource.referralPath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd700c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.160651Z",
     "iopub.status.busy": "2025-07-22T09:29:48.160152Z",
     "iopub.status.idle": "2025-07-22T09:29:48.162948Z",
     "shell.execute_reply": "2025-07-22T09:29:48.162449Z"
    },
    "papermill": {
     "duration": 0.071751,
     "end_time": "2025-07-22T09:29:48.163979",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.092228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[['trafficSource.referralPath']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556504b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:05:47.294642Z",
     "iopub.status.busy": "2025-07-22T09:05:47.294353Z",
     "iopub.status.idle": "2025-07-22T09:05:47.308007Z",
     "shell.execute_reply": "2025-07-22T09:05:47.307219Z",
     "shell.execute_reply.started": "2025-07-22T09:05:47.294620Z"
    },
    "papermill": {
     "duration": 0.026397,
     "end_time": "2025-07-22T09:29:48.217364",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.190967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4ed77c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.271475Z",
     "iopub.status.busy": "2025-07-22T09:29:48.271276Z",
     "iopub.status.idle": "2025-07-22T09:29:48.399377Z",
     "shell.execute_reply": "2025-07-22T09:29:48.398478Z"
    },
    "papermill": {
     "duration": 0.156738,
     "end_time": "2025-07-22T09:29:48.400718",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.243980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with outliers and the number of rows to be deleted:\n",
      "- purchaseValue: 23985 rows\n",
      "- gclIdPresent: 4295 rows\n",
      "- sessionNumber: 14116 rows\n",
      "- pageViews: 12419 rows\n",
      "- totalHits: 13154 rows\n",
      "- sessionNumber_log: 10347 rows\n",
      "- pageViews_log: 71 rows\n",
      "- totalHits_log: 68 rows\n",
      "\n",
      "Total rows to be deleted if all outliers are removed: 78455\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_outliers_iqr(df, column):\n",
    "  \"\"\"Finds outliers in a column using the Interquartile Range (IQR) method.\"\"\"\n",
    "  q1 = df[column].quantile(0.25)\n",
    "  q3 = df[column].quantile(0.75)\n",
    "  iqr = q3 - q1\n",
    "  lower_bound = q1 - 1.5 * iqr\n",
    "  upper_bound = q3 + 1.5 * iqr\n",
    "  outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "  return outliers\n",
    "\n",
    "outliers_info = {}\n",
    "total_rows_to_delete = 0\n",
    "\n",
    "# Consider only numerical columns for outlier detection\n",
    "numerical_cols = train_df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "for col in numerical_cols:\n",
    "  outliers = find_outliers_iqr(train_df, col)\n",
    "  if not outliers.empty:\n",
    "    outliers_info[col] = len(outliers)\n",
    "    total_rows_to_delete += len(outliers)\n",
    "\n",
    "if outliers_info:\n",
    "  print(\"\\nColumns with outliers and the number of rows to be deleted:\")\n",
    "  for col, count in outliers_info.items():\n",
    "    print(f\"- {col}: {count} rows\")\n",
    "  print(f\"\\nTotal rows to be deleted if all outliers are removed: {total_rows_to_delete}\")\n",
    "else:\n",
    "  print(\"\\nNo significant outliers found in numerical columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a5d3198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.457953Z",
     "iopub.status.busy": "2025-07-22T09:29:48.457733Z",
     "iopub.status.idle": "2025-07-22T09:29:48.571565Z",
     "shell.execute_reply": "2025-07-22T09:29:48.570439Z"
    },
    "papermill": {
     "duration": 0.142532,
     "end_time": "2025-07-22T09:29:48.572951",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.430419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Range of outliers (based on 1.5*IQR) for each numerical feature:\n",
      "- trafficSource.isTrueDirect: No outliers detected based on the 1.5*IQR rule.\n",
      "- purchaseValue: Outliers below 0.00 and above 0.00. Outlier range observed: [10000.00, 23129500000.00]\n",
      "- userId: No outliers detected based on the 1.5*IQR rule.\n",
      "- gclIdPresent: Outliers below 0.00 and above 0.00. Outlier range observed: [1.00, 1.00]\n",
      "- sessionNumber: Outliers below -0.50 and above 3.50. Outlier range observed: [4.00, 447.00]\n",
      "- sessionId: No outliers detected based on the 1.5*IQR rule.\n",
      "- pageViews: Outliers below -12.50 and above 23.50. Outlier range observed: [24.00, 469.00]\n",
      "- totals.bounces: No outliers detected based on the 1.5*IQR rule.\n",
      "- date: No outliers detected based on the 1.5*IQR rule.\n",
      "- totalHits: Outliers below -15.50 and above 28.50. Outlier range observed: [29.00, 500.00]\n",
      "- sessionStart: No outliers detected based on the 1.5*IQR rule.\n",
      "- new_visits: No outliers detected based on the 1.5*IQR rule.\n",
      "- sessionNumber_log: Outliers below 0.08 and above 1.71. Outlier range observed: [1.79, 6.10]\n",
      "- pageViews_log: Outliers below -1.86 and above 4.96. Outlier range observed: [4.97, 6.15]\n",
      "- totalHits_log: Outliers below -2.11 and above 5.37. Outlier range observed: [5.38, 6.22]\n"
     ]
    }
   ],
   "source": [
    "def print_outlier_ranges_iqr(df):\n",
    "  \"\"\"Prints the range of outliers for each numerical column using the IQR method.\"\"\"\n",
    "  numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "  print(\"\\nRange of outliers (based on 1.5*IQR) for each numerical feature:\")\n",
    "\n",
    "  for col in numerical_cols:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "    if not outliers.empty:\n",
    "      min_outlier = outliers[col].min()\n",
    "      max_outlier = outliers[col].max()\n",
    "      print(f\"- {col}: Outliers below {lower_bound:.2f} and above {upper_bound:.2f}. Outlier range observed: [{min_outlier:.2f}, {max_outlier:.2f}]\")\n",
    "    else:\n",
    "      print(f\"- {col}: No outliers detected based on the 1.5*IQR rule.\")\n",
    "\n",
    "print_outlier_ranges_iqr(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47836952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.630941Z",
     "iopub.status.busy": "2025-07-22T09:29:48.630704Z",
     "iopub.status.idle": "2025-07-22T09:29:48.633672Z",
     "shell.execute_reply": "2025-07-22T09:29:48.633177Z"
    },
    "papermill": {
     "duration": 0.032393,
     "end_time": "2025-07-22T09:29:48.634801",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.602408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['totals.bounces'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaf1ca32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.692816Z",
     "iopub.status.busy": "2025-07-22T09:29:48.692620Z",
     "iopub.status.idle": "2025-07-22T09:29:48.695794Z",
     "shell.execute_reply": "2025-07-22T09:29:48.695106Z"
    },
    "papermill": {
     "duration": 0.033444,
     "end_time": "2025-07-22T09:29:48.696796",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.663352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['new_visits'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523350d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T05:54:24.550250Z",
     "iopub.status.busy": "2025-07-20T05:54:24.549792Z",
     "iopub.status.idle": "2025-07-20T05:54:24.555864Z",
     "shell.execute_reply": "2025-07-20T05:54:24.555366Z",
     "shell.execute_reply.started": "2025-07-20T05:54:24.550228Z"
    },
    "papermill": {
     "duration": 0.026406,
     "end_time": "2025-07-22T09:29:48.752214",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.725808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2028a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.806105Z",
     "iopub.status.busy": "2025-07-22T09:29:48.805881Z",
     "iopub.status.idle": "2025-07-22T09:29:48.808844Z",
     "shell.execute_reply": "2025-07-22T09:29:48.808197Z"
    },
    "papermill": {
     "duration": 0.031193,
     "end_time": "2025-07-22T09:29:48.809882",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.778689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df['new_visits'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d80b39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:05:53.286729Z",
     "iopub.status.busy": "2025-07-22T09:05:53.286116Z",
     "iopub.status.idle": "2025-07-22T09:05:53.294923Z",
     "shell.execute_reply": "2025-07-22T09:05:53.294226Z",
     "shell.execute_reply.started": "2025-07-22T09:05:53.286702Z"
    },
    "papermill": {
     "duration": 0.027277,
     "end_time": "2025-07-22T09:29:48.863888",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.836611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98588f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T08:10:07.950139Z",
     "iopub.status.busy": "2025-07-17T08:10:07.949888Z",
     "iopub.status.idle": "2025-07-17T08:10:07.954764Z",
     "shell.execute_reply": "2025-07-17T08:10:07.954231Z",
     "shell.execute_reply.started": "2025-07-17T08:10:07.950121Z"
    },
    "papermill": {
     "duration": 0.026605,
     "end_time": "2025-07-22T09:29:48.917105",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.890500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63fa91e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:48.970866Z",
     "iopub.status.busy": "2025-07-22T09:29:48.970671Z",
     "iopub.status.idle": "2025-07-22T09:29:48.973222Z",
     "shell.execute_reply": "2025-07-22T09:29:48.972748Z"
    },
    "papermill": {
     "duration": 0.030827,
     "end_time": "2025-07-22T09:29:48.974215",
     "exception": false,
     "start_time": "2025-07-22T09:29:48.943388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2fe87906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.028238Z",
     "iopub.status.busy": "2025-07-22T09:29:49.028012Z",
     "iopub.status.idle": "2025-07-22T09:29:49.031000Z",
     "shell.execute_reply": "2025-07-22T09:29:49.030354Z"
    },
    "papermill": {
     "duration": 0.031015,
     "end_time": "2025-07-22T09:29:49.032046",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.001031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69c20ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.086429Z",
     "iopub.status.busy": "2025-07-22T09:29:49.086235Z",
     "iopub.status.idle": "2025-07-22T09:29:49.088835Z",
     "shell.execute_reply": "2025-07-22T09:29:49.088373Z"
    },
    "papermill": {
     "duration": 0.030891,
     "end_time": "2025-07-22T09:29:49.089805",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.058914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dcfbd26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.144171Z",
     "iopub.status.busy": "2025-07-22T09:29:49.143966Z",
     "iopub.status.idle": "2025-07-22T09:29:49.146565Z",
     "shell.execute_reply": "2025-07-22T09:29:49.146100Z"
    },
    "papermill": {
     "duration": 0.031158,
     "end_time": "2025-07-22T09:29:49.147599",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.116441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5cf93efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.201859Z",
     "iopub.status.busy": "2025-07-22T09:29:49.201663Z",
     "iopub.status.idle": "2025-07-22T09:29:49.204676Z",
     "shell.execute_reply": "2025-07-22T09:29:49.204016Z"
    },
    "papermill": {
     "duration": 0.031375,
     "end_time": "2025-07-22T09:29:49.205752",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.174377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.histplot(data=train_df, x='purchaseValue', bins=100, kde=True)\n",
    "# plt.title('Distribution of Purchase Value')\n",
    "# plt.xlabel('Purchase Value')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "840af441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.259778Z",
     "iopub.status.busy": "2025-07-22T09:29:49.259593Z",
     "iopub.status.idle": "2025-07-22T09:29:49.262774Z",
     "shell.execute_reply": "2025-07-22T09:29:49.262112Z"
    },
    "papermill": {
     "duration": 0.031329,
     "end_time": "2025-07-22T09:29:49.263793",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.232464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Calculate 0.5 and 99.5 percentiles\n",
    "# lower_bound = np.percentile(train_df['purchaseValue'], 0.5)\n",
    "# upper_bound = np.percentile(train_df['purchaseValue'], 95)\n",
    "\n",
    "# # Filter the central 99% of data\n",
    "# filtered_data = train_df[\n",
    "#     (train_df['purchaseValue'] >= lower_bound) & \n",
    "#     (train_df['purchaseValue'] <= upper_bound)\n",
    "# ]\n",
    "\n",
    "# # Plot the filtered distribution\n",
    "# sns.histplot(data=filtered_data, x='purchaseValue', bins=100, kde=True)\n",
    "# plt.title('Distribution of Purchase Value (Central 99%)')\n",
    "# plt.xlabel('Purchase Value')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01e4f5dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.318041Z",
     "iopub.status.busy": "2025-07-22T09:29:49.317585Z",
     "iopub.status.idle": "2025-07-22T09:29:49.320235Z",
     "shell.execute_reply": "2025-07-22T09:29:49.319734Z"
    },
    "papermill": {
     "duration": 0.030939,
     "end_time": "2025-07-22T09:29:49.321265",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.290326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.boxplot(data=train_df, x='purchaseValue')\n",
    "# plt.title('Boxplot of Purchase Value')\n",
    "# plt.xlabel('Purchase Value')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9a9ae11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.376249Z",
     "iopub.status.busy": "2025-07-22T09:29:49.376034Z",
     "iopub.status.idle": "2025-07-22T09:29:49.378649Z",
     "shell.execute_reply": "2025-07-22T09:29:49.378134Z"
    },
    "papermill": {
     "duration": 0.031058,
     "end_time": "2025-07-22T09:29:49.379723",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.348665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.boxplot(data=train_df, x=np.log1p(train_df['purchaseValue']))\n",
    "# plt.title(\"Boxplot of Log-Transformed Purchase Value\")\n",
    "# plt.xlabel(\"Log(Purchase Value + 1)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0351485c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.434867Z",
     "iopub.status.busy": "2025-07-22T09:29:49.434703Z",
     "iopub.status.idle": "2025-07-22T09:29:49.437730Z",
     "shell.execute_reply": "2025-07-22T09:29:49.437011Z"
    },
    "papermill": {
     "duration": 0.031718,
     "end_time": "2025-07-22T09:29:49.438829",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.407111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.violinplot(data=train_df, x='purchaseValue')\n",
    "# plt.title('Violin Plot of Purchase Value')\n",
    "# plt.xlabel('Purchase Value')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49fdd2be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.493950Z",
     "iopub.status.busy": "2025-07-22T09:29:49.493767Z",
     "iopub.status.idle": "2025-07-22T09:29:49.496744Z",
     "shell.execute_reply": "2025-07-22T09:29:49.496118Z"
    },
    "papermill": {
     "duration": 0.031369,
     "end_time": "2025-07-22T09:29:49.497810",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.466441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Histogram for pageViews\n",
    "# sns.histplot(data=train_df, x='pageViews', bins=50, kde=True)\n",
    "# plt.title('Distribution of Page Views')\n",
    "# plt.show()\n",
    "\n",
    "# # Histogram for totalHits\n",
    "# sns.histplot(data=train_df, x='totalHits', bins=50, kde=True)\n",
    "# plt.title('Distribution of Total Hits')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "377464a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.552214Z",
     "iopub.status.busy": "2025-07-22T09:29:49.552010Z",
     "iopub.status.idle": "2025-07-22T09:29:49.554718Z",
     "shell.execute_reply": "2025-07-22T09:29:49.554268Z"
    },
    "papermill": {
     "duration": 0.031133,
     "end_time": "2025-07-22T09:29:49.555676",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.524543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Histogram for pageViews > 0\n",
    "# sns.histplot(data=train_df[train_df['pageViews'] > 1], x='pageViews', bins=50, kde=True)\n",
    "# plt.title('Distribution of Page Views (pageViews > 1)')\n",
    "# plt.show()\n",
    "\n",
    "# # Histogram for totalHits > 0\n",
    "# sns.histplot(data=train_df[train_df['totalHits'] > 1], x='totalHits', bins=50, kde=True)\n",
    "# plt.title('Distribution of Total Hits (totalHits > 1)')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4459ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.610964Z",
     "iopub.status.busy": "2025-07-22T09:29:49.610801Z",
     "iopub.status.idle": "2025-07-22T09:29:49.613492Z",
     "shell.execute_reply": "2025-07-22T09:29:49.612992Z"
    },
    "papermill": {
     "duration": 0.032316,
     "end_time": "2025-07-22T09:29:49.614482",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.582166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['pageViews'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "540d9fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.668800Z",
     "iopub.status.busy": "2025-07-22T09:29:49.668636Z",
     "iopub.status.idle": "2025-07-22T09:29:49.671452Z",
     "shell.execute_reply": "2025-07-22T09:29:49.670945Z"
    },
    "papermill": {
     "duration": 0.031286,
     "end_time": "2025-07-22T09:29:49.672401",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.641115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Boxplot for pageViews\n",
    "# sns.boxplot(data=train_df, x='pageViews')\n",
    "# plt.title('Boxplot of Page Views')\n",
    "# plt.show()\n",
    "\n",
    "# # Boxplot for totalHits\n",
    "# sns.boxplot(data=train_df, x='totalHits')\n",
    "# plt.title('Boxplot of Total Hits')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d545c010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.726934Z",
     "iopub.status.busy": "2025-07-22T09:29:49.726531Z",
     "iopub.status.idle": "2025-07-22T09:29:49.730398Z",
     "shell.execute_reply": "2025-07-22T09:29:49.729605Z"
    },
    "papermill": {
     "duration": 0.033341,
     "end_time": "2025-07-22T09:29:49.732269",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.698928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['totalHits'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b3ce95e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.801407Z",
     "iopub.status.busy": "2025-07-22T09:29:49.800997Z",
     "iopub.status.idle": "2025-07-22T09:29:49.803783Z",
     "shell.execute_reply": "2025-07-22T09:29:49.803303Z"
    },
    "papermill": {
     "duration": 0.031511,
     "end_time": "2025-07-22T09:29:49.804677",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.773166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['totalHits'].value_counts()[train_df['totalHits'].value_counts() > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11b1c5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.859189Z",
     "iopub.status.busy": "2025-07-22T09:29:49.858762Z",
     "iopub.status.idle": "2025-07-22T09:29:49.861481Z",
     "shell.execute_reply": "2025-07-22T09:29:49.860975Z"
    },
    "papermill": {
     "duration": 0.030659,
     "end_time": "2025-07-22T09:29:49.862535",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.831876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vc = train_df['totalHits'].value_counts()\n",
    "# vc[(vc >= 1) & (vc <= 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e78aa009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.916390Z",
     "iopub.status.busy": "2025-07-22T09:29:49.916189Z",
     "iopub.status.idle": "2025-07-22T09:29:49.919496Z",
     "shell.execute_reply": "2025-07-22T09:29:49.918751Z"
    },
    "papermill": {
     "duration": 0.031373,
     "end_time": "2025-07-22T09:29:49.920481",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.889108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Violin plot for pageViews\n",
    "# sns.violinplot(data=train_df, x='pageViews')\n",
    "# plt.title('Violin Plot of Page Views')\n",
    "# plt.show()\n",
    "\n",
    "# # Violin plot for totalHits\n",
    "# sns.violinplot(data=train_df, x='totalHits')\n",
    "# plt.title('Violin Plot of Total Hits')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f78b6127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:49.974867Z",
     "iopub.status.busy": "2025-07-22T09:29:49.974683Z",
     "iopub.status.idle": "2025-07-22T09:29:49.977892Z",
     "shell.execute_reply": "2025-07-22T09:29:49.977211Z"
    },
    "papermill": {
     "duration": 0.031585,
     "end_time": "2025-07-22T09:29:49.978863",
     "exception": false,
     "start_time": "2025-07-22T09:29:49.947278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Histogram for sessionNumber\n",
    "# sns.histplot(data=train_df, x='sessionNumber', bins=50)\n",
    "# plt.title('Distribution of Session Number')\n",
    "# plt.show()\n",
    "\n",
    "# train_df['sessionStart'] = pd.to_datetime(train_df['sessionStart'], unit='s')\n",
    "\n",
    "# # # Histogram for date\n",
    "# # sns.histplot(data=train_df, x='sessionStart', bins=50)\n",
    "# # plt.title('Distribution of Dates')\n",
    "# # plt.show()\n",
    "\n",
    "# # Histogram for sessionStart (convert if needed)\n",
    "# sns.histplot(data=train_df, x='sessionStart', bins=50)\n",
    "# plt.title('Distribution of Session Start')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "010d9526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.032519Z",
     "iopub.status.busy": "2025-07-22T09:29:50.032336Z",
     "iopub.status.idle": "2025-07-22T09:29:50.035097Z",
     "shell.execute_reply": "2025-07-22T09:29:50.034595Z"
    },
    "papermill": {
     "duration": 0.030686,
     "end_time": "2025-07-22T09:29:50.035988",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.005302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Violin plot for sessionNumber\n",
    "# sns.violinplot(data=train_df, x='sessionNumber')\n",
    "# plt.title('Violin Plot of Session Number')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Violin plot for date\n",
    "# sns.violinplot(data=train_df, x='date')\n",
    "# plt.title('Violin Plot of Dates')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9cf0eeac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.089570Z",
     "iopub.status.busy": "2025-07-22T09:29:50.089383Z",
     "iopub.status.idle": "2025-07-22T09:29:50.092410Z",
     "shell.execute_reply": "2025-07-22T09:29:50.091923Z"
    },
    "papermill": {
     "duration": 0.030854,
     "end_time": "2025-07-22T09:29:50.093359",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.062505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Browser\n",
    "# sns.countplot(data=train_df, x='browser', order=train_df['browser'].value_counts().index[:10])\n",
    "# plt.title('Top 10 Browsers')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # OS\n",
    "# sns.countplot(data=train_df, x='os', order=train_df['os'].value_counts().index[:10])\n",
    "# plt.title('Top 10 Operating Systems')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # Device Type\n",
    "# sns.countplot(data=train_df, x='deviceType', order=train_df['deviceType'].value_counts().index)\n",
    "# plt.title('Device Type Distribution')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # Language\n",
    "# sns.countplot(data=train_df, x='device.language', order=train_df['device.language'].value_counts().index[:10])\n",
    "# plt.title('Top 10 Device Languages')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dab2da42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.147408Z",
     "iopub.status.busy": "2025-07-22T09:29:50.147208Z",
     "iopub.status.idle": "2025-07-22T09:29:50.149924Z",
     "shell.execute_reply": "2025-07-22T09:29:50.149447Z"
    },
    "papermill": {
     "duration": 0.030661,
     "end_time": "2025-07-22T09:29:50.150962",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.120301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['browser'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40ebd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:52:04.563698Z",
     "iopub.status.busy": "2025-07-22T07:52:04.563117Z",
     "iopub.status.idle": "2025-07-22T07:52:04.568296Z",
     "shell.execute_reply": "2025-07-22T07:52:04.567640Z",
     "shell.execute_reply.started": "2025-07-22T07:52:04.563676Z"
    },
    "papermill": {
     "duration": 0.0264,
     "end_time": "2025-07-22T09:29:50.204009",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.177609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6325c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:52:07.522592Z",
     "iopub.status.busy": "2025-07-22T07:52:07.521891Z",
     "iopub.status.idle": "2025-07-22T07:52:08.633255Z",
     "shell.execute_reply": "2025-07-22T07:52:08.632678Z",
     "shell.execute_reply.started": "2025-07-22T07:52:07.522569Z"
    },
    "papermill": {
     "duration": 0.026454,
     "end_time": "2025-07-22T09:29:50.256860",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.230406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44ecbba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.310433Z",
     "iopub.status.busy": "2025-07-22T09:29:50.310240Z",
     "iopub.status.idle": "2025-07-22T09:29:50.312756Z",
     "shell.execute_reply": "2025-07-22T09:29:50.312303Z"
    },
    "papermill": {
     "duration": 0.030593,
     "end_time": "2025-07-22T09:29:50.313763",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.283170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64568a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T19:10:23.025374Z",
     "iopub.status.busy": "2025-07-20T19:10:23.025141Z",
     "iopub.status.idle": "2025-07-20T19:10:23.042398Z",
     "shell.execute_reply": "2025-07-20T19:10:23.041789Z",
     "shell.execute_reply.started": "2025-07-20T19:10:23.025358Z"
    },
    "papermill": {
     "duration": 0.026238,
     "end_time": "2025-07-22T09:29:50.367105",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.340867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f0acef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.420594Z",
     "iopub.status.busy": "2025-07-22T09:29:50.420408Z",
     "iopub.status.idle": "2025-07-22T09:29:50.423370Z",
     "shell.execute_reply": "2025-07-22T09:29:50.422853Z"
    },
    "papermill": {
     "duration": 0.030883,
     "end_time": "2025-07-22T09:29:50.424351",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.393468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['browser'] = train_df['browser'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Other'\n",
    "# )\n",
    "# # Step 1: Get top 5 most frequent browsers\n",
    "# top_browsers = train_df['browser'].value_counts().nlargest(15).index\n",
    "\n",
    "# # Step 2: Replace less frequent browsers with 'Other' in the same column\n",
    "# train_df['browser'] = train_df['browser'].apply(\n",
    "#     lambda x: x if x in top_browsers else 'Other'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee7550bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.478584Z",
     "iopub.status.busy": "2025-07-22T09:29:50.478399Z",
     "iopub.status.idle": "2025-07-22T09:29:50.481265Z",
     "shell.execute_reply": "2025-07-22T09:29:50.480738Z"
    },
    "papermill": {
     "duration": 0.031145,
     "end_time": "2025-07-22T09:29:50.482252",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.451107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df['browser'] = test_df['browser'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Other'\n",
    "# )\n",
    "# # Step 1: Get top 5 most frequent browsers\n",
    "# #top_browsers = test_df['browser'].value_counts().nlargest(15).index\n",
    "\n",
    "# # Step 2: Replace less frequent browsers with 'Other' in the same column\n",
    "# test_df['browser'] = test_df['browser'].apply(\n",
    "#     lambda x: x if x in top_browsers else 'Other'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d37012c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.537417Z",
     "iopub.status.busy": "2025-07-22T09:29:50.536689Z",
     "iopub.status.idle": "2025-07-22T09:29:50.540096Z",
     "shell.execute_reply": "2025-07-22T09:29:50.539455Z"
    },
    "papermill": {
     "duration": 0.033049,
     "end_time": "2025-07-22T09:29:50.541718",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.508669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['browser'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc42b879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.599229Z",
     "iopub.status.busy": "2025-07-22T09:29:50.598787Z",
     "iopub.status.idle": "2025-07-22T09:29:50.601603Z",
     "shell.execute_reply": "2025-07-22T09:29:50.601046Z"
    },
    "papermill": {
     "duration": 0.031858,
     "end_time": "2025-07-22T09:29:50.602592",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.570734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['os'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa1357d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.662244Z",
     "iopub.status.busy": "2025-07-22T09:29:50.661979Z",
     "iopub.status.idle": "2025-07-22T09:29:50.665631Z",
     "shell.execute_reply": "2025-07-22T09:29:50.664829Z"
    },
    "papermill": {
     "duration": 0.037526,
     "end_time": "2025-07-22T09:29:50.666731",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.629205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['os'] = train_df['os'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Other'\n",
    "# )\n",
    "# # Step 1: Get top 5 most frequent browsers\n",
    "# top_os = train_df['os'].value_counts().nlargest(6).index\n",
    "\n",
    "# # Step 2: Replace less frequent browsers with 'Other' in the same column\n",
    "# train_df['os'] = train_df['os'].apply(\n",
    "#     lambda x: x if x in top_os else 'Other'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c624437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.739690Z",
     "iopub.status.busy": "2025-07-22T09:29:50.739255Z",
     "iopub.status.idle": "2025-07-22T09:29:50.742145Z",
     "shell.execute_reply": "2025-07-22T09:29:50.741586Z"
    },
    "papermill": {
     "duration": 0.033089,
     "end_time": "2025-07-22T09:29:50.743174",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.710085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['os'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "633fe520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.797443Z",
     "iopub.status.busy": "2025-07-22T09:29:50.797244Z",
     "iopub.status.idle": "2025-07-22T09:29:50.800204Z",
     "shell.execute_reply": "2025-07-22T09:29:50.799701Z"
    },
    "papermill": {
     "duration": 0.031255,
     "end_time": "2025-07-22T09:29:50.801240",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.769985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df['os'] = test_df['os'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Other'\n",
    "# )\n",
    "# # Step 1: Get top 5 most frequent browsers\n",
    "# #top_os = train_df['os'].value_counts().nlargest(6).index\n",
    "\n",
    "# # Step 2: Replace less frequent browsers with 'Other' in the same column\n",
    "# test_df['os'] = test_df['os'].apply(\n",
    "#     lambda x: x if x in top_os else 'Other'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0dd1a8bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.855002Z",
     "iopub.status.busy": "2025-07-22T09:29:50.854816Z",
     "iopub.status.idle": "2025-07-22T09:29:50.857609Z",
     "shell.execute_reply": "2025-07-22T09:29:50.857111Z"
    },
    "papermill": {
     "duration": 0.030614,
     "end_time": "2025-07-22T09:29:50.858621",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.828007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['deviceType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "564f4df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.912701Z",
     "iopub.status.busy": "2025-07-22T09:29:50.912208Z",
     "iopub.status.idle": "2025-07-22T09:29:50.915006Z",
     "shell.execute_reply": "2025-07-22T09:29:50.914506Z"
    },
    "papermill": {
     "duration": 0.030739,
     "end_time": "2025-07-22T09:29:50.915939",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.885200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['device.language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b85bf7bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:50.969654Z",
     "iopub.status.busy": "2025-07-22T09:29:50.969464Z",
     "iopub.status.idle": "2025-07-22T09:29:50.972540Z",
     "shell.execute_reply": "2025-07-22T09:29:50.972015Z"
    },
    "papermill": {
     "duration": 0.030972,
     "end_time": "2025-07-22T09:29:50.973487",
     "exception": false,
     "start_time": "2025-07-22T09:29:50.942515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.countplot(data=train_df, x='locationCountry', order=train_df['locationCountry'].value_counts().index[:10])\n",
    "# plt.title('Top 10 Countries by User Count')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # City\n",
    "# sns.countplot(data=train_df, x='geoNetwork.city', order=train_df['geoNetwork.city'].value_counts().index[:10])\n",
    "# plt.title('Top 10 Cities by User Count')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # Region\n",
    "# sns.countplot(data=train_df, x='geoNetwork.region', order=train_df['geoNetwork.region'].value_counts().index[:10])\n",
    "# plt.title('Top 10 Regions')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # Continent\n",
    "# sns.countplot(data=train_df, x='geoNetwork.continent', order=train_df['geoNetwork.continent'].value_counts().index)\n",
    "# plt.title('Users by Continent')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05966339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.027533Z",
     "iopub.status.busy": "2025-07-22T09:29:51.027348Z",
     "iopub.status.idle": "2025-07-22T09:29:51.029954Z",
     "shell.execute_reply": "2025-07-22T09:29:51.029493Z"
    },
    "papermill": {
     "duration": 0.030441,
     "end_time": "2025-07-22T09:29:51.030921",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.000480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['locationCountry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f30ec53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.084777Z",
     "iopub.status.busy": "2025-07-22T09:29:51.084613Z",
     "iopub.status.idle": "2025-07-22T09:29:51.087544Z",
     "shell.execute_reply": "2025-07-22T09:29:51.087020Z"
    },
    "papermill": {
     "duration": 0.030768,
     "end_time": "2025-07-22T09:29:51.088540",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.057772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['locationCountry'] = train_df['locationCountry'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "# # Step 1: Get the top 10 countries\n",
    "# top_countries = train_df['locationCountry'].value_counts().nlargest(10).index\n",
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# train_df['locationCountry'] = train_df['locationCountry'].apply(\n",
    "#     lambda x: x if x in top_countries else 'Unknown'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5fa94ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.141999Z",
     "iopub.status.busy": "2025-07-22T09:29:51.141812Z",
     "iopub.status.idle": "2025-07-22T09:29:51.144740Z",
     "shell.execute_reply": "2025-07-22T09:29:51.144106Z"
    },
    "papermill": {
     "duration": 0.03089,
     "end_time": "2025-07-22T09:29:51.145768",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.114878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['locationCountry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a4bb254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.200445Z",
     "iopub.status.busy": "2025-07-22T09:29:51.200036Z",
     "iopub.status.idle": "2025-07-22T09:29:51.202921Z",
     "shell.execute_reply": "2025-07-22T09:29:51.202412Z"
    },
    "papermill": {
     "duration": 0.031141,
     "end_time": "2025-07-22T09:29:51.203830",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.172689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df['locationCountry'] = test_df['locationCountry'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "# # Step 1: Get the top 10 countries\n",
    "# #top_countries = train_df['locationCountry'].value_counts().nlargest(10).index\n",
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# test_df['locationCountry'] = test_df['locationCountry'].apply(\n",
    "#     lambda x: x if x in top_countries else 'Unknown'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d538ed99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.257545Z",
     "iopub.status.busy": "2025-07-22T09:29:51.257379Z",
     "iopub.status.idle": "2025-07-22T09:29:51.260180Z",
     "shell.execute_reply": "2025-07-22T09:29:51.259522Z"
    },
    "papermill": {
     "duration": 0.030904,
     "end_time": "2025-07-22T09:29:51.261479",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.230575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df['locationCountry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6972ac15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.316779Z",
     "iopub.status.busy": "2025-07-22T09:29:51.316591Z",
     "iopub.status.idle": "2025-07-22T09:29:51.319615Z",
     "shell.execute_reply": "2025-07-22T09:29:51.318957Z"
    },
    "papermill": {
     "duration": 0.03117,
     "end_time": "2025-07-22T09:29:51.320702",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.289532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['geoNetwork.city'] = train_df['geoNetwork.city'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "\n",
    "# # Step 1: Get the top 10 countries\n",
    "# top_geoNetwork_city = train_df['geoNetwork.city'].value_counts().nlargest(10).index\n",
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# train_df['geoNetwork.city'] = train_df['geoNetwork.city'].apply(\n",
    "#     lambda x: x if x in top_geoNetwork_city else 'Unknown'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "49c1146c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.375306Z",
     "iopub.status.busy": "2025-07-22T09:29:51.374828Z",
     "iopub.status.idle": "2025-07-22T09:29:51.377820Z",
     "shell.execute_reply": "2025-07-22T09:29:51.377188Z"
    },
    "papermill": {
     "duration": 0.031121,
     "end_time": "2025-07-22T09:29:51.378880",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.347759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df['geoNetwork.city'] = test_df['geoNetwork.city'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "\n",
    "# # Step 1: Get the top 10 countries\n",
    "# #top_geoNetwork_city = train_df['geoNetwork.city'].value_counts().nlargest(10).index\n",
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# test_df['geoNetwork.city'] = test_df['geoNetwork.city'].apply(\n",
    "#     lambda x: x if x in top_geoNetwork_city else 'Unknown'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b4cdf8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.433385Z",
     "iopub.status.busy": "2025-07-22T09:29:51.432986Z",
     "iopub.status.idle": "2025-07-22T09:29:51.435758Z",
     "shell.execute_reply": "2025-07-22T09:29:51.435297Z"
    },
    "papermill": {
     "duration": 0.031223,
     "end_time": "2025-07-22T09:29:51.436757",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.405534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['geoNetwork.continent'] = train_df['geoNetwork.continent'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "\n",
    "# # Step 1: Get the top 10 countries\n",
    "# top_geoNetwork_continent = train_df['geoNetwork.continent'].value_counts().nlargest(10).index\n",
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# train_df['geoNetwork.continent'] = train_df['geoNetwork.continent'].apply(\n",
    "#     lambda x: x if x in top_geoNetwork_continent else 'Unknown'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a415b1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.490423Z",
     "iopub.status.busy": "2025-07-22T09:29:51.490254Z",
     "iopub.status.idle": "2025-07-22T09:29:51.493112Z",
     "shell.execute_reply": "2025-07-22T09:29:51.492607Z"
    },
    "papermill": {
     "duration": 0.030703,
     "end_time": "2025-07-22T09:29:51.494035",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.463332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df['geoNetwork.continent'] = test_df['geoNetwork.continent'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "\n",
    "# # Step 1: Get the top 10 countries\n",
    "# #top_geoNetwork_continent = train_df['geoNetwork.continent'].value_counts().nlargest(10).index\n",
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# test_df['geoNetwork.continent'] = test_df['geoNetwork.continent'].apply(\n",
    "#     lambda x: x if x in top_geoNetwork_continent else 'Unknown'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71ca321f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.590180Z",
     "iopub.status.busy": "2025-07-22T09:29:51.589906Z",
     "iopub.status.idle": "2025-07-22T09:29:51.593563Z",
     "shell.execute_reply": "2025-07-22T09:29:51.592656Z"
    },
    "papermill": {
     "duration": 0.032469,
     "end_time": "2025-07-22T09:29:51.594742",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.562273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['geoNetwork.continent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a333afc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.649434Z",
     "iopub.status.busy": "2025-07-22T09:29:51.649254Z",
     "iopub.status.idle": "2025-07-22T09:29:51.651982Z",
     "shell.execute_reply": "2025-07-22T09:29:51.651489Z"
    },
    "papermill": {
     "duration": 0.031064,
     "end_time": "2025-07-22T09:29:51.652933",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.621869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['locationCountry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0325ea42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.708022Z",
     "iopub.status.busy": "2025-07-22T09:29:51.707847Z",
     "iopub.status.idle": "2025-07-22T09:29:51.710914Z",
     "shell.execute_reply": "2025-07-22T09:29:51.710283Z"
    },
    "papermill": {
     "duration": 0.031305,
     "end_time": "2025-07-22T09:29:51.711901",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.680596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['geoNetwork.city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e41ab89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.766063Z",
     "iopub.status.busy": "2025-07-22T09:29:51.765874Z",
     "iopub.status.idle": "2025-07-22T09:29:51.768739Z",
     "shell.execute_reply": "2025-07-22T09:29:51.768110Z"
    },
    "papermill": {
     "duration": 0.031234,
     "end_time": "2025-07-22T09:29:51.769772",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.738538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['geoNetwork.city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87562316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.823647Z",
     "iopub.status.busy": "2025-07-22T09:29:51.823454Z",
     "iopub.status.idle": "2025-07-22T09:29:51.826296Z",
     "shell.execute_reply": "2025-07-22T09:29:51.825639Z"
    },
    "papermill": {
     "duration": 0.030981,
     "end_time": "2025-07-22T09:29:51.827459",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.796478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df['geoNetwork.city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0357734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.881054Z",
     "iopub.status.busy": "2025-07-22T09:29:51.880858Z",
     "iopub.status.idle": "2025-07-22T09:29:51.883722Z",
     "shell.execute_reply": "2025-07-22T09:29:51.883100Z"
    },
    "papermill": {
     "duration": 0.030744,
     "end_time": "2025-07-22T09:29:51.884690",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.853946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['geoNetwork.region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0eae091b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.938259Z",
     "iopub.status.busy": "2025-07-22T09:29:51.938022Z",
     "iopub.status.idle": "2025-07-22T09:29:51.940808Z",
     "shell.execute_reply": "2025-07-22T09:29:51.940347Z"
    },
    "papermill": {
     "duration": 0.030644,
     "end_time": "2025-07-22T09:29:51.941751",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.911107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['geoNetwork.region'] = train_df['geoNetwork.region'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "\n",
    "# # Step 1: Get the top 10 countries\n",
    "# top_geoNetwork_continent = train_df['geoNetwork.region'].value_counts().nlargest(10).index\n",
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# train_df['geoNetwork.region'] = train_df['geoNetwork.region'].apply(\n",
    "#     lambda x: x if x in top_geoNetwork_continent else 'Unknown'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ba6bc2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:51.995936Z",
     "iopub.status.busy": "2025-07-22T09:29:51.995442Z",
     "iopub.status.idle": "2025-07-22T09:29:51.998093Z",
     "shell.execute_reply": "2025-07-22T09:29:51.997592Z"
    },
    "papermill": {
     "duration": 0.030642,
     "end_time": "2025-07-22T09:29:51.999179",
     "exception": false,
     "start_time": "2025-07-22T09:29:51.968537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['geoNetwork.region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "41916ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.052739Z",
     "iopub.status.busy": "2025-07-22T09:29:52.052556Z",
     "iopub.status.idle": "2025-07-22T09:29:52.055586Z",
     "shell.execute_reply": "2025-07-22T09:29:52.054909Z"
    },
    "papermill": {
     "duration": 0.031172,
     "end_time": "2025-07-22T09:29:52.056677",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.025505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df['geoNetwork.region'] = test_df['geoNetwork.region'].replace(\n",
    "#     ['not available in demo dataset', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "\n",
    "# Step 2: Replace all others with 'Other'\n",
    "# test_df['geoNetwork.region'] = test_df['geoNetwork.region'].apply(\n",
    "#     lambda x: x if x in top_geoNetwork_continent else 'Unknown'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a7467168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.111413Z",
     "iopub.status.busy": "2025-07-22T09:29:52.110705Z",
     "iopub.status.idle": "2025-07-22T09:29:52.113986Z",
     "shell.execute_reply": "2025-07-22T09:29:52.113342Z"
    },
    "papermill": {
     "duration": 0.031684,
     "end_time": "2025-07-22T09:29:52.115130",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.083446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Medium\n",
    "# sns.countplot(data=train_df, x='trafficSource.medium', order=train_df['trafficSource.medium'].value_counts().index[:10])\n",
    "# plt.title('Traffic Source Medium')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # Campaign\n",
    "# sns.countplot(data=train_df, x='trafficSource.campaign', order=train_df['trafficSource.campaign'].value_counts().index[:10])\n",
    "# plt.title('Top Campaigns')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # Referral Path\n",
    "# sns.countplot(data=train_df, x='trafficSource.referralPath', order=train_df['trafficSource.referralPath'].value_counts().index[:10])\n",
    "# plt.title('Top Referral Paths')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "21a7f75d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.169234Z",
     "iopub.status.busy": "2025-07-22T09:29:52.168825Z",
     "iopub.status.idle": "2025-07-22T09:29:52.171660Z",
     "shell.execute_reply": "2025-07-22T09:29:52.171019Z"
    },
    "papermill": {
     "duration": 0.031188,
     "end_time": "2025-07-22T09:29:52.172635",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.141447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.medium'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f3a72453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.226396Z",
     "iopub.status.busy": "2025-07-22T09:29:52.226218Z",
     "iopub.status.idle": "2025-07-22T09:29:52.229147Z",
     "shell.execute_reply": "2025-07-22T09:29:52.228497Z"
    },
    "papermill": {
     "duration": 0.03092,
     "end_time": "2025-07-22T09:29:52.230151",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.199231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['trafficSource.medium'] = train_df['trafficSource.medium'].replace(\n",
    "#     ['(none)', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )\n",
    "# test_df['trafficSource.medium'] = test_df['trafficSource.medium'].replace(\n",
    "#     ['(none)', '(not set)'],\n",
    "#     'Unknown'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fc0d1b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.284000Z",
     "iopub.status.busy": "2025-07-22T09:29:52.283661Z",
     "iopub.status.idle": "2025-07-22T09:29:52.286474Z",
     "shell.execute_reply": "2025-07-22T09:29:52.285804Z"
    },
    "papermill": {
     "duration": 0.030829,
     "end_time": "2025-07-22T09:29:52.287518",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.256689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.medium'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ade0b10c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.341180Z",
     "iopub.status.busy": "2025-07-22T09:29:52.340976Z",
     "iopub.status.idle": "2025-07-22T09:29:52.343588Z",
     "shell.execute_reply": "2025-07-22T09:29:52.343125Z"
    },
    "papermill": {
     "duration": 0.030438,
     "end_time": "2025-07-22T09:29:52.344552",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.314114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.campaign'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "30759110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.398886Z",
     "iopub.status.busy": "2025-07-22T09:29:52.398413Z",
     "iopub.status.idle": "2025-07-22T09:29:52.401358Z",
     "shell.execute_reply": "2025-07-22T09:29:52.400843Z"
    },
    "papermill": {
     "duration": 0.030833,
     "end_time": "2025-07-22T09:29:52.402408",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.371575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Step 1: Get the top 10 countries\n",
    "# top_trafficSource_campaign = train_df['trafficSource.campaign'].value_counts().nlargest(10).index\n",
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# train_df['trafficSource.campaign'] = train_df['trafficSource.campaign'].apply(\n",
    "#     lambda x: x if x in top_trafficSource_campaign else 'Unknown'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1bb81a29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.456370Z",
     "iopub.status.busy": "2025-07-22T09:29:52.456169Z",
     "iopub.status.idle": "2025-07-22T09:29:52.459031Z",
     "shell.execute_reply": "2025-07-22T09:29:52.458406Z"
    },
    "papermill": {
     "duration": 0.030837,
     "end_time": "2025-07-22T09:29:52.460021",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.429184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Step 2: Replace all others with 'Other'\n",
    "# test_df['trafficSource.campaign'] = test_df['trafficSource.campaign'].apply(\n",
    "#     lambda x: x if x in top_trafficSource_campaign else 'Unknown'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3870d61e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.513891Z",
     "iopub.status.busy": "2025-07-22T09:29:52.513708Z",
     "iopub.status.idle": "2025-07-22T09:29:52.516352Z",
     "shell.execute_reply": "2025-07-22T09:29:52.515871Z"
    },
    "papermill": {
     "duration": 0.030669,
     "end_time": "2025-07-22T09:29:52.517337",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.486668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.campaign'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1394a8d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.571219Z",
     "iopub.status.busy": "2025-07-22T09:29:52.570997Z",
     "iopub.status.idle": "2025-07-22T09:29:52.573977Z",
     "shell.execute_reply": "2025-07-22T09:29:52.573338Z"
    },
    "papermill": {
     "duration": 0.031044,
     "end_time": "2025-07-22T09:29:52.575016",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.543972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['trafficSource.referralPath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "74fdac77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.630517Z",
     "iopub.status.busy": "2025-07-22T09:29:52.630319Z",
     "iopub.status.idle": "2025-07-22T09:29:52.633279Z",
     "shell.execute_reply": "2025-07-22T09:29:52.632591Z"
    },
    "papermill": {
     "duration": 0.031254,
     "end_time": "2025-07-22T09:29:52.634387",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.603133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # User Channel\n",
    "# sns.countplot(data=train_df, x='userChannel', order=train_df['userChannel'].value_counts().index[:10])\n",
    "# plt.title('User Channels')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # Social Engagement Type\n",
    "# sns.countplot(data=train_df, x='socialEngagementType', order=train_df['socialEngagementType'].value_counts().index)\n",
    "# plt.title('Social Engagement Types')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c43ebbeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.689166Z",
     "iopub.status.busy": "2025-07-22T09:29:52.688628Z",
     "iopub.status.idle": "2025-07-22T09:29:52.691479Z",
     "shell.execute_reply": "2025-07-22T09:29:52.690967Z"
    },
    "papermill": {
     "duration": 0.031503,
     "end_time": "2025-07-22T09:29:52.692489",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.660986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['socialEngagementType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "223bc600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.746277Z",
     "iopub.status.busy": "2025-07-22T09:29:52.746039Z",
     "iopub.status.idle": "2025-07-22T09:29:52.748886Z",
     "shell.execute_reply": "2025-07-22T09:29:52.748280Z"
    },
    "papermill": {
     "duration": 0.030746,
     "end_time": "2025-07-22T09:29:52.749857",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.719111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df['socialEngagementType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dc6cfdd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.803432Z",
     "iopub.status.busy": "2025-07-22T09:29:52.803234Z",
     "iopub.status.idle": "2025-07-22T09:29:52.805805Z",
     "shell.execute_reply": "2025-07-22T09:29:52.805337Z"
    },
    "papermill": {
     "duration": 0.030498,
     "end_time": "2025-07-22T09:29:52.806809",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.776311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.scatterplot(data=train_df, x='pageViews', y='purchaseValue')\n",
    "# plt.title('Page Views vs Purchase Value')\n",
    "# plt.xlabel('Page Views')\n",
    "# plt.ylabel('Purchase Value')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "96f86da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.860525Z",
     "iopub.status.busy": "2025-07-22T09:29:52.860024Z",
     "iopub.status.idle": "2025-07-22T09:29:52.863145Z",
     "shell.execute_reply": "2025-07-22T09:29:52.862484Z"
    },
    "papermill": {
     "duration": 0.031024,
     "end_time": "2025-07-22T09:29:52.864246",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.833222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.regplot(data=train_df, x='totalHits', y='purchaseValue', scatter_kws={'alpha':0.5})\n",
    "# plt.title('Total Hits vs Purchase Value (with Regression Line)')\n",
    "# plt.xlabel('Total Hits')\n",
    "# plt.ylabel('Purchase Value')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9e9af17a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.918056Z",
     "iopub.status.busy": "2025-07-22T09:29:52.917549Z",
     "iopub.status.idle": "2025-07-22T09:29:52.920508Z",
     "shell.execute_reply": "2025-07-22T09:29:52.919844Z"
    },
    "papermill": {
     "duration": 0.030887,
     "end_time": "2025-07-22T09:29:52.921476",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.890589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selected_cols = ['pageViews', 'totalHits', 'purchaseValue']\n",
    "# sns.pairplot(train_df[selected_cols])\n",
    "# plt.suptitle('Pairwise Relationships', y=1.02)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eaadcac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:52.975023Z",
     "iopub.status.busy": "2025-07-22T09:29:52.974830Z",
     "iopub.status.idle": "2025-07-22T09:29:52.977720Z",
     "shell.execute_reply": "2025-07-22T09:29:52.977042Z"
    },
    "papermill": {
     "duration": 0.030839,
     "end_time": "2025-07-22T09:29:52.978673",
     "exception": false,
     "start_time": "2025-07-22T09:29:52.947834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.catplot(data=train_df, x='deviceType', y='purchaseValue', kind='box')\n",
    "# plt.title('Purchase Value by Device Type')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8e7da83d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.032880Z",
     "iopub.status.busy": "2025-07-22T09:29:53.032380Z",
     "iopub.status.idle": "2025-07-22T09:29:53.035250Z",
     "shell.execute_reply": "2025-07-22T09:29:53.034672Z"
    },
    "papermill": {
     "duration": 0.030784,
     "end_time": "2025-07-22T09:29:53.036333",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.005549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.scatterplot(data=train_df, x='pageViews', y='totalHits', alpha=0.5)\n",
    "# plt.title('Scatter Plot: PageViews vs TotalHits')\n",
    "# plt.xlabel('Page Views')\n",
    "# plt.ylabel('Total Hits')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "100380bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.090104Z",
     "iopub.status.busy": "2025-07-22T09:29:53.089525Z",
     "iopub.status.idle": "2025-07-22T09:29:53.092503Z",
     "shell.execute_reply": "2025-07-22T09:29:53.091852Z"
    },
    "papermill": {
     "duration": 0.030855,
     "end_time": "2025-07-22T09:29:53.093509",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.062654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(data=train_df, x='pageViews', y='totalHits', kind='reg', height=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3810f058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.147699Z",
     "iopub.status.busy": "2025-07-22T09:29:53.147506Z",
     "iopub.status.idle": "2025-07-22T09:29:53.150403Z",
     "shell.execute_reply": "2025-07-22T09:29:53.149733Z"
    },
    "papermill": {
     "duration": 0.031437,
     "end_time": "2025-07-22T09:29:53.151527",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.120090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# corr = train_df[['pageViews', 'totalHits']].corr()\n",
    "# sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "# plt.title('Correlation between pageViews and totalHits')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4dd490b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.205890Z",
     "iopub.status.busy": "2025-07-22T09:29:53.205410Z",
     "iopub.status.idle": "2025-07-22T09:29:53.208223Z",
     "shell.execute_reply": "2025-07-22T09:29:53.207592Z"
    },
    "papermill": {
     "duration": 0.03091,
     "end_time": "2025-07-22T09:29:53.209242",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.178332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.scatterplot(x=np.log1p(train_df['pageViews']), y=np.log1p(train_df['totalHits']))\n",
    "# plt.title('Log-Scale Scatter Plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "903d5ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.263972Z",
     "iopub.status.busy": "2025-07-22T09:29:53.263299Z",
     "iopub.status.idle": "2025-07-22T09:29:53.266348Z",
     "shell.execute_reply": "2025-07-22T09:29:53.265699Z"
    },
    "papermill": {
     "duration": 0.03114,
     "end_time": "2025-07-22T09:29:53.267389",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.236249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[['pageViews','totalHits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "50baede6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.322090Z",
     "iopub.status.busy": "2025-07-22T09:29:53.321574Z",
     "iopub.status.idle": "2025-07-22T09:29:53.324386Z",
     "shell.execute_reply": "2025-07-22T09:29:53.323868Z"
    },
    "papermill": {
     "duration": 0.03136,
     "end_time": "2025-07-22T09:29:53.325481",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.294121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_df[['pageViews','totalHits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "11cc0ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.380181Z",
     "iopub.status.busy": "2025-07-22T09:29:53.379664Z",
     "iopub.status.idle": "2025-07-22T09:29:53.389546Z",
     "shell.execute_reply": "2025-07-22T09:29:53.389039Z"
    },
    "papermill": {
     "duration": 0.038409,
     "end_time": "2025-07-22T09:29:53.390553",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.352144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['avg_interaction'] = (train_df['pageViews'] + train_df['totalHits']) / 2\n",
    "test_df['avg_interaction'] = (train_df['pageViews'] + train_df['totalHits']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729250c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:06:50.318726Z",
     "iopub.status.busy": "2025-07-22T09:06:50.318434Z",
     "iopub.status.idle": "2025-07-22T09:06:50.327784Z",
     "shell.execute_reply": "2025-07-22T09:06:50.326970Z",
     "shell.execute_reply.started": "2025-07-22T09:06:50.318704Z"
    },
    "papermill": {
     "duration": 0.026745,
     "end_time": "2025-07-22T09:29:53.444274",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.417529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b79639ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.497652Z",
     "iopub.status.busy": "2025-07-22T09:29:53.497484Z",
     "iopub.status.idle": "2025-07-22T09:29:53.593682Z",
     "shell.execute_reply": "2025-07-22T09:29:53.592809Z"
    },
    "papermill": {
     "duration": 0.124266,
     "end_time": "2025-07-22T09:29:53.594801",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.470535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116023 entries, 0 to 116022\n",
      "Data columns (total 34 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   trafficSource.isTrueDirect  116023 non-null  int64  \n",
      " 1   purchaseValue               116023 non-null  float64\n",
      " 2   browser                     116023 non-null  object \n",
      " 3   trafficSource.keyword       116023 non-null  object \n",
      " 4   geoCluster                  116023 non-null  object \n",
      " 5   userId                      116023 non-null  int64  \n",
      " 6   trafficSource.campaign      116023 non-null  object \n",
      " 7   geoNetwork.networkDomain    116023 non-null  object \n",
      " 8   gclIdPresent                116023 non-null  int64  \n",
      " 9   sessionNumber               116023 non-null  int64  \n",
      " 10  geoNetwork.region           116023 non-null  object \n",
      " 11  trafficSource               116023 non-null  object \n",
      " 12  sessionId                   116023 non-null  int64  \n",
      " 13  os                          116023 non-null  object \n",
      " 14  geoNetwork.subContinent     116023 non-null  object \n",
      " 15  trafficSource.medium        116023 non-null  object \n",
      " 16  locationCountry             116023 non-null  object \n",
      " 17  geoNetwork.city             116023 non-null  object \n",
      " 18  geoNetwork.metro            116023 non-null  object \n",
      " 19  pageViews                   116023 non-null  float64\n",
      " 20  trafficSource.referralPath  116023 non-null  object \n",
      " 21  totals.bounces              116023 non-null  int64  \n",
      " 22  date                        116023 non-null  int64  \n",
      " 23  deviceType                  116023 non-null  object \n",
      " 24  userChannel                 116023 non-null  object \n",
      " 25  totalHits                   116023 non-null  int64  \n",
      " 26  sessionStart                116023 non-null  int64  \n",
      " 27  geoNetwork.continent        116023 non-null  object \n",
      " 28  device.isMobile             116023 non-null  bool   \n",
      " 29  new_visits                  116023 non-null  int64  \n",
      " 30  sessionNumber_log           116023 non-null  float64\n",
      " 31  pageViews_log               116023 non-null  float64\n",
      " 32  totalHits_log               116023 non-null  float64\n",
      " 33  avg_interaction             116023 non-null  float64\n",
      "dtypes: bool(1), float64(6), int64(10), object(17)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "28b97bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.653713Z",
     "iopub.status.busy": "2025-07-22T09:29:53.653511Z",
     "iopub.status.idle": "2025-07-22T09:29:53.685740Z",
     "shell.execute_reply": "2025-07-22T09:29:53.684888Z"
    },
    "papermill": {
     "duration": 0.062943,
     "end_time": "2025-07-22T09:29:53.686900",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.623957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29006 entries, 0 to 29005\n",
      "Data columns (total 33 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   userChannel                 29006 non-null  object \n",
      " 1   date                        29006 non-null  int64  \n",
      " 2   browser                     29006 non-null  object \n",
      " 3   deviceType                  29006 non-null  object \n",
      " 4   device.isMobile             29006 non-null  bool   \n",
      " 5   os                          29006 non-null  object \n",
      " 6   geoNetwork.city             29006 non-null  object \n",
      " 7   geoNetwork.continent        29006 non-null  object \n",
      " 8   locationCountry             29006 non-null  object \n",
      " 9   geoNetwork.metro            29006 non-null  object \n",
      " 10  geoNetwork.networkDomain    29006 non-null  object \n",
      " 11  geoNetwork.region           29006 non-null  object \n",
      " 12  geoNetwork.subContinent     29006 non-null  object \n",
      " 13  totals.bounces              29006 non-null  int64  \n",
      " 14  totalHits                   29006 non-null  int64  \n",
      " 15  new_visits                  29006 non-null  int64  \n",
      " 16  pageViews                   29006 non-null  float64\n",
      " 17  trafficSource.campaign      29006 non-null  object \n",
      " 18  trafficSource.isTrueDirect  29006 non-null  int64  \n",
      " 19  trafficSource.keyword       29006 non-null  object \n",
      " 20  trafficSource.medium        29006 non-null  object \n",
      " 21  trafficSource.referralPath  29006 non-null  object \n",
      " 22  trafficSource               29006 non-null  object \n",
      " 23  sessionId                   29006 non-null  int64  \n",
      " 24  sessionNumber               29006 non-null  int64  \n",
      " 25  sessionStart                29006 non-null  int64  \n",
      " 26  userId                      29006 non-null  int64  \n",
      " 27  geoCluster                  29006 non-null  object \n",
      " 28  gclIdPresent                29006 non-null  int64  \n",
      " 29  sessionNumber_log           29006 non-null  float64\n",
      " 30  pageViews_log               29006 non-null  float64\n",
      " 31  totalHits_log               29006 non-null  float64\n",
      " 32  avg_interaction             29006 non-null  float64\n",
      "dtypes: bool(1), float64(5), int64(10), object(17)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "76772bf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.747264Z",
     "iopub.status.busy": "2025-07-22T09:29:53.746632Z",
     "iopub.status.idle": "2025-07-22T09:29:53.750388Z",
     "shell.execute_reply": "2025-07-22T09:29:53.749659Z"
    },
    "papermill": {
     "duration": 0.035767,
     "end_time": "2025-07-22T09:29:53.751482",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.715715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[['date', 'sessionStart', 'sessionId']].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f5b4163a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.807038Z",
     "iopub.status.busy": "2025-07-22T09:29:53.806830Z",
     "iopub.status.idle": "2025-07-22T09:29:53.809768Z",
     "shell.execute_reply": "2025-07-22T09:29:53.809120Z"
    },
    "papermill": {
     "duration": 0.031199,
     "end_time": "2025-07-22T09:29:53.810751",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.779552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Convert int to datetime\n",
    "# train_df['date'] = pd.to_datetime(train_df['date'], format='%Y%m%d')\n",
    "\n",
    "# # Convert both date and sessionStart to numeric for correlation\n",
    "# train_df['date_ordinal'] = train_df['date'].map(lambda x: x.toordinal())\n",
    "# train_df['sessionStart_numeric'] = train_df['sessionStart'].astype('int64') // 1e9  # seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a6acb004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.865264Z",
     "iopub.status.busy": "2025-07-22T09:29:53.864721Z",
     "iopub.status.idle": "2025-07-22T09:29:53.867498Z",
     "shell.execute_reply": "2025-07-22T09:29:53.866985Z"
    },
    "papermill": {
     "duration": 0.030801,
     "end_time": "2025-07-22T09:29:53.868453",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.837652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[['date_ordinal', 'sessionStart_numeric']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5e5d32a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.922563Z",
     "iopub.status.busy": "2025-07-22T09:29:53.922375Z",
     "iopub.status.idle": "2025-07-22T09:29:53.925140Z",
     "shell.execute_reply": "2025-07-22T09:29:53.924608Z"
    },
    "papermill": {
     "duration": 0.031003,
     "end_time": "2025-07-22T09:29:53.926117",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.895114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[['date', 'sessionStart']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d348a40a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:53.980805Z",
     "iopub.status.busy": "2025-07-22T09:29:53.980615Z",
     "iopub.status.idle": "2025-07-22T09:29:53.983448Z",
     "shell.execute_reply": "2025-07-22T09:29:53.982930Z"
    },
    "papermill": {
     "duration": 0.031341,
     "end_time": "2025-07-22T09:29:53.984500",
     "exception": false,
     "start_time": "2025-07-22T09:29:53.953159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['session_delay_seconds'] = (train_df['sessionStart'] - train_df['date']).dt.total_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aa64a62a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.038513Z",
     "iopub.status.busy": "2025-07-22T09:29:54.038322Z",
     "iopub.status.idle": "2025-07-22T09:29:54.040855Z",
     "shell.execute_reply": "2025-07-22T09:29:54.040388Z"
    },
    "papermill": {
     "duration": 0.030703,
     "end_time": "2025-07-22T09:29:54.041806",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.011103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['session_delay_days'] = train_df['session_delay_seconds'] / 86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "52ecf38c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.096038Z",
     "iopub.status.busy": "2025-07-22T09:29:54.095874Z",
     "iopub.status.idle": "2025-07-22T09:29:54.098535Z",
     "shell.execute_reply": "2025-07-22T09:29:54.098037Z"
    },
    "papermill": {
     "duration": 0.030907,
     "end_time": "2025-07-22T09:29:54.099499",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.068592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['session_delay_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b9d320ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.154065Z",
     "iopub.status.busy": "2025-07-22T09:29:54.153871Z",
     "iopub.status.idle": "2025-07-22T09:29:54.156448Z",
     "shell.execute_reply": "2025-07-22T09:29:54.155958Z"
    },
    "papermill": {
     "duration": 0.031007,
     "end_time": "2025-07-22T09:29:54.157512",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.126505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "84714a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.211742Z",
     "iopub.status.busy": "2025-07-22T09:29:54.211542Z",
     "iopub.status.idle": "2025-07-22T09:29:54.214431Z",
     "shell.execute_reply": "2025-07-22T09:29:54.213944Z"
    },
    "papermill": {
     "duration": 0.031262,
     "end_time": "2025-07-22T09:29:54.215491",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.184229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(train_df['session_delay_days'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8c34adf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.269682Z",
     "iopub.status.busy": "2025-07-22T09:29:54.269520Z",
     "iopub.status.idle": "2025-07-22T09:29:54.272204Z",
     "shell.execute_reply": "2025-07-22T09:29:54.271673Z"
    },
    "papermill": {
     "duration": 0.031017,
     "end_time": "2025-07-22T09:29:54.273301",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.242284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['date'] = pd.to_datetime(train_df['date'], unit='us')\n",
    "# print(train_df['date'].min(), train_df['date'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "658b0631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.327723Z",
     "iopub.status.busy": "2025-07-22T09:29:54.327559Z",
     "iopub.status.idle": "2025-07-22T09:29:54.330182Z",
     "shell.execute_reply": "2025-07-22T09:29:54.329659Z"
    },
    "papermill": {
     "duration": 0.031098,
     "end_time": "2025-07-22T09:29:54.331240",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.300142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df['sessionStart'] = pd.to_datetime(train_df['sessionStart'], unit='ns')\n",
    "# print(train_df['sessionStart'].min(), train_df['sessionStart'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b76da53f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.386275Z",
     "iopub.status.busy": "2025-07-22T09:29:54.385781Z",
     "iopub.status.idle": "2025-07-22T09:29:54.388986Z",
     "shell.execute_reply": "2025-07-22T09:29:54.388327Z"
    },
    "papermill": {
     "duration": 0.031743,
     "end_time": "2025-07-22T09:29:54.389983",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.358240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Convert to datetime if not already\n",
    "# train_df['sessionStart'] = pd.to_datetime(train_df['sessionStart'], unit='us')\n",
    "\n",
    "# # Extract useful features\n",
    "# train_df['session_day_of_week'] = train_df['sessionStart'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "# train_df['session_hour'] = train_df['sessionStart'].dt.hour            # Hour of the day 0-23\n",
    "# train_df['session_day'] = train_df['sessionStart'].dt.day              # Day of the month\n",
    "# train_df['session_month'] = train_df['sessionStart'].dt.month          # Month 1-12\n",
    "# train_df['session_weekofyear'] = train_df['sessionStart'].dt.isocalendar().week  # Week number\n",
    "# train_df['session_is_weekend'] = (train_df['session_day_of_week'] >= 5).astype(int)  # 1 if Sat/Sun else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5a0743c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.444363Z",
     "iopub.status.busy": "2025-07-22T09:29:54.444161Z",
     "iopub.status.idle": "2025-07-22T09:29:54.447195Z",
     "shell.execute_reply": "2025-07-22T09:29:54.446514Z"
    },
    "papermill": {
     "duration": 0.031697,
     "end_time": "2025-07-22T09:29:54.448331",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.416634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Convert to datetime if not already\n",
    "# test_df['sessionStart'] = pd.to_datetime(test_df['sessionStart'])\n",
    "\n",
    "# # Extract time features\n",
    "# test_df['session_day_of_week'] = test_df['sessionStart'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "# test_df['session_hour'] = test_df['sessionStart'].dt.hour              # Hour of the day 0-23\n",
    "# test_df['session_day'] = test_df['sessionStart'].dt.day                # Day of the month\n",
    "# test_df['session_month'] = test_df['sessionStart'].dt.month            # Month 1-12\n",
    "# test_df['session_weekofyear'] = test_df['sessionStart'].dt.isocalendar().week  # Week number\n",
    "# test_df['session_is_weekend'] = (test_df['session_day_of_week'] >= 5).astype(int)  # 1 if Sat/Sun else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0a7242c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.507177Z",
     "iopub.status.busy": "2025-07-22T09:29:54.506965Z",
     "iopub.status.idle": "2025-07-22T09:29:54.509758Z",
     "shell.execute_reply": "2025-07-22T09:29:54.509279Z"
    },
    "papermill": {
     "duration": 0.035517,
     "end_time": "2025-07-22T09:29:54.510763",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.475246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df[['sessionStart','session_day_of_week','session_hour','session_day','session_month','session_weekofyear','session_is_weekend']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4e399966",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.566108Z",
     "iopub.status.busy": "2025-07-22T09:29:54.565891Z",
     "iopub.status.idle": "2025-07-22T09:29:54.568837Z",
     "shell.execute_reply": "2025-07-22T09:29:54.568201Z"
    },
    "papermill": {
     "duration": 0.031244,
     "end_time": "2025-07-22T09:29:54.569807",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.538563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Drop columns from train and test DataFrames\n",
    "# train_df = train_df.drop(columns=['sessionStart', 'date'], errors='ignore')\n",
    "# test_df = test_df.drop(columns=['sessionStart', 'date'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9251c1cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.626200Z",
     "iopub.status.busy": "2025-07-22T09:29:54.625799Z",
     "iopub.status.idle": "2025-07-22T09:29:54.628704Z",
     "shell.execute_reply": "2025-07-22T09:29:54.628180Z"
    },
    "papermill": {
     "duration": 0.032883,
     "end_time": "2025-07-22T09:29:54.629631",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.596748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Select numeric features\n",
    "# numeric_cols = train_df.select_dtypes(include=['number', 'int32', 'int64', 'float64', 'UInt32'])\n",
    "\n",
    "# # Compute correlation matrix\n",
    "# corr = numeric_cols.corr()\n",
    "\n",
    "# # Plot heatmap\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n",
    "# plt.title('Correlation Heatmap of Numeric Features')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6e579fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.685345Z",
     "iopub.status.busy": "2025-07-22T09:29:54.685175Z",
     "iopub.status.idle": "2025-07-22T09:29:54.687783Z",
     "shell.execute_reply": "2025-07-22T09:29:54.687329Z"
    },
    "papermill": {
     "duration": 0.032506,
     "end_time": "2025-07-22T09:29:54.688816",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.656310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(numeric_cols.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3f4dcff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.744046Z",
     "iopub.status.busy": "2025-07-22T09:29:54.743642Z",
     "iopub.status.idle": "2025-07-22T09:29:54.746317Z",
     "shell.execute_reply": "2025-07-22T09:29:54.745802Z"
    },
    "papermill": {
     "duration": 0.031216,
     "end_time": "2025-07-22T09:29:54.747355",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.716139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(numeric_cols[['session_hour', 'session_day', 'session_month', 'session_weekofyear']].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4e24ddf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.802610Z",
     "iopub.status.busy": "2025-07-22T09:29:54.802447Z",
     "iopub.status.idle": "2025-07-22T09:29:54.805179Z",
     "shell.execute_reply": "2025-07-22T09:29:54.804685Z"
    },
    "papermill": {
     "duration": 0.031283,
     "end_time": "2025-07-22T09:29:54.806227",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.774944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_df['session_hour'].unique())\n",
    "# print(train_df['session_day'].unique())\n",
    "# print(train_df['session_month'].unique())\n",
    "# print(train_df['session_weekofyear'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e12204d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.902718Z",
     "iopub.status.busy": "2025-07-22T09:29:54.902031Z",
     "iopub.status.idle": "2025-07-22T09:29:54.905626Z",
     "shell.execute_reply": "2025-07-22T09:29:54.904937Z"
    },
    "papermill": {
     "duration": 0.032064,
     "end_time": "2025-07-22T09:29:54.906753",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.874689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# # Prepare data\n",
    "# X = train_df[numeric_cols.drop('purchaseValue', axis=1).columns]\n",
    "# y = train_df['purchaseValue']\n",
    "\n",
    "# # Fit model\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "# model.fit(X, y)\n",
    "\n",
    "# # Get feature importances\n",
    "# importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "# importances = importances.sort_values(ascending=False)\n",
    "\n",
    "# # Show top 10\n",
    "# print(\"Top 10 important numeric features:\")\n",
    "# print(importances.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cf7cc4aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:54.961767Z",
     "iopub.status.busy": "2025-07-22T09:29:54.961563Z",
     "iopub.status.idle": "2025-07-22T09:29:54.964626Z",
     "shell.execute_reply": "2025-07-22T09:29:54.963961Z"
    },
    "papermill": {
     "duration": 0.031543,
     "end_time": "2025-07-22T09:29:54.965585",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.934042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Correlation with target\n",
    "# target_corr = corr['purchaseValue'].drop('purchaseValue')  # remove self-correlation\n",
    "\n",
    "# # Sort by absolute correlation value (strongest relationships)\n",
    "# top_features = target_corr.abs().sort_values(ascending=False)\n",
    "\n",
    "# # Print top N features\n",
    "# print(\"Top correlated numeric features with 'purchaseValue':\")\n",
    "# print(top_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "21c8afa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.020152Z",
     "iopub.status.busy": "2025-07-22T09:29:55.019927Z",
     "iopub.status.idle": "2025-07-22T09:29:55.022913Z",
     "shell.execute_reply": "2025-07-22T09:29:55.022282Z"
    },
    "papermill": {
     "duration": 0.031627,
     "end_time": "2025-07-22T09:29:55.023972",
     "exception": false,
     "start_time": "2025-07-22T09:29:54.992345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cat_cols = train_df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bd6a1d12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.078278Z",
     "iopub.status.busy": "2025-07-22T09:29:55.078093Z",
     "iopub.status.idle": "2025-07-22T09:29:55.081047Z",
     "shell.execute_reply": "2025-07-22T09:29:55.080414Z"
    },
    "papermill": {
     "duration": 0.031303,
     "end_time": "2025-07-22T09:29:55.082183",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.050880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoded_df = train_df.copy()\n",
    "\n",
    "# for col in cat_cols:\n",
    "#     target_mean = encoded_df.groupby(col)['purchaseValue'].mean()\n",
    "#     encoded_df[col + '_encoded'] = encoded_df[col].map(target_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2e00a979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.137037Z",
     "iopub.status.busy": "2025-07-22T09:29:55.136871Z",
     "iopub.status.idle": "2025-07-22T09:29:55.139768Z",
     "shell.execute_reply": "2025-07-22T09:29:55.139110Z"
    },
    "papermill": {
     "duration": 0.03141,
     "end_time": "2025-07-22T09:29:55.140833",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.109423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoded_cols = [col for col in encoded_df.columns if col.endswith('_encoded')]\n",
    "# correlations = encoded_df[encoded_cols + ['purchaseValue']].corr()['purchaseValue'].drop('purchaseValue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7c6b5920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.195224Z",
     "iopub.status.busy": "2025-07-22T09:29:55.195012Z",
     "iopub.status.idle": "2025-07-22T09:29:55.197846Z",
     "shell.execute_reply": "2025-07-22T09:29:55.197242Z"
    },
    "papermill": {
     "duration": 0.031157,
     "end_time": "2025-07-22T09:29:55.198815",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.167658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correlations.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "676ba58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.252904Z",
     "iopub.status.busy": "2025-07-22T09:29:55.252742Z",
     "iopub.status.idle": "2025-07-22T09:29:55.255389Z",
     "shell.execute_reply": "2025-07-22T09:29:55.254876Z"
    },
    "papermill": {
     "duration": 0.030609,
     "end_time": "2025-07-22T09:29:55.256407",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.225798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df['purchaseValue_imputed'] = train_df['purchaseValue'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9182ac22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.311474Z",
     "iopub.status.busy": "2025-07-22T09:29:55.311281Z",
     "iopub.status.idle": "2025-07-22T09:29:55.314208Z",
     "shell.execute_reply": "2025-07-22T09:29:55.313562Z"
    },
    "papermill": {
     "duration": 0.03199,
     "end_time": "2025-07-22T09:29:55.315344",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.283354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Missing values:\", train_df['purchaseValue'].isna().sum())\n",
    "# print(\"Minimum value:\", train_df['purchaseValue'].min())\n",
    "# print(\"Maximum value:\", train_df['purchaseValue'].max())\n",
    "#  # Should return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fe6d2400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.370035Z",
     "iopub.status.busy": "2025-07-22T09:29:55.369831Z",
     "iopub.status.idle": "2025-07-22T09:29:55.372547Z",
     "shell.execute_reply": "2025-07-22T09:29:55.372008Z"
    },
    "papermill": {
     "duration": 0.031205,
     "end_time": "2025-07-22T09:29:55.373527",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.342322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# zero_ratio = (train_df['purchaseValue'] == 0).mean()\n",
    "# print(f\"Zero values: {zero_ratio:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "adaed683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.428913Z",
     "iopub.status.busy": "2025-07-22T09:29:55.428749Z",
     "iopub.status.idle": "2025-07-22T09:29:55.521976Z",
     "shell.execute_reply": "2025-07-22T09:29:55.521137Z"
    },
    "papermill": {
     "duration": 0.121916,
     "end_time": "2025-07-22T09:29:55.523138",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.401222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116023 entries, 0 to 116022\n",
      "Data columns (total 34 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   trafficSource.isTrueDirect  116023 non-null  int64  \n",
      " 1   purchaseValue               116023 non-null  float64\n",
      " 2   browser                     116023 non-null  object \n",
      " 3   trafficSource.keyword       116023 non-null  object \n",
      " 4   geoCluster                  116023 non-null  object \n",
      " 5   userId                      116023 non-null  int64  \n",
      " 6   trafficSource.campaign      116023 non-null  object \n",
      " 7   geoNetwork.networkDomain    116023 non-null  object \n",
      " 8   gclIdPresent                116023 non-null  int64  \n",
      " 9   sessionNumber               116023 non-null  int64  \n",
      " 10  geoNetwork.region           116023 non-null  object \n",
      " 11  trafficSource               116023 non-null  object \n",
      " 12  sessionId                   116023 non-null  int64  \n",
      " 13  os                          116023 non-null  object \n",
      " 14  geoNetwork.subContinent     116023 non-null  object \n",
      " 15  trafficSource.medium        116023 non-null  object \n",
      " 16  locationCountry             116023 non-null  object \n",
      " 17  geoNetwork.city             116023 non-null  object \n",
      " 18  geoNetwork.metro            116023 non-null  object \n",
      " 19  pageViews                   116023 non-null  float64\n",
      " 20  trafficSource.referralPath  116023 non-null  object \n",
      " 21  totals.bounces              116023 non-null  int64  \n",
      " 22  date                        116023 non-null  int64  \n",
      " 23  deviceType                  116023 non-null  object \n",
      " 24  userChannel                 116023 non-null  object \n",
      " 25  totalHits                   116023 non-null  int64  \n",
      " 26  sessionStart                116023 non-null  int64  \n",
      " 27  geoNetwork.continent        116023 non-null  object \n",
      " 28  device.isMobile             116023 non-null  bool   \n",
      " 29  new_visits                  116023 non-null  int64  \n",
      " 30  sessionNumber_log           116023 non-null  float64\n",
      " 31  pageViews_log               116023 non-null  float64\n",
      " 32  totalHits_log               116023 non-null  float64\n",
      " 33  avg_interaction             116023 non-null  float64\n",
      "dtypes: bool(1), float64(6), int64(10), object(17)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "04132611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.578368Z",
     "iopub.status.busy": "2025-07-22T09:29:55.578192Z",
     "iopub.status.idle": "2025-07-22T09:29:55.581009Z",
     "shell.execute_reply": "2025-07-22T09:29:55.580553Z"
    },
    "papermill": {
     "duration": 0.031046,
     "end_time": "2025-07-22T09:29:55.581920",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.550874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #lower = train_df['purchaseValue'].quantile(0.01)\n",
    "# #upper = train_df['purchaseValue'].quantile(0.99)\n",
    "# #filtered_df = train_df[(train_df['purchaseValue'] >= lower) & (train_df['purchaseValue'] <= upper)]\n",
    "\n",
    "# purchase_df = train_df[train_df['purchaseValue'] > 0].copy()\n",
    "# purchase_df['log_purchase'] = np.log1p(purchase_df['purchaseValue'])\n",
    "# print(\"Minimum value:\", purchase_df['purchaseValue'].min())\n",
    "# print(\"Maximum value:\", purchase_df['purchaseValue'].max())\n",
    "# print(\"Standard deviation:\", purchase_df['purchaseValue'].std())\n",
    "# print(\"Log standard deviation:\", purchase_df['log_purchase'].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f08a43ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.638420Z",
     "iopub.status.busy": "2025-07-22T09:29:55.638254Z",
     "iopub.status.idle": "2025-07-22T09:29:55.640946Z",
     "shell.execute_reply": "2025-07-22T09:29:55.640487Z"
    },
    "papermill": {
     "duration": 0.031441,
     "end_time": "2025-07-22T09:29:55.641900",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.610459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.histplot(data=purchase_df, x='purchaseValue', bins=100, kde=True)\n",
    "# plt.title('Distribution of Purchase Value')\n",
    "# plt.xlabel('Purchase Value')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fbd01935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.697654Z",
     "iopub.status.busy": "2025-07-22T09:29:55.697470Z",
     "iopub.status.idle": "2025-07-22T09:29:55.700020Z",
     "shell.execute_reply": "2025-07-22T09:29:55.699549Z"
    },
    "papermill": {
     "duration": 0.032132,
     "end_time": "2025-07-22T09:29:55.701054",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.668922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.boxplot(data=purchase_df, x='purchaseValue')\n",
    "# plt.title('Boxplot of Purchase Value')\n",
    "# plt.xlabel('Purchase Value')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b7ba152f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.755908Z",
     "iopub.status.busy": "2025-07-22T09:29:55.755722Z",
     "iopub.status.idle": "2025-07-22T09:29:55.758703Z",
     "shell.execute_reply": "2025-07-22T09:29:55.758087Z"
    },
    "papermill": {
     "duration": 0.031737,
     "end_time": "2025-07-22T09:29:55.759668",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.727931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.boxplot(data=train_df, x=np.log1p(train_df['purchaseValue']))\n",
    "# plt.title(\"Boxplot of Log-Transformed Purchase Value\")\n",
    "# plt.xlabel(\"Log(Purchase Value + 1)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd10beb",
   "metadata": {
    "papermill": {
     "duration": 0.026911,
     "end_time": "2025-07-22T09:29:55.813967",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.787056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "14e173ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.869298Z",
     "iopub.status.busy": "2025-07-22T09:29:55.869052Z",
     "iopub.status.idle": "2025-07-22T09:29:55.873214Z",
     "shell.execute_reply": "2025-07-22T09:29:55.872648Z"
    },
    "papermill": {
     "duration": 0.032831,
     "end_time": "2025-07-22T09:29:55.874326",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.841495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# # Step 1: Feature selection\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # Step 2: Remove top 1% outliers from target\n",
    "# #threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# #filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# purchase_df = train_df[train_df['purchaseValue'] > 0].copy()\n",
    "# purchase_df['log_purchase'] = np.log1p(purchase_df['purchaseValue'])\n",
    "\n",
    "# # Step 3: Define features (X) and target (y)\n",
    "# X = purchase_df[selected_features].copy()\n",
    "# y = purchase_df['log_purchase']\n",
    "\n",
    "# # Step 4: Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Step 5: Preprocessing setup\n",
    "# cat_cols = list(set(X_train.select_dtypes(include='object').columns) & set(cat_features))\n",
    "# num_cols = list(set(X_train.select_dtypes(include='number').columns) & set(num_features))\n",
    "\n",
    "# X_train[cat_cols] = X_train[cat_cols].astype(str)\n",
    "# X_test[cat_cols] = X_test[cat_cols].astype(str)\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('num', numeric_transformer, num_cols),\n",
    "#     ('cat', categorical_transformer, cat_cols)\n",
    "# ])\n",
    "\n",
    "# # Step 6: Build model pipeline\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', LinearRegression())\n",
    "# ])\n",
    "\n",
    "# # Step 7: Cross-validation\n",
    "# scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "# print(f\"Cross-validation R² scores: {scores}\")\n",
    "# print(f\"Average R²: {scores.mean():.4f}\")\n",
    "\n",
    "# # Step 8: Fit model and predict\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# y_train_pred = pipeline.predict(X_train)\n",
    "# y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Step 9: Evaluate model\n",
    "# r2 = r2_score(y_test, y_test_pred)\n",
    "# print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "# # Step 10: Residual plot\n",
    "# residuals = y_train - y_train_pred\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=y_train_pred, y=residuals)\n",
    "# plt.axhline(y=0, color='r', linestyle='--')\n",
    "# plt.xlabel(\"Predicted purchaseValue (Train)\")\n",
    "# plt.ylabel(\"Residuals\")\n",
    "# plt.title(\"Residual Plot (Train Data)\")\n",
    "# plt.show()\n",
    "\n",
    "# # Step 11: Predict on final test set (Kaggle/test_df)\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# y_final_pred = pipeline.predict(test_df[selected_features])\n",
    "# y_final_pred = np.maximum(0, y_final_pred)\n",
    "\n",
    "# # Step 12: Create submission file\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_final_pred)),  # Replace with test_df[\"id\"] if available\n",
    "#     \"purchaseValue\": y_final_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "378f0092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.928857Z",
     "iopub.status.busy": "2025-07-22T09:29:55.928654Z",
     "iopub.status.idle": "2025-07-22T09:29:55.932904Z",
     "shell.execute_reply": "2025-07-22T09:29:55.932438Z"
    },
    "papermill": {
     "duration": 0.032921,
     "end_time": "2025-07-22T09:29:55.933940",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.901019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# # Step 1: Feature selection\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log', 'sessionNumber_log', 'new_visits', 'totals.bounces', 'trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # Step 2: Use existing log-transformed target (do NOT filter out 0s)\n",
    "# # Assume 'purchaseValue_log' already exists in train_df\n",
    "# df = train_df.copy()\n",
    "# if 'purchaseValue_log' not in df.columns:\n",
    "#     df['purchaseValue_log'] = np.log1p(df['purchaseValue'])\n",
    "\n",
    "# # Step 3: Define features (X) and target (y)\n",
    "# X = df[selected_features].copy()\n",
    "# y = df['purchaseValue_log'].copy()\n",
    "\n",
    "# # Drop any rows with missing target\n",
    "# not_null_indices = y.notnull()\n",
    "# X = X.loc[not_null_indices].copy()\n",
    "# y = y.loc[not_null_indices].copy()\n",
    "\n",
    "# # Step 4: Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Step 5: Preprocessing setup\n",
    "# cat_cols = list(set(X_train.select_dtypes(include='object').columns) & set(cat_features))\n",
    "# num_cols = list(set(X_train.select_dtypes(include='number').columns) & set(num_features))\n",
    "\n",
    "# X_train[cat_cols] = X_train[cat_cols].astype(str)\n",
    "# X_test[cat_cols] = X_test[cat_cols].astype(str)\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('num', numeric_transformer, num_cols),\n",
    "#     ('cat', categorical_transformer, cat_cols)\n",
    "# ])\n",
    "\n",
    "# # Step 6: Build model pipeline\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', LinearRegression())\n",
    "# ])\n",
    "\n",
    "# # Step 7: Cross-validation (optional)\n",
    "# scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "# print(f\"Cross-validation R² scores: {scores}\")\n",
    "# print(f\"Average R²: {scores.mean():.4f}\")\n",
    "\n",
    "# # Step 8: Fit model and predict\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# y_train_pred = pipeline.predict(X_train)\n",
    "# y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Step 9: Evaluate model\n",
    "# # Clip negative values (rare, but possible)\n",
    "# y_test_pred = np.clip(y_test_pred, 0, np.log1p(df['purchaseValue'].max() * 1000))\n",
    "\n",
    "# r2 = r2_score(y_test, y_test_pred)\n",
    "# print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "# # Step 10: Residual plot\n",
    "# residuals = y_train - y_train_pred\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=y_train_pred, y=residuals)\n",
    "# plt.axhline(y=0, color='r', linestyle='--')\n",
    "# plt.xlabel(\"Predicted log(purchaseValue) (Train)\")\n",
    "# plt.ylabel(\"Residuals\")\n",
    "# plt.title(\"Residual Plot (Train Data)\")\n",
    "# plt.show()\n",
    "\n",
    "# # Step 11: Predict on final test set (Kaggle/test_df)\n",
    "\n",
    "# # Ensure same preprocessing as training data\n",
    "# test_df = test_df.copy()\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "\n",
    "# # Ensure test_df has all expected features (fill missing ones with np.nan)\n",
    "# for col in selected_features:\n",
    "#     if col not in test_df.columns:\n",
    "#         test_df[col] = np.nan\n",
    "\n",
    "# # Reorder to match training column order\n",
    "# X_final = test_df[selected_features]\n",
    "\n",
    "# # Predict log(purchaseValue), then inverse transform\n",
    "# log_pred = pipeline.predict(X_final)\n",
    "# log_pred = np.clip(log_pred, 0, None)  # Clip any negatives just in case\n",
    "\n",
    "# # Convert from log scale to original purchaseValue\n",
    "# y_final_pred = np.expm1(log_pred)\n",
    "\n",
    "# # Step 12: Create submission file\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": test_df[\"id\"] if \"id\" in test_df.columns else np.arange(len(y_final_pred)),\n",
    "#     \"purchaseValue\": y_final_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\\n\")\n",
    "\n",
    "# # Optional: preview\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0613158f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:29:55.988707Z",
     "iopub.status.busy": "2025-07-22T09:29:55.988516Z",
     "iopub.status.idle": "2025-07-22T09:30:37.935609Z",
     "shell.execute_reply": "2025-07-22T09:30:37.934745Z"
    },
    "papermill": {
     "duration": 42.003473,
     "end_time": "2025-07-22T09:30:37.964480",
     "exception": false,
     "start_time": "2025-07-22T09:29:55.961007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on train split...\n",
      "\n",
      "Validation Set Evaluation:\n",
      "Accuracy : 0.9525\n",
      "Precision: 0.8612\n",
      "Recall   : 0.9183\n",
      "F1 Score : 0.8888\n",
      "ROC AUC  : 0.9828\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define the target variable\n",
    "train_df['purchased'] = (train_df['purchaseValue'] > 0).astype(int)\n",
    "\n",
    "# Select features\n",
    "numerical_features = [\n",
    "    'sessionNumber_log',\n",
    "    'pageViews_log',\n",
    "    'totalHits_log',\n",
    "    'trafficSource.adwordsClickInfo.page',\n",
    "    'new_visits', 'totals.bounces', 'trafficSource.isTrueDirect'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "    'userChannel', 'trafficSource.medium'\n",
    "]\n",
    "\n",
    "# Filter only columns that exist\n",
    "all_features = numerical_features + categorical_features\n",
    "available_features = [col for col in all_features if col in train_df.columns]\n",
    "numerical_features = [col for col in numerical_features if col in available_features]\n",
    "categorical_features = [col for col in categorical_features if col in available_features]\n",
    "\n",
    "X = train_df[available_features]\n",
    "y = train_df['purchased']\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', SimpleImputer(strategy='mean'), numerical_features),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_features)\n",
    "])\n",
    "\n",
    "# Classification pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train\n",
    "print(\"Training model on train split...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "y_val_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"\\nValidation Set Evaluation:\")\n",
    "print(f\"Accuracy : {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"F1 Score : {f1_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"ROC AUC  : {roc_auc_score(y_val, y_val_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "574eb644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:30:38.019687Z",
     "iopub.status.busy": "2025-07-22T09:30:38.019455Z",
     "iopub.status.idle": "2025-07-22T09:30:38.035291Z",
     "shell.execute_reply": "2025-07-22T09:30:38.034653Z"
    },
    "papermill": {
     "duration": 0.044682,
     "end_time": "2025-07-22T09:30:38.036409",
     "exception": false,
     "start_time": "2025-07-22T09:30:37.991727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trafficSource.isTrueDirect</th>\n",
       "      <th>purchaseValue</th>\n",
       "      <th>browser</th>\n",
       "      <th>trafficSource.keyword</th>\n",
       "      <th>geoCluster</th>\n",
       "      <th>userId</th>\n",
       "      <th>trafficSource.campaign</th>\n",
       "      <th>geoNetwork.networkDomain</th>\n",
       "      <th>gclIdPresent</th>\n",
       "      <th>sessionNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>totalHits</th>\n",
       "      <th>sessionStart</th>\n",
       "      <th>geoNetwork.continent</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>new_visits</th>\n",
       "      <th>sessionNumber_log</th>\n",
       "      <th>pageViews_log</th>\n",
       "      <th>totalHits_log</th>\n",
       "      <th>avg_interaction</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Others</td>\n",
       "      <td>Region_2</td>\n",
       "      <td>61421</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>domain1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1500100799</td>\n",
       "      <td>Americas</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Others</td>\n",
       "      <td>Region_3</td>\n",
       "      <td>72287</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>domain3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1495262065</td>\n",
       "      <td>Americas</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Others</td>\n",
       "      <td>Region_2</td>\n",
       "      <td>25180</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>domain1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1508510328</td>\n",
       "      <td>Europe</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Others</td>\n",
       "      <td>Region_4</td>\n",
       "      <td>41295</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>domain3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1483431838</td>\n",
       "      <td>Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>88950000.0</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Others</td>\n",
       "      <td>Region_3</td>\n",
       "      <td>113697</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>domain1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>1475804633</td>\n",
       "      <td>Americas</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trafficSource.isTrueDirect  purchaseValue            browser  \\\n",
       "0                           0            0.0               Edge   \n",
       "1                           1            0.0             Chrome   \n",
       "2                           1            0.0             Chrome   \n",
       "3                           0            0.0  Internet Explorer   \n",
       "4                           1     88950000.0             Chrome   \n",
       "\n",
       "  trafficSource.keyword geoCluster  userId trafficSource.campaign  \\\n",
       "0                Others   Region_2   61421              (not set)   \n",
       "1                Others   Region_3   72287              (not set)   \n",
       "2                Others   Region_2   25180              (not set)   \n",
       "3                Others   Region_4   41295              (not set)   \n",
       "4                Others   Region_3  113697              (not set)   \n",
       "\n",
       "  geoNetwork.networkDomain  gclIdPresent  sessionNumber  ... totalHits  \\\n",
       "0                  domain1             0              1  ...         1   \n",
       "1                  domain3             0              1  ...         1   \n",
       "2                  domain1             0              2  ...         6   \n",
       "3                  domain3             0              1  ...         1   \n",
       "4                  domain1             0              1  ...        66   \n",
       "\n",
       "  sessionStart  geoNetwork.continent device.isMobile new_visits  \\\n",
       "0   1500100799              Americas           False          1   \n",
       "1   1495262065              Americas           False          1   \n",
       "2   1508510328                Europe           False          0   \n",
       "3   1483431838                  Asia           False          1   \n",
       "4   1475804633              Americas           False          1   \n",
       "\n",
       "  sessionNumber_log pageViews_log totalHits_log avg_interaction  purchased  \n",
       "0          0.693147      0.693147      0.693147             1.0          0  \n",
       "1          0.693147      0.693147      0.693147             1.0          0  \n",
       "2          1.098612      1.945910      1.945910             6.0          0  \n",
       "3          0.693147      0.693147      0.693147             1.0          0  \n",
       "4          0.693147      4.007333      4.204693            60.0          1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "032e3673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:30:38.091882Z",
     "iopub.status.busy": "2025-07-22T09:30:38.091705Z",
     "iopub.status.idle": "2025-07-22T09:31:24.464419Z",
     "shell.execute_reply": "2025-07-22T09:31:24.463665Z"
    },
    "papermill": {
     "duration": 46.429374,
     "end_time": "2025-07-22T09:31:24.493417",
     "exception": false,
     "start_time": "2025-07-22T09:30:38.064043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training regression model on purchases only...\n",
      "\n",
      "Regression Model Evaluation on Validation Set (only for purchase > 0):\n",
      "R² Score : 0.4417\n",
      "RMSE     : 295254548.93\n",
      "MAE      : 111782914.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Filter training data to only rows where purchase happened\n",
    "X_train_reg = X_train[y_train == 1].copy()\n",
    "y_train_reg = train_df.loc[X_train_reg.index, 'purchaseValue']\n",
    "\n",
    "# Same for validation set\n",
    "X_val_reg = X_val[y_val == 1].copy()\n",
    "y_val_reg = train_df.loc[X_val_reg.index, 'purchaseValue']\n",
    "\n",
    "# Preprocessing for regression (same as before)\n",
    "preprocessor_reg = ColumnTransformer(transformers=[\n",
    "    ('num', SimpleImputer(strategy='mean'), numerical_features),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_features)\n",
    "])\n",
    "\n",
    "# Regression pipeline\n",
    "regression_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_reg),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining regression model on purchases only...\")\n",
    "regression_pipeline.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_reg = regression_pipeline.predict(X_val_reg)\n",
    "\n",
    "# Evaluate regression performance\n",
    "r2 = r2_score(y_val_reg, y_val_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_val_reg, y_val_pred_reg))\n",
    "mae = mean_absolute_error(y_val_reg, y_val_pred_reg)\n",
    "\n",
    "print(\"\\nRegression Model Evaluation on Validation Set (only for purchase > 0):\")\n",
    "print(f\"R² Score : {r2:.4f}\")\n",
    "print(f\"RMSE     : {rmse:.2f}\")\n",
    "print(f\"MAE      : {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f3ac90f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:31:24.549052Z",
     "iopub.status.busy": "2025-07-22T09:31:24.548814Z",
     "iopub.status.idle": "2025-07-22T09:33:23.256768Z",
     "shell.execute_reply": "2025-07-22T09:33:23.256135Z"
    },
    "papermill": {
     "duration": 118.766812,
     "end_time": "2025-07-22T09:33:23.287445",
     "exception": false,
     "start_time": "2025-07-22T09:31:24.520633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Submission file created: 'submission.csv'\n",
      "   purchaseValue\n",
      "0   2.709320e+07\n",
      "1   3.201938e+06\n",
      "2   0.000000e+00\n",
      "3   4.518660e+06\n",
      "4   0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# STEP 1: Setup\n",
    "train_df['purchased'] = (train_df['purchaseValue'] > 0).astype(int)\n",
    "\n",
    "# Set up features (adjust these lists as per your preprocessing)\n",
    "numerical_features = ['sessionNumber_log', 'pageViews_log', 'totalHits_log',\n",
    "                      'trafficSource.adwordsClickInfo.page', 'new_visits', 'totals.bounces', 'trafficSource.isTrueDirect']\n",
    "categorical_features = ['trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "                        'userChannel', 'trafficSource.medium']\n",
    "\n",
    "all_features = numerical_features + categorical_features\n",
    "final_features = [col for col in all_features if col in train_df.columns and col in test_df.columns]\n",
    "numerical_features = [col for col in final_features if col in numerical_features]\n",
    "categorical_features = [col for col in final_features if col in categorical_features]\n",
    "\n",
    "X_train_full = train_df[final_features]\n",
    "y_classification = train_df['purchased']\n",
    "\n",
    "# STEP 2: Classification model\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='mean'), numerical_features),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_features)\n",
    "])\n",
    "\n",
    "classification_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "classification_model.fit(X_train_full, y_classification)\n",
    "\n",
    "# Predict purchase probability on test data\n",
    "X_test_final = test_df[final_features]\n",
    "test_pred_purchase_proba = classification_model.predict_proba(X_test_final)[:, 1]\n",
    "test_df['predicted_purchase_probability'] = test_pred_purchase_proba\n",
    "\n",
    "# STEP 3: Regression model (only on purchases)\n",
    "purchased_df = train_df[train_df['purchased'] == 1].copy()\n",
    "X_reg_train = purchased_df[final_features]\n",
    "y_reg_train = purchased_df['purchaseValue']\n",
    "\n",
    "regression_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "regression_model.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "# Predict purchase value given purchase (for test set)\n",
    "test_pred_value_if_purchase = regression_model.predict(X_test_final)\n",
    "test_df['predicted_purchase_value_given_purchase'] = test_pred_value_if_purchase\n",
    "\n",
    "# STEP 4: Final predicted purchase value\n",
    "test_df['purchaseValue'] = test_df['predicted_purchase_probability'] * test_df['predicted_purchase_value_given_purchase']\n",
    "\n",
    "# STEP 5: Prepare submission\n",
    "submission_df = test_df[['purchaseValue']].copy()\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Submission file created: 'submission.csv'\")\n",
    "print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "876e5e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.343500Z",
     "iopub.status.busy": "2025-07-22T09:33:23.343300Z",
     "iopub.status.idle": "2025-07-22T09:33:23.347559Z",
     "shell.execute_reply": "2025-07-22T09:33:23.347019Z"
    },
    "papermill": {
     "duration": 0.033045,
     "end_time": "2025-07-22T09:33:23.348523",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.315478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "# # Assume train_df already loaded and preprocessed with:\n",
    "# # - 'purchaseValue' column\n",
    "# # - transformed log features: sessionNumber_log, pageViews_log, totalHits_log\n",
    "\n",
    "# # 1. Create binary purchase label\n",
    "# train_df['purchased'] = (train_df['purchaseValue'] > 0).astype(int)\n",
    "\n",
    "# # 2. Define feature columns\n",
    "# numerical_features = ['sessionNumber_log', 'pageViews_log', 'totalHits_log',\n",
    "#                       'trafficSource.adwordsClickInfo.page', 'new_visits', 'totals.bounces', 'trafficSource.isTrueDirect']\n",
    "# categorical_features = ['trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#                         'userChannel', 'trafficSource.medium']\n",
    "\n",
    "# # Filter actual features available\n",
    "# numerical_features = [col for col in numerical_features if col in train_df.columns]\n",
    "# categorical_features = [col for col in categorical_features if col in train_df.columns]\n",
    "# all_features = numerical_features + categorical_features\n",
    "\n",
    "# # 3. Train-test split (for evaluation)\n",
    "# X = train_df[all_features]\n",
    "# y_class = train_df['purchased']\n",
    "# y_reg_full = train_df['purchaseValue']\n",
    "\n",
    "# X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "#     X, y_class, test_size=0.25, random_state=42\n",
    "# )\n",
    "\n",
    "# # 4. Classifier pipeline\n",
    "# clf_preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', 'passthrough', numerical_features),\n",
    "#         ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# clf_pipeline = Pipeline([\n",
    "#     ('preprocessor', clf_preprocessor),\n",
    "#     ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
    "# ])\n",
    "\n",
    "# clf_pipeline.fit(X_train_class, y_train_class)\n",
    "# y_test_probs = clf_pipeline.predict_proba(X_test_class)[:, 1]  # Probability of purchase\n",
    "\n",
    "# # 5. Train regression model on only rows with purchases\n",
    "# X_train_reg = X_train_class[y_train_class == 1]\n",
    "# y_train_reg = train_df.loc[X_train_reg.index, 'purchaseValue']\n",
    "\n",
    "# X_test_reg = X_test_class.copy()  # we predict for all, multiply with prob\n",
    "\n",
    "# reg_preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', 'passthrough', numerical_features),\n",
    "#         ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# reg_pipeline = Pipeline([\n",
    "#     ('preprocessor', reg_preprocessor),\n",
    "#     ('regressor', RandomForestRegressor(random_state=42, n_estimators=100))\n",
    "# ])\n",
    "\n",
    "# reg_pipeline.fit(X_train_reg, y_train_reg)\n",
    "# y_test_reg_pred = reg_pipeline.predict(X_test_reg)\n",
    "\n",
    "# # 6. Combine classifier and regressor outputs\n",
    "# final_pred = y_test_probs * y_test_reg_pred\n",
    "\n",
    "# # 7. Evaluate against true purchaseValue\n",
    "# true_y = train_df.loc[X_test_class.index, 'purchaseValue']\n",
    "# r2 = r2_score(true_y, final_pred)\n",
    "\n",
    "# print(f\"\\nTwo-Part Model Test R²: {r2:.4f}\")\n",
    "#print(f\"Classifier Accuracy: {accuracy_score(y_test_class, clf_pipeline.predict(X_test_class)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bd45ceb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.403907Z",
     "iopub.status.busy": "2025-07-22T09:33:23.403738Z",
     "iopub.status.idle": "2025-07-22T09:33:23.406503Z",
     "shell.execute_reply": "2025-07-22T09:33:23.405994Z"
    },
    "papermill": {
     "duration": 0.031652,
     "end_time": "2025-07-22T09:33:23.407570",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.375918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Numerical features available in train_df:\", [col for col in numerical_features_for_classification if col in train_df.columns])\n",
    "# print(\"Numerical features available in test_df:\", [col for col in numerical_features_for_classification if col in test_df.columns])\n",
    "# print(\"Categorical features available in train_df:\", [col for col in categorical_features_for_classification if col in train_df.columns])\n",
    "# print(\"Categorical features available in test_df:\", [col for col in categorical_features_for_classification if col in test_df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8be1cf0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.463409Z",
     "iopub.status.busy": "2025-07-22T09:33:23.463235Z",
     "iopub.status.idle": "2025-07-22T09:33:23.466265Z",
     "shell.execute_reply": "2025-07-22T09:33:23.465562Z"
    },
    "papermill": {
     "duration": 0.031871,
     "end_time": "2025-07-22T09:33:23.467299",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.435428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Train_df columns:\")\n",
    "# print(train_df.columns.tolist())\n",
    "\n",
    "# print(\"\\nTest_df columns:\")\n",
    "# print(test_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7126dcb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.523601Z",
     "iopub.status.busy": "2025-07-22T09:33:23.523403Z",
     "iopub.status.idle": "2025-07-22T09:33:23.527306Z",
     "shell.execute_reply": "2025-07-22T09:33:23.526625Z"
    },
    "papermill": {
     "duration": 0.032965,
     "end_time": "2025-07-22T09:33:23.528324",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.495359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# # --- assume from previous code ---\n",
    "# # train_df, test_df, selected_features, categorical_features_for_classification, numerical_features_for_classification\n",
    "# # clf_pipeline: classification pipeline fitted already on full train data predicting purchase probability\n",
    "# # X_test: prepared test features dataframe for prediction\n",
    "\n",
    "# # Step 1: Add purchased flag to training data\n",
    "# train_df['purchased'] = (train_df['purchaseValue'] > 0).astype(int)\n",
    "\n",
    "# # Step 2: Build regression model for purchase value > 0\n",
    "\n",
    "# # Subset training data for purchase > 0\n",
    "# purchased_train_df = train_df[train_df['purchased'] == 1].copy()\n",
    "\n",
    "# # Define regression features (use your lists or reuse classification features)\n",
    "# regression_features_with_transformed = [\n",
    "#     'sessionNumber_log',\n",
    "#     'pageViews_log',\n",
    "#     'totalHits_log',\n",
    "#     'trafficSource.adwordsClickInfo.page',\n",
    "#     'new_visits', 'totals.bounces', 'trafficSource.isTrueDirect'\n",
    "# ] + [col for col in categorical_features_for_classification if col in purchased_train_df.columns]\n",
    "\n",
    "# final_regression_features = [col for col in regression_features_with_transformed if col in purchased_train_df.columns]\n",
    "\n",
    "# numerical_features_for_regression = [col for col in final_regression_features if col in numerical_features_for_classification]\n",
    "# categorical_features_for_regression = [col for col in final_regression_features if col in categorical_features_for_classification]\n",
    "\n",
    "# X_reg_train = purchased_train_df[final_regression_features]\n",
    "# y_reg = purchased_train_df['purchaseValue']  # original target, no log here but can be changed if you want\n",
    "\n",
    "# # Create regression preprocessing pipeline\n",
    "# regression_preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', 'passthrough', numerical_features_for_regression),\n",
    "#         ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_for_regression)\n",
    "#     ],\n",
    "#     remainder='passthrough'\n",
    "# )\n",
    "\n",
    "# regression_model = Pipeline([\n",
    "#     ('preprocessor', regression_preprocessor),\n",
    "#     ('regressor', RandomForestRegressor(random_state=42, n_estimators=100))\n",
    "# ])\n",
    "\n",
    "# print(\"Training regression model on purchased samples...\")\n",
    "# regression_model.fit(X_reg_train, y_reg)\n",
    "# print(\"Regression model training complete.\")\n",
    "\n",
    "# # Step 3: Predict purchase value for test data (conditional on purchase)\n",
    "# X_reg_test = X_test[final_regression_features]\n",
    "# test_predicted_purchase_value_given_purchase = regression_model.predict(X_reg_test)\n",
    "\n",
    "# # Step 4: Combine predictions from classification and regression\n",
    "\n",
    "# # Assuming you have already predicted purchase probability on test set:\n",
    "# # test_df['predicted_purchase_probability'] = clf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# test_df['predicted_purchase_value_given_purchase'] = test_predicted_purchase_value_given_purchase\n",
    "\n",
    "# test_df['final_predicted_purchase_value'] = test_df['predicted_purchase_probability'] * test_df['predicted_purchase_value_given_purchase']\n",
    "\n",
    "# print(\"\\nFinal combined predictions added to test_df:\")\n",
    "# print(test_df[['predicted_purchase_probability', 'predicted_purchase_value_given_purchase', 'final_predicted_purchase_value']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "df2fee4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.583989Z",
     "iopub.status.busy": "2025-07-22T09:33:23.583654Z",
     "iopub.status.idle": "2025-07-22T09:33:23.587352Z",
     "shell.execute_reply": "2025-07-22T09:33:23.586724Z"
    },
    "papermill": {
     "duration": 0.032299,
     "end_time": "2025-07-22T09:33:23.588416",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.556117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userChannel', 'date', 'browser', 'deviceType', 'device.isMobile', 'os',\n",
      "       'geoNetwork.city', 'geoNetwork.continent', 'locationCountry',\n",
      "       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\n",
      "       'geoNetwork.subContinent', 'totals.bounces', 'totalHits', 'new_visits',\n",
      "       'pageViews', 'trafficSource.campaign', 'trafficSource.isTrueDirect',\n",
      "       'trafficSource.keyword', 'trafficSource.medium',\n",
      "       'trafficSource.referralPath', 'trafficSource', 'sessionId',\n",
      "       'sessionNumber', 'sessionStart', 'userId', 'geoCluster', 'gclIdPresent',\n",
      "       'sessionNumber_log', 'pageViews_log', 'totalHits_log',\n",
      "       'avg_interaction', 'predicted_purchase_probability',\n",
      "       'predicted_purchase_value_given_purchase', 'purchaseValue'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f27a9cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.644055Z",
     "iopub.status.busy": "2025-07-22T09:33:23.643856Z",
     "iopub.status.idle": "2025-07-22T09:33:23.646755Z",
     "shell.execute_reply": "2025-07-22T09:33:23.646104Z"
    },
    "papermill": {
     "duration": 0.031833,
     "end_time": "2025-07-22T09:33:23.647766",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.615933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(test_df['sessionId'].is_unique)  # True or False\n",
    "# print(test_df['userId'].is_unique)     # True or False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7df81d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.703830Z",
     "iopub.status.busy": "2025-07-22T09:33:23.703637Z",
     "iopub.status.idle": "2025-07-22T09:33:23.706558Z",
     "shell.execute_reply": "2025-07-22T09:33:23.706042Z"
    },
    "papermill": {
     "duration": 0.031929,
     "end_time": "2025-07-22T09:33:23.707505",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.675576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# num_features_select = X_train_transformed.shape[1]\n",
    "\n",
    "# rfe = RFE(LogisticRegression(),\n",
    "#           n_features_to_select=num_features_select-250)\n",
    "# rfe.fit(X_train_transformed, y_train)\n",
    "\n",
    "# # Get the mask of selected features (True = kept, False = removed)\n",
    "# selected_mask = rfe.support_\n",
    "\n",
    "# # Get the names or indices of selected features\n",
    "# selected_features = X_train_transformed.columns[selected_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d2c27f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.763039Z",
     "iopub.status.busy": "2025-07-22T09:33:23.762845Z",
     "iopub.status.idle": "2025-07-22T09:33:23.765684Z",
     "shell.execute_reply": "2025-07-22T09:33:23.765213Z"
    },
    "papermill": {
     "duration": 0.031692,
     "end_time": "2025-07-22T09:33:23.766695",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.735003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFECV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Create the model\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# # Use StratifiedKFold for classification tasks\n",
    "# cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# # Recursive Feature Elimination with Cross-Validation\n",
    "# rfecv = RFECV(estimator=model, step=1, cv=cv, scoring='accuracy')  # or 'roc_auc' etc.\n",
    "# rfecv.fit(X_train_transformed, y_train)\n",
    "\n",
    "# # Get optimal number of features\n",
    "# print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "\n",
    "# # Features selected\n",
    "# selected_features = X_train_transformed.columns[rfecv.support_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadaca7",
   "metadata": {
    "papermill": {
     "duration": 0.027374,
     "end_time": "2025-07-22T09:33:23.821972",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.794598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b7380368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.878112Z",
     "iopub.status.busy": "2025-07-22T09:33:23.877904Z",
     "iopub.status.idle": "2025-07-22T09:33:23.882361Z",
     "shell.execute_reply": "2025-07-22T09:33:23.881784Z"
    },
    "papermill": {
     "duration": 0.033854,
     "end_time": "2025-07-22T09:33:23.883296",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.849442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# # === CONFIG ===\n",
    "# USE_LOG_TRANSFORM = True\n",
    "\n",
    "# # === Step 1: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log', 'sessionNumber_log', 'new_visits', 'totals.bounces', 'trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # === Step 2: Prepare data ===\n",
    "# train_df = train_df.copy()\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     train_df['purchaseValue_log'] = np.log1p(train_df['purchaseValue'])\n",
    "\n",
    "# X = train_df[selected_features].copy()\n",
    "# y = train_df['purchaseValue_log'] if USE_LOG_TRANSFORM else train_df['purchaseValue']\n",
    "\n",
    "# # Drop rows with missing target\n",
    "# not_null_mask = y.notnull()\n",
    "# X = X.loc[not_null_mask]\n",
    "# y = y.loc[not_null_mask]\n",
    "\n",
    "# # === Step 3: Train-test split ===\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # === Step 4: Preprocessing setup ===\n",
    "# X_train[cat_features] = X_train[cat_features].astype(str)\n",
    "# X_test[cat_features] = X_test[cat_features].astype(str)\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Add this line\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('num', numeric_transformer, num_features),\n",
    "#     ('cat', categorical_transformer, cat_features)\n",
    "# ])\n",
    "\n",
    "# # === Step 5: Ridge + GridSearch ===\n",
    "# ridge = Ridge(solver='cholesky', fit_intercept=False)\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', Ridge(solver='cholesky', fit_intercept=False))\n",
    "#    ])\n",
    "\n",
    "# param_grid = {\n",
    "#      'regressor__alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "#  }\n",
    "\n",
    "# grid_search = GridSearchCV(pipeline,param_grid, cv=5, scoring='r2',error_score='raise')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best alpha:\", grid_search.best_params_['regressor__alpha'])\n",
    "# print(f\"Best CV R²: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# # === Step 6: Evaluation ===\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# # if USE_LOG_TRANSFORM:\n",
    "# #     y_pred_log = np.clip(y_pred_log, 0, None)\n",
    "# #     y_pred = np.expm1(y_pred_log)\n",
    "# #     y_test_actual = np.expm1(y_test)\n",
    "# # else:\n",
    "# y_pred = y_pred_log\n",
    "# y_test_actual = y_test\n",
    "\n",
    "# test_r2 = r2_score(y_test_actual, y_pred)\n",
    "# print(\"Test R² Score: log\", test_r2)\n",
    "\n",
    "# test_r2 = r2_score(y_test, y_pred)\n",
    "# print(\"Test R² Score:\", test_r2)\n",
    "\n",
    "# # === Step 7: Predict on test_df and Submit ===\n",
    "# test_df = test_df.copy()\n",
    "# test_df[cat_features] = test_df[cat_features].astype(str)\n",
    "\n",
    "# # Fill missing columns if needed\n",
    "# for col in selected_features:\n",
    "#     if col not in test_df.columns:\n",
    "#         test_df[col] = np.nan\n",
    "\n",
    "# X_final = test_df[selected_features]\n",
    "# y_test_pred_raw = best_model.predict(X_final)\n",
    "\n",
    "# # if USE_LOG_TRANSFORM:\n",
    "# #     y_test_pred_raw = np.clip(y_test_pred_raw, 0, None)\n",
    "# #     y_test_pred = np.expm1(y_test_pred_raw)\n",
    "# # else:\n",
    "# y_test_pred = y_test_pred_raw\n",
    "\n",
    "# y_test_pred = np.maximum(0, y_test_pred)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": test_df[\"id\"] if \"id\" in test_df.columns else np.arange(len(y_test_pred)),\n",
    "#     \"purchaseValue\": y_test_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "# print(submission.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daef83",
   "metadata": {
    "papermill": {
     "duration": 0.027344,
     "end_time": "2025-07-22T09:33:23.937897",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.910553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Lasso with Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "00f1017d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:23.993686Z",
     "iopub.status.busy": "2025-07-22T09:33:23.993172Z",
     "iopub.status.idle": "2025-07-22T09:33:23.997327Z",
     "shell.execute_reply": "2025-07-22T09:33:23.996758Z"
    },
    "papermill": {
     "duration": 0.033131,
     "end_time": "2025-07-22T09:33:23.998432",
     "exception": false,
     "start_time": "2025-07-22T09:33:23.965301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso, ElasticNet\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # Define the model here: switch between Lasso or ElasticNet\n",
    "# regressor = ElasticNet()  # or Lasso()\n",
    "\n",
    "# # Define the param grid depending on model type\n",
    "# if isinstance(regressor, Lasso):\n",
    "#     param_grid = {\n",
    "#         'regressor__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "#         'regressor__max_iter': [1000, 5000, 10000]\n",
    "#     }\n",
    "# else:  # ElasticNet\n",
    "#     param_grid = {\n",
    "#         'regressor__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "#         'regressor__l1_ratio': [0.1, 0.5, 0.9],\n",
    "#         'regressor__max_iter': [1000, 5000, 10000]\n",
    "#     }\n",
    "\n",
    "# # Full pipeline\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', regressor)\n",
    "# ])\n",
    "\n",
    "# # Grid search with R² scoring on log scale\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=model_pipeline,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='r2',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # Fit the model\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Report best parameters and scores\n",
    "# print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation R² score (log scale):\", grid_search.best_score_)\n",
    "\n",
    "# # Predict on test set using the best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# # Optionally clip extreme log predictions\n",
    "# CLIP_MIN, CLIP_MAX = 0, 20\n",
    "# y_pred_log = np.clip(y_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "# # Evaluate on log-transformed scale\n",
    "# test_r2_log = r2_score(y_test, y_pred_log)\n",
    "# test_mse_log = mean_squared_error(y_test, y_pred_log)\n",
    "\n",
    "# print(\"Test MSE (log scale):\", test_mse_log)\n",
    "# print(\"Test R² (log scale):\", test_r2_log)\n",
    "\n",
    "# # ========== Residual Plot ==========\n",
    "# y_train_pred_log = best_model.predict(X_train)\n",
    "# y_train_pred_log = np.clip(y_train_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# residuals = y_train - y_train_pred_log  # Residuals on log scale\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=y_train_pred_log, y=residuals)\n",
    "# plt.axhline(y=0, color='r', linestyle='--')\n",
    "# plt.xlabel(\"Predicted log(purchaseValue) (Train)\")\n",
    "# plt.ylabel(\"Residuals (log scale)\")\n",
    "# plt.title(f\"Residual Plot (Train Data, {'ElasticNet' if isinstance(regressor, ElasticNet) else 'Lasso'})\")\n",
    "# plt.show()\n",
    "\n",
    "# # ========== Final Predictions ==========\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# y_final_pred_log = best_model.predict(test_df[selected_features])\n",
    "# y_final_pred_log = np.clip(y_final_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# y_final_pred = np.expm1(y_final_pred_log)\n",
    "# y_final_pred = np.maximum(0, y_final_pred)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_final_pred)),\n",
    "#     \"purchaseValue\": y_final_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809497d",
   "metadata": {
    "papermill": {
     "duration": 0.027566,
     "end_time": "2025-07-22T09:33:24.053436",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.025870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "99e0cdfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.108754Z",
     "iopub.status.busy": "2025-07-22T09:33:24.108588Z",
     "iopub.status.idle": "2025-07-22T09:33:24.113380Z",
     "shell.execute_reply": "2025-07-22T09:33:24.112841Z"
    },
    "papermill": {
     "duration": 0.033681,
     "end_time": "2025-07-22T09:33:24.114404",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.080723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20 \n",
    "# # === Step 0: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # # Step 2: Remove top 1% outliers from target\n",
    "# # threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# # filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# purchase_df = train_df[train_df['purchaseValue'] > 0].copy()\n",
    "# #purchase_df['log_purchase'] = np.log1p(purchase_df['purchaseValue'])\n",
    "\n",
    "# # Step 3: Define features (X) and log-transformed target (y)\n",
    "# X = purchase_df[selected_features].copy()\n",
    "# y = np.log1p(purchase_df['purchaseValue']) \n",
    "\n",
    "# # Step 3: Define features (X) and log-transformed target (y)\n",
    "# # X = filtered_df[selected_features].copy()\n",
    "# # y = np.log1p(filtered_df['purchaseValue'])  # log1p ensures 0 is handled safely\n",
    "\n",
    "# # Step 4: Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Step 5: Preprocessing setup\n",
    "# cat_cols = list(set(X_train.select_dtypes(include='object').columns) & set(cat_features))\n",
    "# num_cols = list(set(X_train.select_dtypes(include='number').columns) & set(num_features))\n",
    "\n",
    "# X_train[cat_cols] = X_train[cat_cols].astype(str)\n",
    "# X_test[cat_cols] = X_test[cat_cols].astype(str)\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('num', numeric_transformer, num_cols),\n",
    "#     ('cat', categorical_transformer, cat_cols)\n",
    "# ])\n",
    "\n",
    "# # === Step 4: Create pipeline with RandomForestRegressor ===\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "# ])\n",
    "\n",
    "# # === Step 5: Train the model ===\n",
    "# model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # === Step 6: Predict on test set ===\n",
    "# y_pred_log = model_pipeline.predict(X_test)\n",
    "# y_pred_log_clipped = np.clip(y_pred_log, CLIP_MIN_LOG, CLIP_MAX_LOG)\n",
    "# y_pred = np.expm1(y_pred_log_clipped) if USE_LOG_TRANSFORM else y_pred_log_clipped\n",
    "\n",
    "# y_test_log_clipped = np.clip(y_test, CLIP_MIN_LOG, CLIP_MAX_LOG)\n",
    "# y_test_original = np.expm1(y_test_log_clipped) if USE_LOG_TRANSFORM else y_test_log_clipped\n",
    "\n",
    "# # === Step 7: Evaluation ===\n",
    "# mse = mean_squared_error(y_test_original, y_pred)\n",
    "# r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "# print(f\"Test MSE (original scale): {mse:.4f}\")\n",
    "# print(f\"Test R² (original scale): {r2:.4f}\")\n",
    "\n",
    "# # === Step 8: Residual plot ===\n",
    "# y_train_pred_log = model_pipeline.predict(X_train)\n",
    "# y_train_pred = np.expm1(np.clip(y_train_pred_log, CLIP_MIN_LOG, CLIP_MAX_LOG))\n",
    "# y_train_actual = np.expm1(np.clip(y_train, CLIP_MIN_LOG, CLIP_MAX_LOG))\n",
    "\n",
    "# residuals = y_train_actual - y_train_pred\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=y_train_pred, y=residuals)\n",
    "# plt.axhline(y=0, color='red', linestyle='--')\n",
    "# plt.xlabel(\"Predicted purchaseValue (Train)\")\n",
    "# plt.ylabel(\"Residuals\")\n",
    "# plt.title(\"Residual Plot (Train Data, Random Forest)\")\n",
    "# plt.show()\n",
    "\n",
    "# # === Step 9: Predict on test_df for submission ===\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# X_kaggle_test = test_df[selected_features]\n",
    "# y_test_pred_raw = model_pipeline.predict(X_kaggle_test)\n",
    "\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_test_pred_raw = np.clip(y_test_pred_raw, CLIP_MIN_LOG, CLIP_MAX_LOG)\n",
    "#     y_test_pred = np.expm1(y_test_pred_raw)\n",
    "# else:\n",
    "#     y_test_pred = y_test_pred_raw\n",
    "\n",
    "# # Clip to ensure positive range and max value\n",
    "# y_test_pred = np.maximum(0, y_test_pred)\n",
    "# y_test_pred = np.minimum(y_test_pred, 1e6)\n",
    "\n",
    "# # === Step 10: Submission file ===\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_test_pred)),  # Replace with test_df['id'] if available\n",
    "#     \"purchaseValue\": y_test_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"✅ Submission file created: 'submission.csv'\")\n",
    "# print(submission.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7d5e0a33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.173015Z",
     "iopub.status.busy": "2025-07-22T09:33:24.172846Z",
     "iopub.status.idle": "2025-07-22T09:33:24.176718Z",
     "shell.execute_reply": "2025-07-22T09:33:24.176231Z"
    },
    "papermill": {
     "duration": 0.033032,
     "end_time": "2025-07-22T09:33:24.177690",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.144658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # ========== Define Random Forest Model and Hyperparameter Grid ==========\n",
    "# regressor = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [100, 200],\n",
    "#     'regressor__max_depth': [5, 10, None],\n",
    "#     'regressor__min_samples_split': [2, 5],\n",
    "#     'regressor__min_samples_leaf': [1, 2]\n",
    "# }\n",
    "\n",
    "# # ========== Pipeline ==========\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', regressor)\n",
    "# ])\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=model_pipeline, \n",
    "#     param_grid=param_grid,\n",
    "#     scoring='r2',  # log-scale R²\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # ========== Train ==========\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation R² score (log scale):\", grid_search.best_score_)\n",
    "\n",
    "# # ========== Predict ==========\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# CLIP_MIN, CLIP_MAX = 0, 20\n",
    "# y_pred_log = np.clip(y_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "# test_r2_log = r2_score(y_test, y_pred_log)\n",
    "# test_mse_log = mean_squared_error(y_test, y_pred_log)\n",
    "\n",
    "# print(\"Test MSE (log scale):\", test_mse_log)\n",
    "# print(\"Test R² (log scale):\", test_r2_log)\n",
    "\n",
    "# # ========== Residual Plot ==========\n",
    "# y_train_pred_log = best_model.predict(X_train)\n",
    "# y_train_pred_log = np.clip(y_train_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# residuals = y_train - y_train_pred_log\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=y_train_pred_log, y=residuals)\n",
    "# plt.axhline(y=0, color='r', linestyle='--')\n",
    "# plt.xlabel(\"Predicted log(purchaseValue) (Train)\")\n",
    "# plt.ylabel(\"Residuals (log scale)\")\n",
    "# plt.title(\"Residual Plot (Train Data, Random Forest)\")\n",
    "# plt.show()\n",
    "\n",
    "# # ========== Final Predictions ==========\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# y_final_pred_log = best_model.predict(test_df[selected_features])\n",
    "# y_final_pred_log = np.clip(y_final_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# y_final_pred = np.expm1(y_final_pred_log)\n",
    "# y_final_pred = np.maximum(0, y_final_pred)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_final_pred)),\n",
    "#     \"purchaseValue\": y_final_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca9222",
   "metadata": {
    "papermill": {
     "duration": 0.027486,
     "end_time": "2025-07-22T09:33:24.232709",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.205223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Gradient Boosting Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "932f8fda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.288788Z",
     "iopub.status.busy": "2025-07-22T09:33:24.288617Z",
     "iopub.status.idle": "2025-07-22T09:33:24.291919Z",
     "shell.execute_reply": "2025-07-22T09:33:24.291443Z"
    },
    "papermill": {
     "duration": 0.032912,
     "end_time": "2025-07-22T09:33:24.292875",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.259963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # ========== Gradient Boosting Model ==========\n",
    "# regressor = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [100, 200],\n",
    "#     'regressor__learning_rate': [0.01, 0.1],\n",
    "#     'regressor__max_depth': [3, 5]\n",
    "# }\n",
    "\n",
    "# # ========== Model Pipeline ==========\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', regressor)\n",
    "# ])\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=model_pipeline,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='r2',  # log-scale R²\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # ========== Train ==========\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation R² score (log scale):\", grid_search.best_score_)\n",
    "\n",
    "# # ========== Predict ==========\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# CLIP_MIN, CLIP_MAX = 0, 20\n",
    "# y_pred_log = np.clip(y_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "# test_r2_log = r2_score(y_test, y_pred_log)\n",
    "# test_mse_log = mean_squared_error(y_test, y_pred_log)\n",
    "\n",
    "# print(\"Test MSE (log scale):\", test_mse_log)\n",
    "# print(\"Test R² (log scale):\", test_r2_log)\n",
    "\n",
    "# # ========== Residual Plot ==========\n",
    "# y_train_pred_log = best_model.predict(X_train)\n",
    "# y_train_pred_log = np.clip(y_train_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# residuals = y_train - y_train_pred_log\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=y_train_pred_log, y=residuals)\n",
    "# plt.axhline(y=0, color='r', linestyle='--')\n",
    "# plt.xlabel(\"Predicted log(purchaseValue) (Train)\")\n",
    "# plt.ylabel(\"Residuals (log scale)\")\n",
    "# plt.title(\"Residual Plot (Train Data, Gradient Boosting)\")\n",
    "# plt.show()\n",
    "\n",
    "# # ========== Final Predictions ==========\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# y_final_pred_log = best_model.predict(test_df[selected_features])\n",
    "# y_final_pred_log = np.clip(y_final_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# y_final_pred = np.expm1(y_final_pred_log)\n",
    "# y_final_pred = np.maximum(0, y_final_pred)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_final_pred)),\n",
    "#     \"purchaseValue\": y_final_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1cfe8",
   "metadata": {
    "papermill": {
     "duration": 0.027314,
     "end_time": "2025-07-22T09:33:24.347513",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.320199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### XGBoost Model + Pipeline + Tuning + Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e973b1d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.402678Z",
     "iopub.status.busy": "2025-07-22T09:33:24.402504Z",
     "iopub.status.idle": "2025-07-22T09:33:24.406134Z",
     "shell.execute_reply": "2025-07-22T09:33:24.405634Z"
    },
    "papermill": {
     "duration": 0.032333,
     "end_time": "2025-07-22T09:33:24.407127",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.374794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # ========== Define XGBoost Model ==========\n",
    "# regressor = XGBRegressor(\n",
    "#     objective='reg:squarederror',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     verbosity=1\n",
    "# )\n",
    "\n",
    "# # ========== Hyperparameter Grid ==========\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [100, 200],\n",
    "#     'regressor__learning_rate': [0.01, 0.1],\n",
    "#     'regressor__max_depth': [3, 6]\n",
    "# }\n",
    "\n",
    "# # ========== Pipeline ==========\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', regressor)\n",
    "# ])\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=model_pipeline,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='r2',\n",
    "#     cv=5,\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # ========== Train ==========\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nBest parameters found by GridSearchCV for XGBoost:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation R² score (log scale):\", grid_search.best_score_)\n",
    "\n",
    "# # ========== Predict ==========\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "# CLIP_MIN, CLIP_MAX = 0, 20\n",
    "# y_pred_log = np.clip(y_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "# test_r2_log = r2_score(y_test, y_pred_log)\n",
    "# test_mse_log = mean_squared_error(y_test, y_pred_log)\n",
    "\n",
    "# print(\"Test MSE (log scale):\", test_mse_log)\n",
    "# print(\"Test R² (log scale):\", test_r2_log)\n",
    "\n",
    "# # ========== Residual Plot ==========\n",
    "# y_train_pred_log = best_model.predict(X_train)\n",
    "# y_train_pred_log = np.clip(y_train_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# residuals = y_train - y_train_pred_log\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=y_train_pred_log, y=residuals)\n",
    "# plt.axhline(y=0, color='r', linestyle='--')\n",
    "# plt.xlabel(\"Predicted log(purchaseValue) (Train)\")\n",
    "# plt.ylabel(\"Residuals (log scale)\")\n",
    "# plt.title(\"Residual Plot (Train Data, XGBoost)\")\n",
    "# plt.show()\n",
    "\n",
    "# # ========== Final Predictions ==========\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# y_final_pred_log = best_model.predict(test_df[selected_features])\n",
    "# y_final_pred_log = np.clip(y_final_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# y_final_pred = np.expm1(y_final_pred_log)\n",
    "# y_final_pred = np.maximum(0, y_final_pred)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_final_pred)),\n",
    "#     \"purchaseValue\": y_final_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680ef82",
   "metadata": {
    "papermill": {
     "duration": 0.027258,
     "end_time": "2025-07-22T09:33:24.462132",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.434874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### LightGBM Full Integration Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8dbdc084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.518145Z",
     "iopub.status.busy": "2025-07-22T09:33:24.517923Z",
     "iopub.status.idle": "2025-07-22T09:33:24.521266Z",
     "shell.execute_reply": "2025-07-22T09:33:24.520781Z"
    },
    "papermill": {
     "duration": 0.032963,
     "end_time": "2025-07-22T09:33:24.522342",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.489379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # ========== LightGBM Regressor ==========\n",
    "# regressor = LGBMRegressor(objective='regression', random_state=42, n_jobs=-1)\n",
    "\n",
    "# # ========== Parameter Grid ==========\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [100, 200],\n",
    "#     'regressor__learning_rate': [0.01, 0.1],\n",
    "#     'regressor__max_depth': [3, 6]\n",
    "# }\n",
    "\n",
    "# # ========== Pipeline ==========\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', regressor)\n",
    "# ])\n",
    "\n",
    "# # ========== GridSearchCV ==========\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=model_pipeline,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='r2',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # ========== Fit ==========\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\nBest parameters found by GridSearchCV for LightGBM:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation R² score (log scale):\", grid_search.best_score_)\n",
    "\n",
    "# # ========== Predict ==========\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# CLIP_MIN, CLIP_MAX = 0, 20\n",
    "# y_pred_log = np.clip(y_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "# test_r2_log = r2_score(y_test, y_pred_log)\n",
    "# test_mse_log = mean_squared_error(y_test, y_pred_log)\n",
    "\n",
    "# print(\"Test MSE (log scale):\", test_mse_log)\n",
    "# print(\"Test R² (log scale):\", test_r2_log)\n",
    "\n",
    "# # ========== Residual Plot ==========\n",
    "# y_train_pred_log = best_model.predict(X_train)\n",
    "# y_train_pred_log = np.clip(y_train_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# residuals = y_train - y_train_pred_log\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=y_train_pred_log, y=residuals)\n",
    "# plt.axhline(y=0, color='r', linestyle='--')\n",
    "# plt.xlabel(\"Predicted log(purchaseValue) (Train)\")\n",
    "# plt.ylabel(\"Residuals (log scale)\")\n",
    "# plt.title(\"Residual Plot (Train Data, LightGBM)\")\n",
    "# plt.show()\n",
    "\n",
    "# # ========== Final Predictions ==========\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# y_final_pred_log = best_model.predict(test_df[selected_features])\n",
    "# y_final_pred_log = np.clip(y_final_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# y_final_pred = np.expm1(y_final_pred_log)\n",
    "# y_final_pred = np.maximum(0, y_final_pred)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_final_pred)),\n",
    "#     \"purchaseValue\": y_final_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3e40f6",
   "metadata": {
    "papermill": {
     "duration": 0.0279,
     "end_time": "2025-07-22T09:33:24.577456",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.549556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Random Forest with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "84d8d3c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.632918Z",
     "iopub.status.busy": "2025-07-22T09:33:24.632735Z",
     "iopub.status.idle": "2025-07-22T09:33:24.637624Z",
     "shell.execute_reply": "2025-07-22T09:33:24.637132Z"
    },
    "papermill": {
     "duration": 0.033956,
     "end_time": "2025-07-22T09:33:24.638615",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.604659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn. preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # ==============================\n",
    "# # 🧠 STEP 1: Setup & Constants\n",
    "# # ==============================\n",
    "# USE_LOG_TRANSFORM = True\n",
    "\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20 \n",
    "# # === Step 0: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # # Step 2: Remove top 1% outliers from target\n",
    "# # threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# # filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# purchase_df = train_df[train_df['purchaseValue'] > 0].copy()\n",
    "# #purchase_df['log_purchase'] = np.log1p(purchase_df['purchaseValue'])\n",
    "\n",
    "# # Step 3: Define features (X) and log-transformed target (y)\n",
    "# X = purchase_df[selected_features].copy()\n",
    "# y = np.log1p(purchase_df['purchaseValue']) \n",
    "\n",
    "# # Step 3: Define features (X) and log-transformed target (y)\n",
    "# # X = filtered_df[selected_features].copy()\n",
    "# # y = np.log1p(filtered_df['purchaseValue'])  # log1p ensures 0 is handled safely\n",
    "\n",
    "# # Step 4: Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Step 5: Preprocessing setup\n",
    "# cat_cols = list(set(X_train.select_dtypes(include='object').columns) & set(cat_features))\n",
    "# num_cols = list(set(X_train.select_dtypes(include='number').columns) & set(num_features))\n",
    "\n",
    "# X_train[cat_cols] = X_train[cat_cols].astype(str)\n",
    "# X_test[cat_cols] = X_test[cat_cols].astype(str)\n",
    "\n",
    "# # ==============================\n",
    "# # 🔄 STEP 4: Preprocessor\n",
    "# # ==============================\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('num', numeric_transformer, num_features),\n",
    "#     ('cat', categorical_transformer, cat_features)\n",
    "# ])\n",
    "\n",
    "# # ==============================\n",
    "# # 🌲 STEP 5: Pipeline & GridSearch\n",
    "# # ==============================\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', RandomForestRegressor(random_state=42))\n",
    "# ])\n",
    "\n",
    "# param_grid = {\n",
    "#     'regressor__max_depth': [20, 30],\n",
    "#     'regressor__min_samples_split': [2, 5],\n",
    "#     'regressor__n_estimators': [50, 100]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     model_pipeline,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='r2',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # ==============================\n",
    "# # ✅ STEP 6: Fit GridSearch\n",
    "# # ==============================\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best R² Score (CV):\", grid_search.best_score_)\n",
    "\n",
    "# # ==============================\n",
    "# # 🧪 STEP 7: Predict and Evaluate\n",
    "# # ==============================\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# # Clip and inverse transform predictions\n",
    "# y_pred_log_clipped = np.clip(y_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "# y_pred = np.expm1(y_pred_log_clipped) if USE_LOG_TRANSFORM else y_pred_log_clipped\n",
    "# y_test_original = np.expm1(y_test) if USE_LOG_TRANSFORM else y_test\n",
    "\n",
    "# mse = mean_squared_error(y_test_original, y_pred)\n",
    "# r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "# print(f\"Test MSE (original scale): {mse:.4f}\")\n",
    "# print(f\"Test R² (original scale): {r2:.4f}\")\n",
    "\n",
    "# # ==============================\n",
    "# # 📦 STEP 8: Predict on Kaggle Test Set\n",
    "# # ==============================\n",
    "# # Preprocess test data\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# X_kaggle_test = test_df[selected_features]\n",
    "\n",
    "# # Predict\n",
    "# y_test_pred_raw = best_model.predict(X_kaggle_test)\n",
    "\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_test_pred_raw = np.clip(y_test_pred_raw, CLIP_MIN, CLIP_MAX)\n",
    "#     y_test_pred = np.expm1(y_test_pred_raw)\n",
    "# else:\n",
    "#     y_test_pred = y_test_pred_raw\n",
    "\n",
    "# y_test_pred = np.maximum(0, y_test_pred)  # No negative values\n",
    "\n",
    "# # ==============================\n",
    "# # 📝 STEP 9: Submission\n",
    "# # ==============================\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_test_pred)),  # Replace with test_df['id'] if available\n",
    "#     \"purchaseValue\": y_test_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"✅ Submission file created!\")\n",
    "\n",
    "# print(submission.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb7159",
   "metadata": {
    "papermill": {
     "duration": 0.027571,
     "end_time": "2025-07-22T09:33:24.694007",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.666436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Adaboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "44524bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.749422Z",
     "iopub.status.busy": "2025-07-22T09:33:24.749244Z",
     "iopub.status.idle": "2025-07-22T09:33:24.753330Z",
     "shell.execute_reply": "2025-07-22T09:33:24.752723Z"
    },
    "papermill": {
     "duration": 0.032929,
     "end_time": "2025-07-22T09:33:24.754307",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.721378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import AdaBoostRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Assuming: preprocessor, X_train, y_train, X_test, y_test, test_df, selected_features are defined\n",
    "\n",
    "# USE_LOG_TRANSFORM = True\n",
    "# CLIP_MIN, CLIP_MAX = -20, 20  # Safe clipping range for log predictions\n",
    "\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20 \n",
    "# # === Step 0: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # Define AdaBoost pipeline\n",
    "# ada_model = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', AdaBoostRegressor(\n",
    "#         base_estimator=DecisionTreeRegressor(max_depth=3),\n",
    "#         random_state=42\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "# # Hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [10, 20, 30],\n",
    "#     'regressor__learning_rate': [3, 9]\n",
    "# }\n",
    "\n",
    "# # Grid search setup\n",
    "# grid_search = GridSearchCV(\n",
    "#     ada_model,\n",
    "#     param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='r2',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # If using log transform, transform y_train before fitting\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_train_log = np.log1p(y_train)\n",
    "# else:\n",
    "#     y_train_log = y_train\n",
    "\n",
    "# # Fit grid search\n",
    "# grid_search.fit(X_train, y_train_log)\n",
    "\n",
    "# print(\"Best Params:\", grid_search.best_params_)\n",
    "# print(\"Best CV R2 Score:\", grid_search.best_score_)\n",
    "\n",
    "# # Best model for predictions\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Predict on test set (log scale if used)\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# # Clip predictions to avoid overflow in inverse log transform\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_pred_log_clipped = np.clip(y_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "#     y_pred = np.expm1(y_pred_log_clipped)\n",
    "#     y_test_orig = np.expm1(y_test)\n",
    "# else:\n",
    "#     y_pred = y_pred_log\n",
    "#     y_test_orig = y_test\n",
    "\n",
    "# # Evaluate\n",
    "# mse = mean_squared_error(y_test_orig, y_pred)\n",
    "# r2 = r2_score(y_test_orig, y_pred)\n",
    "\n",
    "# print(f\"Test MSE (original scale): {mse:.4f}\")\n",
    "# print(f\"Test R2 (original scale): {r2:.4f}\")\n",
    "\n",
    "# # Predict on Kaggle test data\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)  # Ensure categorical types\n",
    "# X_kaggle_test = test_df[selected_features]\n",
    "\n",
    "# y_test_pred_raw = best_model.predict(X_kaggle_test)\n",
    "\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_test_pred_raw = np.clip(y_test_pred_raw, CLIP_MIN, CLIP_MAX)\n",
    "#     y_test_pred = np.expm1(y_test_pred_raw)\n",
    "# else:\n",
    "#     y_test_pred = y_test_pred_raw\n",
    "\n",
    "# # Post-processing predictions\n",
    "# y_test_pred = np.maximum(0, y_test_pred)  # No negative predictions\n",
    "\n",
    "# # Create submission DataFrame\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_test_pred)),  # Replace with test_df['id'] if available\n",
    "#     \"purchaseValue\": y_test_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"✅ Submission file created!\")\n",
    "\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a677bd3",
   "metadata": {
    "papermill": {
     "duration": 0.027316,
     "end_time": "2025-07-22T09:33:24.809107",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.781791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d2ca497b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.865237Z",
     "iopub.status.busy": "2025-07-22T09:33:24.865046Z",
     "iopub.status.idle": "2025-07-22T09:33:24.870220Z",
     "shell.execute_reply": "2025-07-22T09:33:24.869680Z"
    },
    "papermill": {
     "duration": 0.034484,
     "end_time": "2025-07-22T09:33:24.871331",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.836847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from xgboost import XGBRegressor\n",
    "# from scipy.stats import randint, uniform\n",
    "\n",
    "# # ==============================\n",
    "# # ✳️ Feature Selection\n",
    "# # ==============================\n",
    "# # # Step 1: Feature selection\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20 \n",
    "# # === Step 0: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # # Step 2: Remove top 1% outliers from target\n",
    "# # threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# # filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# purchase_df = train_df[train_df['purchaseValue'] > 0].copy()\n",
    "# #purchase_df['log_purchase'] = np.log1p(purchase_df['purchaseValue'])\n",
    "\n",
    "# # Step 3: Define features (X) and log-transformed target (y)\n",
    "# X = purchase_df[selected_features].copy()\n",
    "# y = np.log1p(purchase_df['purchaseValue']) \n",
    "\n",
    "# # ==============================\n",
    "# # 🧼 STEP 1: Prepare Data\n",
    "# # ==============================\n",
    "# USE_LOG_TRANSFORM = True\n",
    "# CLIP_MIN = -20\n",
    "# CLIP_MAX = 20\n",
    "\n",
    "# # Remove top 1% outliers\n",
    "# # threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# # filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# # X = filtered_df[selected_features].copy()\n",
    "# # y = filtered_df['purchaseValue']\n",
    "\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y = np.log1p(y)\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.25, random_state=42\n",
    "# )\n",
    "\n",
    "# # Convert categorical columns to string\n",
    "# cat_cols = list(set(X_train.select_dtypes(include='object').columns) & set(cat_features))\n",
    "# X_train[cat_cols] = X_train[cat_cols].astype(str)\n",
    "# X_test[cat_cols] = X_test[cat_cols].astype(str)\n",
    "\n",
    "# # ==============================\n",
    "# # ⚙️ STEP 2: Preprocessing Pipeline\n",
    "# # ==============================\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# numerical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('cat', categorical_transformer, cat_cols),\n",
    "#     ('num', numerical_transformer, num_features)\n",
    "# ])\n",
    "\n",
    "# # ==============================\n",
    "# # 📈 STEP 3: Model and Pipeline\n",
    "# # ==============================\n",
    "# xgb_model = XGBRegressor(\n",
    "#     objective='reg:squarederror',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     verbosity=1\n",
    "# )\n",
    "\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', xgb_model)\n",
    "# ])\n",
    "\n",
    "# # ==============================\n",
    "# # 🔍 STEP 4: RandomizedSearchCV\n",
    "# # ==============================\n",
    "# param_distributions = {\n",
    "#     'regressor__n_estimators': randint(100, 1000),\n",
    "#     'regressor__max_depth': randint(3, 15),\n",
    "#     'regressor__learning_rate': uniform(0.01, 0.3),\n",
    "#     'regressor__subsample': uniform(0.5, 0.5),\n",
    "#     'regressor__colsample_bytree': uniform(0.5, 0.5),\n",
    "#     'regressor__gamma': uniform(0, 5),\n",
    "#     'regressor__min_child_weight': randint(1, 10)\n",
    "# }\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     model_pipeline,\n",
    "#     param_distributions=param_distributions,\n",
    "#     n_iter=50,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     cv=3,\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # ==============================\n",
    "# # 🏋️ STEP 5: Train Model\n",
    "# # ==============================\n",
    "# random_search.fit(X_train, y_train)\n",
    "# print(\"Best params:\", random_search.best_params_)\n",
    "# print(\"Best CV MSE:\", -random_search.best_score_)\n",
    "\n",
    "# best_model = random_search.best_estimator_\n",
    "\n",
    "# # ==============================\n",
    "# # 📊 STEP 6: Evaluation\n",
    "# # ==============================\n",
    "# y_pred_log = best_model.predict(X_test)\n",
    "\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_pred_log_clipped = np.clip(y_pred_log, CLIP_MIN, CLIP_MAX)\n",
    "#     y_pred = np.expm1(y_pred_log_clipped)\n",
    "#     y_test_orig = np.expm1(y_test)\n",
    "# else:\n",
    "#     y_pred = y_pred_log\n",
    "#     y_test_orig = y_test\n",
    "\n",
    "# test_mse = mean_squared_error(y_test_orig, y_pred)\n",
    "# test_r2 = r2_score(y_test_orig, y_pred)\n",
    "\n",
    "# print(f\"Test Mean Squared Error: {test_mse:.4f}\")\n",
    "# print(f\"Test R² Score: {test_r2:.4f}\")\n",
    "\n",
    "# # ==============================\n",
    "# # 🧪 STEP 7: Predict on Final Test Data\n",
    "# # ==============================\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "# X_kaggle_test = test_df[selected_features]\n",
    "\n",
    "# y_test_pred_raw = best_model.predict(X_kaggle_test)\n",
    "\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_test_pred_raw = np.clip(y_test_pred_raw, CLIP_MIN, CLIP_MAX)\n",
    "#     y_test_pred = np.expm1(y_test_pred_raw)\n",
    "# else:\n",
    "#     y_test_pred = y_test_pred_raw\n",
    "\n",
    "# y_test_pred = np.maximum(0, y_test_pred)\n",
    "\n",
    "# # ==============================\n",
    "# # 📁 STEP 8: Submission File\n",
    "# # ==============================\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_test_pred)),  # Replace with test_df[\"id\"] if available\n",
    "#     \"purchaseValue\": y_test_pred.round().astype(int)\n",
    "# })\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "\n",
    "# # ==============================\n",
    "# # 📄 Optional: Save search results\n",
    "# # ==============================\n",
    "# results_df = pd.DataFrame(random_search.cv_results_)\n",
    "# results_df.to_csv(\"random_search_results.csv\", index=False)\n",
    "\n",
    "# # Output preview\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7ca161da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:24.934820Z",
     "iopub.status.busy": "2025-07-22T09:33:24.934639Z",
     "iopub.status.idle": "2025-07-22T09:33:24.939252Z",
     "shell.execute_reply": "2025-07-22T09:33:24.938420Z"
    },
    "papermill": {
     "duration": 0.042041,
     "end_time": "2025-07-22T09:33:24.941002",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.898961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Make sure these variables are defined before running this:\n",
    "# # train_df, test_df, preprocessor, selected_features\n",
    "\n",
    "# # 1. Prepare data (assuming train_df, test_df are loaded)\n",
    "# threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20 \n",
    "# # === Step 0: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "\n",
    "# X = filtered_df[selected_features].copy()\n",
    "# y = filtered_df['purchaseValue']\n",
    "\n",
    "# # 2. Train-test split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # 3. Log-transform targets if specified\n",
    "# USE_LOG_TRANSFORM = True\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20\n",
    "\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_train_log = np.log1p(y_train)\n",
    "#     y_test_log = np.log1p(y_test)\n",
    "# else:\n",
    "#     y_train_log = y_train\n",
    "#     y_test_log = y_test\n",
    "\n",
    "# # 4. Train KNN model pipeline\n",
    "# knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "# pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', knn_regressor)\n",
    "# ])\n",
    "# pipeline.fit(X_train, y_train_log)\n",
    "\n",
    "# # 5. Predict on test set\n",
    "# y_pred_log = pipeline.predict(X_test)\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_pred_log = np.clip(y_pred_log, CLIP_MIN_LOG, CLIP_MAX_LOG)\n",
    "#     y_pred = np.expm1(y_pred_log)\n",
    "#     y_test_log_clipped = np.clip(y_test_log, CLIP_MIN_LOG, CLIP_MAX_LOG)\n",
    "#     y_test_original = np.expm1(y_test_log_clipped)\n",
    "# else:\n",
    "#     y_pred = y_pred_log\n",
    "#     y_test_original = y_test\n",
    "\n",
    "# # 6. Evaluate\n",
    "# mse = mean_squared_error(y_test_original, y_pred)\n",
    "# r2 = r2_score(y_test_original, y_pred)\n",
    "# print(f\"Test Mean Squared Error: {mse:.4f}\")\n",
    "# print(f\"Test R² Score: {r2:.4f}\")\n",
    "\n",
    "# # 7. Predict on Kaggle test set\n",
    "# # Make sure categorical features in test_df are string type for consistency\n",
    "# cat_cols = list(set(X_train.select_dtypes(include='object').columns) & set(selected_features))\n",
    "# test_df[cat_cols] = test_df[cat_cols].astype(str)\n",
    "\n",
    "# X_kaggle_test = test_df[selected_features]\n",
    "# y_test_pred_raw = pipeline.predict(X_kaggle_test)\n",
    "\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_test_pred_raw = np.clip(y_test_pred_raw, CLIP_MIN_LOG, CLIP_MAX_LOG)\n",
    "#     y_test_pred = np.expm1(y_test_pred_raw)\n",
    "# else:\n",
    "#     y_test_pred = y_test_pred_raw\n",
    "\n",
    "# # 8. Post-process predictions\n",
    "# y_test_pred = np.maximum(0, y_test_pred)       # no negative values\n",
    "# y_test_pred = np.minimum(y_test_pred, 1e6)     # cap extreme high values\n",
    "\n",
    "# # 9. Create submission file\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_test_pred)),  # replace with test_df['id'] if exists\n",
    "#     \"purchaseValue\": y_test_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"✅ Submission file created: 'submission.csv'\")\n",
    "\n",
    "# print(submission.head())\n",
    "# print(submission.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "20489589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.008407Z",
     "iopub.status.busy": "2025-07-22T09:33:25.008174Z",
     "iopub.status.idle": "2025-07-22T09:33:25.012710Z",
     "shell.execute_reply": "2025-07-22T09:33:25.012087Z"
    },
    "papermill": {
     "duration": 0.034882,
     "end_time": "2025-07-22T09:33:25.013831",
     "exception": false,
     "start_time": "2025-07-22T09:33:24.978949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Make sure these variables are defined before running:\n",
    "# # X_train, y_train, X_test, y_test, test_df, preprocessor, selected_features\n",
    "# # Also define the log transform flags and clipping values:\n",
    "# USE_LOG_TRANSFORM = True\n",
    "# CLIP_MIN, CLIP_MAX = -20, 20  # Adjust as per your earlier setup\n",
    "\n",
    "# # 1. Prepare data (assuming train_df, test_df are loaded)\n",
    "# cat_features = [\n",
    "# 'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "# 'userChannel', 'trafficSource.medium'#, 'trafficSource.referralPath',\n",
    "#     #'geoNetwork.continent', 'geoNetwork.metro', 'geoNetwork.region', 'os'\n",
    "# ]\n",
    "\n",
    "# num_features = ['avg_interaction', 'sessionNumber', 'trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # # Step 2: Remove top 1% outliers from target\n",
    "# # threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# # filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# purchase_df = train_df[train_df['purchaseValue'] > 0].copy()\n",
    "# #purchase_df['log_purchase'] = np.log1p(purchase_df['purchaseValue'])\n",
    "\n",
    "# # Step 3: Define features (X) and log-transformed target (y)\n",
    "# X = purchase_df[selected_features].copy()\n",
    "# y = np.log1p(purchase_df['purchaseValue']) \n",
    "\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "\n",
    "# # Step 6: Define parameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [800, 850, 900],           # around 866\n",
    "#     'regressor__max_depth': [6, 8, 10],                   # try deeper trees\n",
    "#     'regressor__learning_rate': [0.03, 0.05, 0.07],       # smaller steps than 0.1\n",
    "#     'regressor__subsample': [0.85, 0.9, 0.95],            # around 0.9015\n",
    "#     'regressor__colsample_bytree': [0.7, 0.8, 0.9],       # optionally add this\n",
    "#     'regressor__reg_alpha': [0, 0.1, 1],\n",
    "#     'regressor__reg_lambda': [1, 5, 10],\n",
    "#     'regressor__min_child_weight': [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# # Step 7: Setup GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     model_pipeline,\n",
    "#     param_grid,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     cv=3,\n",
    "       \n",
    "# )\n",
    "\n",
    "# # Step 8: Fit grid search on training data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best params:\", grid_search.best_params_)\n",
    "# print(\"Best CV MSE:\", -grid_search.best_score_)\n",
    "\n",
    "# # Step 9: Evaluate best model on test data\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# test_mse = mean_squared_error(y_test, y_pred)\n",
    "# test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"Test Mean Squared Error: {test_mse:.4f}\")\n",
    "# print(f\"Test R² Score: {test_r2:.4f}\")\n",
    "\n",
    "# # Step 10: Predict on external test data with best XGB model\n",
    "# y_test_pred_raw = best_model.predict(test_df[selected_features])\n",
    "\n",
    "# # Step 11: Apply inverse log transform if used\n",
    "# if USE_LOG_TRANSFORM:\n",
    "#     y_test_pred_raw = np.clip(y_test_pred_raw, CLIP_MIN, CLIP_MAX)\n",
    "#     y_test_pred = np.expm1(y_test_pred_raw)\n",
    "# else:\n",
    "#     y_test_pred = y_test_pred_raw\n",
    "\n",
    "# # Clip negatives to zero\n",
    "# y_test_pred = np.maximum(0, y_test_pred)\n",
    "\n",
    "# # Step 12: Prepare submission DataFrame\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_test_pred)),  # or use test_df['id'] if available\n",
    "#     \"purchaseValue\": y_test_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission file created!\")\n",
    "\n",
    "# print(submission.head())\n",
    "# print(submission.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8d72ec93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.122096Z",
     "iopub.status.busy": "2025-07-22T09:33:25.121827Z",
     "iopub.status.idle": "2025-07-22T09:33:25.126635Z",
     "shell.execute_reply": "2025-07-22T09:33:25.125967Z"
    },
    "papermill": {
     "duration": 0.035465,
     "end_time": "2025-07-22T09:33:25.127968",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.092503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Step 1: Define features\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20 \n",
    "# # === Step 0: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "\n",
    "# # Step 2: Filter out top 1% outliers on purchaseValue\n",
    "# threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# X = filtered_df[selected_features].copy()\n",
    "# y = np.log1p(filtered_df['purchaseValue'])  # log-transform for better regression performance\n",
    "\n",
    "# # Step 3: Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.25, random_state=42\n",
    "# )\n",
    "\n",
    "# # Step 4: Identify column types\n",
    "# categorical_features = list(set(X_train.select_dtypes(include=['object', 'bool']).columns) & set(cat_top_features))\n",
    "# numeric_features = list(set(X_train.select_dtypes(include=['number']).columns) & set(num_top_features))\n",
    "\n",
    "# # Convert bools to strings (if any)\n",
    "# X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "# X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
    "\n",
    "# # Step 5: Preprocessing pipelines\n",
    "# numeric_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     ('num', numeric_transformer, numeric_features),\n",
    "#     ('cat', categorical_transformer, categorical_features)\n",
    "# ])\n",
    "\n",
    "# # Step 6: Define BaggingRegressor\n",
    "# base_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "\n",
    "# bagging_model = BaggingRegressor(\n",
    "#     estimator=base_model,         # ✅ updated\n",
    "#     n_estimators=50,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Step 7: Full pipeline\n",
    "# pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', bagging_model)\n",
    "# ])\n",
    "\n",
    "# # Step 8: Train model\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Step 9: Predict and evaluate\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Convert predictions back to original scale if log-transformed\n",
    "# y_test_original = np.expm1(y_test)\n",
    "# y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "# mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "# r2 = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "# print(f\"Test Mean Squared Error: {mse:.4f}\")\n",
    "# print(f\"Test R² Score: {r2:.4f}\")\n",
    "\n",
    "# # Step 10: Predict on Kaggle test data\n",
    "# # Make sure 'test_df' and 'selected_features' are defined and preprocessed similarly\n",
    "# X_kaggle_test = test_df[selected_features].copy()\n",
    "\n",
    "# # Convert categorical columns in test set to strings to match training preprocessing\n",
    "# X_kaggle_test[categorical_features] = X_kaggle_test[categorical_features].astype(str)\n",
    "\n",
    "# # Predict (log scale)\n",
    "# y_kaggle_pred_log = pipeline.predict(X_kaggle_test)\n",
    "\n",
    "# # Inverse log transform\n",
    "# y_kaggle_pred = np.expm1(y_kaggle_pred_log)\n",
    "\n",
    "# # Clip negatives to zero\n",
    "# y_kaggle_pred = np.maximum(0, y_kaggle_pred)\n",
    "\n",
    "# # Step 11: Create submission DataFrame\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_kaggle_pred)),  # Replace with test_df['id'] if available\n",
    "#     \"purchaseValue\": y_kaggle_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# # Step 12: Save submission file\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"✅ Submission file created: 'submission.csv'\")\n",
    "\n",
    "# # Optional: Preview submission head\n",
    "# print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e86069a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.189876Z",
     "iopub.status.busy": "2025-07-22T09:33:25.189629Z",
     "iopub.status.idle": "2025-07-22T09:33:25.196353Z",
     "shell.execute_reply": "2025-07-22T09:33:25.195542Z"
    },
    "papermill": {
     "duration": 0.039758,
     "end_time": "2025-07-22T09:33:25.197670",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.157912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Step 1: Define features\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20 \n",
    "# # === Step 0: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# # Step 2: Remove outliers (top 1%)\n",
    "# threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# X = filtered_df[selected_features].copy()\n",
    "# y = np.log1p(filtered_df['purchaseValue'])  # Log-transform to reduce skew\n",
    "\n",
    "# # Step 3: Split into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Step 4: Identify column types\n",
    "# categorical_features = list(set(X_train.select_dtypes(include=['object', 'bool']).columns) & set(cat_top_features))\n",
    "# numeric_features = list(set(X_train.select_dtypes(include=['number']).columns) & set(num_top_features))\n",
    "\n",
    "# # Convert categorical bools to strings\n",
    "# X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "# X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
    "\n",
    "# # Step 5: Preprocessing pipelines\n",
    "# numeric_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     ('num', numeric_transformer, numeric_features),\n",
    "#     ('cat', categorical_transformer, categorical_features)\n",
    "# ])\n",
    "\n",
    "# # Step 6: Define the Gradient Boosting Regressor\n",
    "# gbr_model = GradientBoostingRegressor(\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.1,\n",
    "#     max_depth=3,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Step 7: Full pipeline\n",
    "# pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', gbr_model)\n",
    "# ])\n",
    "\n",
    "# # Step 8: Train the model\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Step 9: Predict and evaluate\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Convert back to original scale\n",
    "# y_test_original = np.expm1(y_test)\n",
    "# y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "# mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "# r2 = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "# print(f\"Test Mean Squared Error: {mse:.4f}\")\n",
    "# print(f\"Test R² Score: {r2:.4f}\")\n",
    "\n",
    "# # Assuming test_df is loaded and contains the same features:\n",
    "# X_kaggle_test = test_df[selected_features].copy()\n",
    "# X_kaggle_test[categorical_features] = X_kaggle_test[categorical_features].astype(str)\n",
    "\n",
    "# y_kaggle_pred_log = pipeline.predict(X_kaggle_test)\n",
    "# y_kaggle_pred = np.expm1(y_kaggle_pred_log)\n",
    "# y_kaggle_pred = np.maximum(0, y_kaggle_pred)  # Avoid negative predictions\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     \"id\": np.arange(len(y_kaggle_pred)),  # Replace with test_df['id'] if available\n",
    "#     \"purchaseValue\": y_kaggle_pred.round().astype(int)\n",
    "# })\n",
    "\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"✅ Submission file created: 'submission.csv'\")\n",
    "\n",
    "# #Optional: Preview submission head\n",
    "# print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "daa84229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.263212Z",
     "iopub.status.busy": "2025-07-22T09:33:25.262983Z",
     "iopub.status.idle": "2025-07-22T09:33:25.267092Z",
     "shell.execute_reply": "2025-07-22T09:33:25.266428Z"
    },
    "papermill": {
     "duration": 0.03434,
     "end_time": "2025-07-22T09:33:25.268422",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.234082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import StackingRegressor\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Feature selection\n",
    "# CLIP_MIN_LOG, CLIP_MAX_LOG = -20, 20 \n",
    "# # === Step 0: Feature selection ===\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium'\n",
    "# ]\n",
    "\n",
    "# num_features = ['totalHits_log', 'pageViews_log','sessionNumber_log','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "\n",
    "# # Outlier removal\n",
    "# threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# X = filtered_df[selected_features].copy()\n",
    "# y = np.log1p(filtered_df['purchaseValue'])  # log-transform\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# categorical_features = list(set(X_train.select_dtypes(include=['object', 'bool']).columns) & set(cat_top_features))\n",
    "# numeric_features = list(set(X_train.select_dtypes(include=['number']).columns) & set(num_top_features))\n",
    "\n",
    "# X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "# X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
    "\n",
    "# numeric_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     ('num', numeric_transformer, numeric_features),\n",
    "#     ('cat', categorical_transformer, categorical_features)\n",
    "# ])\n",
    "\n",
    "# # Base regressors\n",
    "# estimators = [\n",
    "#     ('dt', DecisionTreeRegressor(max_depth=5)),\n",
    "#     ('knn', KNeighborsRegressor(n_neighbors=5))\n",
    "# ]\n",
    "\n",
    "# # Final estimator\n",
    "# final_estimator = Ridge()\n",
    "\n",
    "# stacking_model = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('stacking', StackingRegressor(estimators=estimators, final_estimator=final_estimator, passthrough=True, n_jobs=-1))\n",
    "# ])\n",
    "\n",
    "# stacking_model.fit(X_train, y_train)\n",
    "# y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# # Convert predictions back to original scale\n",
    "# y_test_original = np.expm1(y_test)\n",
    "# y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "# print(\"Stacking Regressor Performance:\")\n",
    "# print(f\"MSE: {mean_squared_error(y_test_original, y_pred_original):.4f}\")\n",
    "# print(f\"R²: {r2_score(y_test_original, y_pred_original):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f4f2703d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.335941Z",
     "iopub.status.busy": "2025-07-22T09:33:25.335739Z",
     "iopub.status.idle": "2025-07-22T09:33:25.339089Z",
     "shell.execute_reply": "2025-07-22T09:33:25.338467Z"
    },
    "papermill": {
     "duration": 0.032691,
     "end_time": "2025-07-22T09:33:25.340235",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.307544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# mlp_model = Pipeline([\n",
    "#     ('preprocessor', preprocessor),  # reuse the same preprocessor as above\n",
    "#     ('mlp', MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42))\n",
    "# ])\n",
    "\n",
    "# mlp_model.fit(X_train, y_train)\n",
    "# y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "# y_test_original = np.expm1(y_test)\n",
    "# y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "# print(\"MLP Regressor Performance:\")\n",
    "# print(f\"MSE: {mean_squared_error(y_test_original, y_pred_original):.4f}\")\n",
    "# print(f\"R²: {r2_score(y_test_original, y_pred_original):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "79c10f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.410825Z",
     "iopub.status.busy": "2025-07-22T09:33:25.410609Z",
     "iopub.status.idle": "2025-07-22T09:33:25.414707Z",
     "shell.execute_reply": "2025-07-22T09:33:25.414130Z"
    },
    "papermill": {
     "duration": 0.044066,
     "end_time": "2025-07-22T09:33:25.415750",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.371684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# # Assuming train_df is loaded and contains features + 'purchaseValue'\n",
    "\n",
    "# # Step 1: Separate features and target\n",
    "# cat_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium', 'trafficSource.referralPath',\n",
    "#     'geoNetwork.continent', 'geoNetwork.metro', 'geoNetwork.region', 'os'\n",
    "# ]\n",
    "\n",
    "# num_features = ['avg_interaction', 'sessionNumber','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "\n",
    "# selected_features = cat_features + num_features\n",
    "\n",
    "# X = train_df[selected_features].copy()\n",
    "# y = train_df['purchaseValue'].copy()\n",
    "\n",
    "# # Step 2: Split with 20% test size, random state 39\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.25, random_state=39\n",
    "# )\n",
    "\n",
    "# # Step 3: Preprocessing pipelines\n",
    "\n",
    "# # Identify categorical and numeric columns in training data\n",
    "# categorical_features = list(set(X_train.select_dtypes(include=['object', 'bool']).columns) & set(cat_features))\n",
    "# numeric_features = list(set(X_train.select_dtypes(include=['number']).columns) & set(num_features))\n",
    "\n",
    "# # Convert bools to string for OneHotEncoder compatibility\n",
    "# X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "# X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
    "\n",
    "# numeric_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     ('num', numeric_transformer, numeric_features),\n",
    "#     ('cat', categorical_transformer, categorical_features)\n",
    "# ])\n",
    "\n",
    "# # Step 4: Build the MLP pipeline\n",
    "# mlp_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', MLPRegressor(hidden_layer_sizes=(5,3), random_state=42, max_iter=500))\n",
    "# ])\n",
    "\n",
    "# # Step 5: Fit the model on training data\n",
    "# mlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Step 6: Predict and score\n",
    "# train_score = mlp_pipeline.score(X_train, y_train)  # R^2 on train\n",
    "# test_score = mlp_pipeline.score(X_test, y_test)    # R^2 on test\n",
    "\n",
    "# # Step 7: Round scores to 3 decimal places\n",
    "# train_score_rounded = round(train_score, 3)\n",
    "# test_score_rounded = round(test_score, 3)\n",
    "\n",
    "# print(f\"Training score (R²): {train_score_rounded}\")\n",
    "# print(f\"Test score (R²): {test_score_rounded}\")\n",
    "\n",
    "# # Step 8: Overfit or Underfit?\n",
    "# if train_score > test_score + 0.1:\n",
    "#     fit_status = \"Overfitting (training score much higher than test score)\"\n",
    "# elif test_score > train_score + 0.1:\n",
    "#     fit_status = \"Underfitting (test score higher than training score)\"\n",
    "# else:\n",
    "#     fit_status = \"Good fit (training and test scores are close)\"\n",
    "\n",
    "# print(f\"Model fit status: {fit_status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f68bfff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.473197Z",
     "iopub.status.busy": "2025-07-22T09:33:25.472901Z",
     "iopub.status.idle": "2025-07-22T09:33:25.478934Z",
     "shell.execute_reply": "2025-07-22T09:33:25.478427Z"
    },
    "papermill": {
     "duration": 0.036076,
     "end_time": "2025-07-22T09:33:25.480042",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.443966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensemble Regression Models: Bagging, Boosting, Stacking\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Models\n",
    "# from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# # --- Data Preparation ---\n",
    "# # Assumes train_df is already loaded\n",
    "# cat_top_features = [\n",
    "#     'trafficSource', 'locationCountry', 'geoNetwork.subContinent',\n",
    "#     'userChannel', 'trafficSource.medium', 'trafficSource.referralPath',\n",
    "#     'geoNetwork.continent', 'geoNetwork.metro', 'geoNetwork.region', 'os'\n",
    "# ]\n",
    "\n",
    "# num_features = ['avg_interaction', 'sessionNumber','new_visits','totals.bounces','trafficSource.isTrueDirect']\n",
    "\n",
    "# selected_features = cat_top_features + num_top_features\n",
    "# threshold = train_df['purchaseValue'].quantile(0.99)\n",
    "# filtered_df = train_df[train_df['purchaseValue'] < threshold]\n",
    "\n",
    "# X = filtered_df[selected_features].copy()\n",
    "# y = np.log1p(filtered_df['purchaseValue'])\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# categorical_features = list(set(X_train.select_dtypes(include=['object', 'bool']).columns) & set(cat_top_features))\n",
    "# numeric_features = list(set(X_train.select_dtypes(include=['number']).columns) & set(num_top_features))\n",
    "\n",
    "# X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "# X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
    "\n",
    "# # --- Preprocessing ---\n",
    "# numeric_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# categorical_transformer = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer([\n",
    "#     ('num', numeric_transformer, numeric_features),\n",
    "#     ('cat', categorical_transformer, categorical_features)\n",
    "# ])\n",
    "\n",
    "# # --- Ensemble Models ---\n",
    "\n",
    "# # 1. Bagging Regressor\n",
    "# bagging_model = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', BaggingRegressor(estimator=DecisionTreeRegressor(max_depth=5), n_estimators=50, random_state=42))\n",
    "# ])\n",
    "\n",
    "# # 2. Gradient Boosting Regressor\n",
    "# boosting_model = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "# ])\n",
    "\n",
    "# # 3. Stacking Regressor\n",
    "# stacking_model = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', StackingRegressor(\n",
    "#         estimators=[\n",
    "#             ('dt', DecisionTreeRegressor(max_depth=5)),\n",
    "#             ('knn', KNeighborsRegressor(n_neighbors=5))\n",
    "#         ],\n",
    "#         final_estimator=Ridge(),\n",
    "#         passthrough=True,\n",
    "#         n_jobs=-1\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "# # --- Evaluation Function ---\n",
    "# def evaluate_model(name, model):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_test_orig = np.expm1(y_test)\n",
    "#     y_pred_orig = np.expm1(y_pred)\n",
    "#     mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "#     r2 = r2_score(y_test_orig, y_pred_orig)\n",
    "#     print(f\"{name} Model\\nMSE: {mse:.4f}\\nR^2: {r2:.4f}\\n\")\n",
    "\n",
    "# # --- Run Evaluations ---\n",
    "# evaluate_model(\"Bagging\", bagging_model)\n",
    "# evaluate_model(\"Boosting\", boosting_model)\n",
    "# evaluate_model(\"Stacking\", stacking_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ebcc7110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.538275Z",
     "iopub.status.busy": "2025-07-22T09:33:25.538010Z",
     "iopub.status.idle": "2025-07-22T09:33:25.542796Z",
     "shell.execute_reply": "2025-07-22T09:33:25.542132Z"
    },
    "papermill": {
     "duration": 0.035904,
     "end_time": "2025-07-22T09:33:25.543835",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.507931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def evaluate_predictions(\n",
    "#     submission_path,\n",
    "#     train_df,\n",
    "#     target_col='purchaseValue',\n",
    "#     id_col='index',\n",
    "#     prediction_col='purchaseValue',\n",
    "#     log_transform=False,\n",
    "#     metric='r2'\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Evaluate submission predictions against true target values.\n",
    "\n",
    "#     Args:\n",
    "#         submission_path (str): Path to submission CSV with 'id' and predicted values.\n",
    "#         train_df (pd.DataFrame): Training dataframe with actual values.\n",
    "#         target_col (str): Name of the true target column in train_df.\n",
    "#         id_col (str): Column to merge on (default is 'index').\n",
    "#         prediction_col (str): Column in submission CSV containing predictions.\n",
    "#         log_transform (bool): Whether the original model was trained on log-transformed target.\n",
    "#         metric (str): 'r2' or 'rmse'\n",
    "\n",
    "#     Returns:\n",
    "#         float: Metric score.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Load submission\n",
    "#     submission = pd.read_csv(submission_path)\n",
    "\n",
    "#     # Ensure train_df has a merge key\n",
    "#     if id_col not in train_df.columns:\n",
    "#         train_df = train_df.reset_index()\n",
    "\n",
    "#     # Merge predictions with true values\n",
    "#     merged = train_df.merge(submission, left_on=id_col, right_on='id')\n",
    "#     actual = merged[target_col + '_x']  # from train_df\n",
    "#     predicted = merged[prediction_col + '_y'].clip(lower=0)  # from submission\n",
    "\n",
    "\n",
    "#     if log_transform:\n",
    "#         # If the model was trained on log1p-transformed target, apply same transform here\n",
    "#         actual = np.log1p(actual)\n",
    "#         predicted = np.log1p(predicted)\n",
    "\n",
    "#     # Choose metric\n",
    "#     if metric == 'r2':\n",
    "#         score = r2_score(actual, predicted)\n",
    "#     elif metric == 'rmse':\n",
    "#         score = mean_squared_error(actual, predicted, squared=False)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported metric: use 'r2' or 'rmse'\")\n",
    "\n",
    "#     print(f\"{metric.upper()} score: {score:.4f}\")\n",
    "#     return score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8d68bce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.600719Z",
     "iopub.status.busy": "2025-07-22T09:33:25.600245Z",
     "iopub.status.idle": "2025-07-22T09:33:25.603568Z",
     "shell.execute_reply": "2025-07-22T09:33:25.602947Z"
    },
    "papermill": {
     "duration": 0.033049,
     "end_time": "2025-07-22T09:33:25.604634",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.571585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # #Example 1: R² on raw purchase values\n",
    "# evaluate_predictions('submission.csv', train_df, log_transform=False, metric='r2')\n",
    "\n",
    "# # # Example 2: RMSE on log-transformed values\n",
    "# evaluate_predictions('submission.csv', train_df, log_transform=True, metric='rmse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3185bdba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T09:33:25.661176Z",
     "iopub.status.busy": "2025-07-22T09:33:25.660913Z",
     "iopub.status.idle": "2025-07-22T09:33:25.664651Z",
     "shell.execute_reply": "2025-07-22T09:33:25.664117Z"
    },
    "papermill": {
     "duration": 0.033135,
     "end_time": "2025-07-22T09:33:25.665761",
     "exception": false,
     "start_time": "2025-07-22T09:33:25.632626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# log_rmse = mean_squared_error(y_val, y_val_pred_log, squared=False)\n",
    "# print(\"Validation RMSE (log):\", log_rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11895149,
     "sourceId": 99546,
     "sourceType": "competition"
    },
    {
     "datasetId": 7715048,
     "sourceId": 12244545,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 232.185522,
   "end_time": "2025-07-22T09:33:26.210644",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-22T09:29:34.025122",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
